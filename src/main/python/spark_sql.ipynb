<<<<<<< HEAD
{"cells":[{"cell_type":"markdown","source":["# Spark SQL\n* Top 10 hotels with max absolute temperature difference by month.\n* Top 10 busy (e.g., with the biggest visits count) hotels for each month. If visit dates refer to several months, it should be counted for all affected months.\n* For visits with extended stay (more than 7 days) calculate weather trend (the day temperature difference between last and first day of stay) and average temperature during stay."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56881a3c-061d-4626-8ca5-2500727e1d4e"}}},{"cell_type":"code","source":["from pyspark import sql\nimport os"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b68c7ce3-de9d-46d1-8078-00b95828e9b7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["session = sql.SparkSession.builder.getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1c4393d-6e57-4fe6-ad66-c64f43a577be"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"create database if not exists spark_sql\")\nsession.sql(\"use spark_sql\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"438f7088-966c-402d-85a2-1d1f42a9dbc9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[3]: DataFrame[]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: DataFrame[]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["session.conf.set(\"fs.azure.account.auth.type.{}.dfs.core.windows.net\".format(os.getenv(\"account_load_name\")),os.getenv(\"auth_type\"))\nsession.conf.set(\"fs.azure.account.oauth.provider.type.{}.dfs.core.windows.net\".format(os.getenv(\"account_load_name\")),os.getenv(\"provider_type\"))\nsession.conf.set(\"fs.azure.account.oauth2.client.id.{}.dfs.core.windows.net\".format(os.getenv(\"account_load_name\")),os.getenv(\"client_id\"))\nsession.conf.set(\"fs.azure.account.oauth2.client.secret.{}.dfs.core.windows.net\".format(os.getenv(\"account_load_name\")),os.getenv(\"client_secret\"))\nsession.conf.set(\"fs.azure.account.oauth2.client.endpoint.{}.dfs.core.windows.net\".format(os.getenv(\"account_load_name\")),os.getenv(\"client_endpoint\"))\nsession.conf.set(\"fs.azure.account.key.{}.dfs.core.windows.net\".format(os.getenv(\"account_upload_name\")),os.getenv(\"account_key\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70886f16-6ac3-40c1-874f-0264784a5b44"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["hotel_weather_DF= session.read.parquet(os.getenv(hotel_weather_path))\nexpedia_DF = session.read.format(\"avro\").load(os.getenv(expedia_path))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0590d695-027f-46f3-87e3-81e615764856"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"drop table if exists hotel_weather\")\nsession.sql(\"drop table if exists expedia\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a66d916-83c8-40f2-9d1f-1a370869348c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["hotel_weather_DF.orderBy(\"wthr_date\").write.saveAsTable(\"hotel_weather\")\nexpedia_DF.write.saveAsTable(\"expedia\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ef01973-d153-4b50-9b67-08d4ec194bca"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"optimize hotel_weather\")\nsession.sql(\"optimize expedia\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a578090-a7db-485b-8d3d-24ab776f3ce3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"drop view if exists expedia_month_sum_view\")\nsession.sql(\"drop view if exists join_data_view\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad381d50-d5a3-4303-9a89-383739342cf4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def analyze_plan(sql_select:str,is_extended: bool = True) -> None:\n  session.sql(sql_select).explain(extended=is_extended)\n\ndef show_query(sql_select:str) -> None:\n  session.sql(sql_select).show()\n\ndef save_query(sql_select:str,table:str,upload_path:str=os.getenv(upload_path),mode:str=\"overwrite\",partition:tuple=()) -> None:\n  \n  session.sql(sql_select)\n\n  session.table(table).write.parquet(path=\"{}/{}/\".format(upload_path,table),mode=mode,partitionBy=partition)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Support procedures","showTitle":true,"inputWidgets":{},"nuid":"f50d6712-ef54-4f5c-8ccf-f458465df844"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"drop table if exists query_1\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7eb764e8-021f-4211-b717-68c767c9e18e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[246]: DataFrame[]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[246]: DataFrame[]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["query=\"\"\" \n          create table if not exists query_1 as\n          \n          select id,year,month,abs(sum_avg_tmpr_c - lag(sum_avg_tmpr_c) over (partition by id,year order by month)) as sum_avg_tmpr_c_diff from \n          \n          (select id,year,month,sum(avg_tmpr_c) as sum_avg_tmpr_c from hotel_weather group by id,year,month)\n          \n          order by sum_avg_tmpr_c_diff desc limit 10\"\"\"\n\nanalyze_plan(query)\nsave_query(query)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Query 1 (calculate difference between months with lag function and order top hotels with max diff)","showTitle":true,"inputWidgets":{},"nuid":"083a1424-ff3f-4964-86b9-54619e19950a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"drop view if exists expedia_month_sum_view\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4cbad62-d971-40ee-b836-d65f3bb77251"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"\"\"\n\n        create view expedia_month_sum_view as \n        \n        select \n        \n        hotel_id,\n        coalesce(sum(Jan),0) as sum_Jan,\n        coalesce(sum(Feb),0) as sum_Feb,\n        coalesce(sum(Mar),0) as sum_Mar,\n        coalesce(sum(Apr),0) as sum_Apr,\n        coalesce(sum(May),0) as sum_May,\n        coalesce(sum(Jun),0) as sum_Jun,\n        coalesce(sum(Jul),0) as sum_Jul,\n        coalesce(sum(Aug),0) as sum_Aug,\n        coalesce(sum(Sep),0) as sum_Sep,\n        coalesce(sum(Oct),0) as sum_Oct,\n        coalesce(sum(Nov),0) as sum_Nov,\n        coalesce(sum(Dec),0) as sum_Dec \n        \n        from (\n        \n        select hotel_id,month(srch_ci) as srch_ci_month,month(srch_co) as srch_co_month from expedia) \n\n        pivot (count(*) for srch_ci_month in (1 as Jan,2 as Feb,3 as Mar,4 as Apr,5 as May,6 as Jun,7 as Jul,8 as Aug,9 as Sep,10 as Oct,11 as Nov,12 as Dec))\n        \n        group by hotel_id\n        \"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Query 2 ( we need to create a view with a pivot that allows on the next step select hotels by months )","showTitle":true,"inputWidgets":{},"nuid":"d3b84db0-8cd9-4817-9b78-afa1e101cc39"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["for month in ['sum_Jan','sum_Feb','sum_Mar','sum_Apr','sum_May','sum_Jun','sum_Jul','sum_Aug','sum_Sep','sum_Oct','sum_Nov','sum_Dec']:\n    session.sql(f\"drop table if exists query_2_{month}\")\n    query=f\"create table if not exists query_2_{month} as select hotel_id,{month} from expedia_month_sum_view order by {month} desc limit 10\"\n    analyze_plan(query)\n    save_query(query,\"query_2_{}\".format(month))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Iterating through months for selecting hotels with a view","showTitle":true,"inputWidgets":{},"nuid":"caa66749-2df4-4e37-9ec0-10d7109482b0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_sum_Jan], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;sum_Jan DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;sum_Jan]\n            +- &#39;UnresolvedRelation [expedia_month_sum_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Jan, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Jan#2211L DESC NULLS LAST], true\n         +- Project [hotel_id#2210L, sum_Jan#2211L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_sum_view\n               +- View (`spark_sql`.`expedia_month_sum_view`, [hotel_id#2210L,sum_Jan#2211L,sum_Feb#2212L,sum_Mar#2213L,sum_Apr#2214L,sum_May#2215L,sum_Jun#2216L,sum_Jul#2217L,sum_Aug#2218L,sum_Sep#2219L,sum_Oct#2220L,sum_Nov#2221L,sum_Dec#2222L])\n                  +- Project [cast(hotel_id#2281L as bigint) AS hotel_id#2210L, cast(sum_Jan#2198L as bigint) AS sum_Jan#2211L, cast(sum_Feb#2199L as bigint) AS sum_Feb#2212L, cast(sum_Mar#2200L as bigint) AS sum_Mar#2213L, cast(sum_Apr#2201L as bigint) AS sum_Apr#2214L, cast(sum_May#2202L as bigint) AS sum_May#2215L, cast(sum_Jun#2203L as bigint) AS sum_Jun#2216L, cast(sum_Jul#2204L as bigint) AS sum_Jul#2217L, cast(sum_Aug#2205L as bigint) AS sum_Aug#2218L, cast(sum_Sep#2206L as bigint) AS sum_Sep#2219L, cast(sum_Oct#2207L as bigint) AS sum_Oct#2220L, cast(sum_Nov#2208L as bigint) AS sum_Nov#2221L, cast(sum_Dec#2209L as bigint) AS sum_Dec#2222L]\n                     +- Aggregate [hotel_id#2281L], [hotel_id#2281L, coalesce(sum(Jan#2310L), cast(0 as bigint)) AS sum_Jan#2198L, coalesce(sum(Feb#2311L), cast(0 as bigint)) AS sum_Feb#2199L, coalesce(sum(Mar#2312L), cast(0 as bigint)) AS sum_Mar#2200L, coalesce(sum(Apr#2313L), cast(0 as bigint)) AS sum_Apr#2201L, coalesce(sum(May#2314L), cast(0 as bigint)) AS sum_May#2202L, coalesce(sum(Jun#2315L), cast(0 as bigint)) AS sum_Jun#2203L, coalesce(sum(Jul#2316L), cast(0 as bigint)) AS sum_Jul#2204L, coalesce(sum(Aug#2317L), cast(0 as bigint)) AS sum_Aug#2205L, coalesce(sum(Sep#2318L), cast(0 as bigint)) AS sum_Sep#2206L, coalesce(sum(Oct#2319L), cast(0 as bigint)) AS sum_Oct#2207L, coalesce(sum(Nov#2320L), cast(0 as bigint)) AS sum_Nov#2208L, coalesce(sum(Dec#2321L), cast(0 as bigint)) AS sum_Dec#2209L]\n                        +- Project [hotel_id#2281L, srch_co_month#2185, __pivot_count(1) AS `count(1)`#2309[0] AS Jan#2310L, __pivot_count(1) AS `count(1)`#2309[1] AS Feb#2311L, __pivot_count(1) AS `count(1)`#2309[2] AS Mar#2312L, __pivot_count(1) AS `count(1)`#2309[3] AS Apr#2313L, __pivot_count(1) AS `count(1)`#2309[4] AS May#2314L, __pivot_count(1) AS `count(1)`#2309[5] AS Jun#2315L, __pivot_count(1) AS `count(1)`#2309[6] AS Jul#2316L, __pivot_count(1) AS `count(1)`#2309[7] AS Aug#2317L, __pivot_count(1) AS `count(1)`#2309[8] AS Sep#2318L, __pivot_count(1) AS `count(1)`#2309[9] AS Oct#2319L, __pivot_count(1) AS `count(1)`#2309[10] AS Nov#2320L, __pivot_count(1) AS `count(1)`#2309[11] AS Dec#2321L]\n                           +- Aggregate [hotel_id#2281L, srch_co_month#2185], [hotel_id#2281L, srch_co_month#2185, pivotfirst(srch_ci_month#2184, count(1)#2283L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS __pivot_count(1) AS `count(1)`#2309]\n                              +- Aggregate [hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184], [hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184, count(1) AS count(1)#2283L]\n                                 +- SubqueryAlias __auto_generated_subquery_name\n                                    +- Project [hotel_id#2281L, month(cast(srch_ci#2274 as date)) AS srch_ci_month#2184, month(cast(srch_co#2275 as date)) AS srch_co_month#2185]\n                                       +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                          +- Relation[id#2262L,date_time#2263,site_name#2264,posa_continent#2265,user_location_country#2266,user_location_region#2267,user_location_city#2268,orig_destination_distance#2269,user_id#2270,is_mobile#2271,is_package#2272,channel#2273,srch_ci#2274,srch_co#2275,srch_adults_cnt#2276,srch_children_cnt#2277,srch_rm_cnt#2278,srch_destination_id#2279,srch_destination_type_id#2280,hotel_id#2281L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Jan, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Jan#2211L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#2281L], [hotel_id#2281L, coalesce(sum(Jan#2310L), 0) AS sum_Jan#2211L]\n            +- Aggregate [hotel_id#2281L, srch_co_month#2185], [hotel_id#2281L, pivotfirst(srch_ci_month#2184, count(1)#2283L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)[0] AS Jan#2310L]\n               +- Aggregate [hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184], [hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184, count(1) AS count(1)#2283L]\n                  +- Project [hotel_id#2281L, month(cast(srch_ci#2274 as date)) AS srch_ci_month#2184, month(cast(srch_co#2275 as date)) AS srch_co_month#2185]\n                     +- Relation[id#2262L,date_time#2263,site_name#2264,posa_continent#2265,user_location_country#2266,user_location_region#2267,user_location_city#2268,orig_destination_distance#2269,user_id#2270,is_mobile#2271,is_package#2272,channel#2273,srch_ci#2274,srch_co#2275,srch_adults_cnt#2276,srch_children_cnt#2277,srch_rm_cnt#2278,srch_destination_id#2279,srch_destination_type_id#2280,hotel_id#2281L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#2640L, num_inserted_rows#2641L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Jan, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_Jan#2211L DESC NULLS LAST], output=[hotel_id#2281L,sum_Jan#2211L])\n      +- HashAggregate(keys=[hotel_id#2281L], functions=[finalmerge_sum(merge sum#2385L) AS sum(Jan#2310L)#2322L], output=[hotel_id#2281L, sum_Jan#2211L])\n         +- Exchange hashpartitioning(hotel_id#2281L, 200), ENSURE_REQUIREMENTS, [id=#1038]\n            +- HashAggregate(keys=[hotel_id#2281L], functions=[partial_sum(Jan#2310L) AS sum#2385L], output=[hotel_id#2281L, sum#2385L])\n               +- HashAggregate(keys=[hotel_id#2281L, srch_co_month#2185], functions=[finalmerge_pivotfirst(merge 1#2296L, 2#2297L, 3#2298L, 4#2299L, 5#2300L, 6#2301L, 7#2302L, 8#2303L, 9#2304L, 10#2305L, 11#2306L, 12#2307L) AS pivotfirst(srch_ci_month#2184, count(1)#2283L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)#2308], output=[hotel_id#2281L, Jan#2310L])\n                  +- Exchange hashpartitioning(hotel_id#2281L, srch_co_month#2185, 200), ENSURE_REQUIREMENTS, [id=#1034]\n                     +- HashAggregate(keys=[hotel_id#2281L, srch_co_month#2185], functions=[partial_pivotfirst(srch_ci_month#2184, count(1)#2283L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS (1#2296L, 2#2297L, 3#2298L, 4#2299L, 5#2300L, 6#2301L, 7#2302L, 8#2303L, 9#2304L, 10#2305L, 11#2306L, 12#2307L)], output=[hotel_id#2281L, srch_co_month#2185, 1#2296L, 2#2297L, 3#2298L, 4#2299L, 5#2300L, 6#2301L, 7#2302L, 8#2303L, 9#2304L, 10#2305L, 11#2306L, 12#2307L])\n                        +- HashAggregate(keys=[hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184], functions=[finalmerge_count(merge count#2387L) AS count(1)#2282L], output=[hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184, count(1)#2283L])\n                           +- Exchange hashpartitioning(hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184, 200), ENSURE_REQUIREMENTS, [id=#1030]\n                              +- HashAggregate(keys=[hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184], functions=[partial_count(1) AS count#2387L], output=[hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184, count#2387L])\n                                 +- Project [hotel_id#2281L, month(cast(srch_ci#2274 as date)) AS srch_ci_month#2184, month(cast(srch_co#2275 as date)) AS srch_co_month#2185]\n                                    +- FileScan parquet spark_sql.expedia[srch_ci#2274,srch_co#2275,hotel_id#2281L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_sum_Feb], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;sum_Feb DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;sum_Feb]\n            +- &#39;UnresolvedRelation [expedia_month_sum_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Feb, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Feb#3988L DESC NULLS LAST], true\n         +- Project [hotel_id#3986L, sum_Feb#3988L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_sum_view\n               +- View (`spark_sql`.`expedia_month_sum_view`, [hotel_id#3986L,sum_Jan#3987L,sum_Feb#3988L,sum_Mar#3989L,sum_Apr#3990L,sum_May#3991L,sum_Jun#3992L,sum_Jul#3993L,sum_Aug#3994L,sum_Sep#3995L,sum_Oct#3996L,sum_Nov#3997L,sum_Dec#3998L])\n                  +- Project [cast(hotel_id#4038L as bigint) AS hotel_id#3986L, cast(sum_Jan#3974L as bigint) AS sum_Jan#3987L, cast(sum_Feb#3975L as bigint) AS sum_Feb#3988L, cast(sum_Mar#3976L as bigint) AS sum_Mar#3989L, cast(sum_Apr#3977L as bigint) AS sum_Apr#3990L, cast(sum_May#3978L as bigint) AS sum_May#3991L, cast(sum_Jun#3979L as bigint) AS sum_Jun#3992L, cast(sum_Jul#3980L as bigint) AS sum_Jul#3993L, cast(sum_Aug#3981L as bigint) AS sum_Aug#3994L, cast(sum_Sep#3982L as bigint) AS sum_Sep#3995L, cast(sum_Oct#3983L as bigint) AS sum_Oct#3996L, cast(sum_Nov#3984L as bigint) AS sum_Nov#3997L, cast(sum_Dec#3985L as bigint) AS sum_Dec#3998L]\n                     +- Aggregate [hotel_id#4038L], [hotel_id#4038L, coalesce(sum(Jan#4067L), cast(0 as bigint)) AS sum_Jan#3974L, coalesce(sum(Feb#4068L), cast(0 as bigint)) AS sum_Feb#3975L, coalesce(sum(Mar#4069L), cast(0 as bigint)) AS sum_Mar#3976L, coalesce(sum(Apr#4070L), cast(0 as bigint)) AS sum_Apr#3977L, coalesce(sum(May#4071L), cast(0 as bigint)) AS sum_May#3978L, coalesce(sum(Jun#4072L), cast(0 as bigint)) AS sum_Jun#3979L, coalesce(sum(Jul#4073L), cast(0 as bigint)) AS sum_Jul#3980L, coalesce(sum(Aug#4074L), cast(0 as bigint)) AS sum_Aug#3981L, coalesce(sum(Sep#4075L), cast(0 as bigint)) AS sum_Sep#3982L, coalesce(sum(Oct#4076L), cast(0 as bigint)) AS sum_Oct#3983L, coalesce(sum(Nov#4077L), cast(0 as bigint)) AS sum_Nov#3984L, coalesce(sum(Dec#4078L), cast(0 as bigint)) AS sum_Dec#3985L]\n                        +- Project [hotel_id#4038L, srch_co_month#3961, __pivot_count(1) AS `count(1)`#4066[0] AS Jan#4067L, __pivot_count(1) AS `count(1)`#4066[1] AS Feb#4068L, __pivot_count(1) AS `count(1)`#4066[2] AS Mar#4069L, __pivot_count(1) AS `count(1)`#4066[3] AS Apr#4070L, __pivot_count(1) AS `count(1)`#4066[4] AS May#4071L, __pivot_count(1) AS `count(1)`#4066[5] AS Jun#4072L, __pivot_count(1) AS `count(1)`#4066[6] AS Jul#4073L, __pivot_count(1) AS `count(1)`#4066[7] AS Aug#4074L, __pivot_count(1) AS `count(1)`#4066[8] AS Sep#4075L, __pivot_count(1) AS `count(1)`#4066[9] AS Oct#4076L, __pivot_count(1) AS `count(1)`#4066[10] AS Nov#4077L, __pivot_count(1) AS `count(1)`#4066[11] AS Dec#4078L]\n                           +- Aggregate [hotel_id#4038L, srch_co_month#3961], [hotel_id#4038L, srch_co_month#3961, pivotfirst(srch_ci_month#3960, count(1)#4040L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS __pivot_count(1) AS `count(1)`#4066]\n                              +- Aggregate [hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960], [hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960, count(1) AS count(1)#4040L]\n                                 +- SubqueryAlias __auto_generated_subquery_name\n                                    +- Project [hotel_id#4038L, month(cast(srch_ci#4031 as date)) AS srch_ci_month#3960, month(cast(srch_co#4032 as date)) AS srch_co_month#3961]\n                                       +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                          +- Relation[id#4019L,date_time#4020,site_name#4021,posa_continent#4022,user_location_country#4023,user_location_region#4024,user_location_city#4025,orig_destination_distance#4026,user_id#4027,is_mobile#4028,is_package#4029,channel#4030,srch_ci#4031,srch_co#4032,srch_adults_cnt#4033,srch_children_cnt#4034,srch_rm_cnt#4035,srch_destination_id#4036,srch_destination_type_id#4037,hotel_id#4038L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Feb, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Feb#3988L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#4038L], [hotel_id#4038L, coalesce(sum(Feb#4068L), 0) AS sum_Feb#3988L]\n            +- Aggregate [hotel_id#4038L, srch_co_month#3961], [hotel_id#4038L, pivotfirst(srch_ci_month#3960, count(1)#4040L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)[1] AS Feb#4068L]\n               +- Aggregate [hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960], [hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960, count(1) AS count(1)#4040L]\n                  +- Project [hotel_id#4038L, month(cast(srch_ci#4031 as date)) AS srch_ci_month#3960, month(cast(srch_co#4032 as date)) AS srch_co_month#3961]\n                     +- Relation[id#4019L,date_time#4020,site_name#4021,posa_continent#4022,user_location_country#4023,user_location_region#4024,user_location_city#4025,orig_destination_distance#4026,user_id#4027,is_mobile#4028,is_package#4029,channel#4030,srch_ci#4031,srch_co#4032,srch_adults_cnt#4033,srch_children_cnt#4034,srch_rm_cnt#4035,srch_destination_id#4036,srch_destination_type_id#4037,hotel_id#4038L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#4163L, num_inserted_rows#4164L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Feb, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_Feb#3988L DESC NULLS LAST], output=[hotel_id#4038L,sum_Feb#3988L])\n      +- HashAggregate(keys=[hotel_id#4038L], functions=[finalmerge_sum(merge sum#4142L) AS sum(Feb#4068L)#4080L], output=[hotel_id#4038L, sum_Feb#3988L])\n         +- Exchange hashpartitioning(hotel_id#4038L, 200), ENSURE_REQUIREMENTS, [id=#1953]\n            +- HashAggregate(keys=[hotel_id#4038L], functions=[partial_sum(Feb#4068L) AS sum#4142L], output=[hotel_id#4038L, sum#4142L])\n               +- HashAggregate(keys=[hotel_id#4038L, srch_co_month#3961], functions=[finalmerge_pivotfirst(merge 1#4053L, 2#4054L, 3#4055L, 4#4056L, 5#4057L, 6#4058L, 7#4059L, 8#4060L, 9#4061L, 10#4062L, 11#4063L, 12#4064L) AS pivotfirst(srch_ci_month#3960, count(1)#4040L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)#4065], output=[hotel_id#4038L, Feb#4068L])\n                  +- Exchange hashpartitioning(hotel_id#4038L, srch_co_month#3961, 200), ENSURE_REQUIREMENTS, [id=#1949]\n                     +- HashAggregate(keys=[hotel_id#4038L, srch_co_month#3961], functions=[partial_pivotfirst(srch_ci_month#3960, count(1)#4040L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS (1#4053L, 2#4054L, 3#4055L, 4#4056L, 5#4057L, 6#4058L, 7#4059L, 8#4060L, 9#4061L, 10#4062L, 11#4063L, 12#4064L)], output=[hotel_id#4038L, srch_co_month#3961, 1#4053L, 2#4054L, 3#4055L, 4#4056L, 5#4057L, 6#4058L, 7#4059L, 8#4060L, 9#4061L, 10#4062L, 11#4063L, 12#4064L])\n                        +- HashAggregate(keys=[hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960], functions=[finalmerge_count(merge count#4144L) AS count(1)#4039L], output=[hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960, count(1)#4040L])\n                           +- Exchange hashpartitioning(hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960, 200), ENSURE_REQUIREMENTS, [id=#1945]\n                              +- HashAggregate(keys=[hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960], functions=[partial_count(1) AS count#4144L], output=[hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960, count#4144L])\n                                 +- Project [hotel_id#4038L, month(cast(srch_ci#4031 as date)) AS srch_ci_month#3960, month(cast(srch_co#4032 as date)) AS srch_co_month#3961]\n                                    +- FileScan parquet spark_sql.expedia[srch_ci#4031,srch_co#4032,hotel_id#4038L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_sum_Mar], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;sum_Mar DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;sum_Mar]\n            +- &#39;UnresolvedRelation [expedia_month_sum_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Mar, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Mar#5493L DESC NULLS LAST], true\n         +- Project [hotel_id#5490L, sum_Mar#5493L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_sum_view\n               +- View (`spark_sql`.`expedia_month_sum_view`, [hotel_id#5490L,sum_Jan#5491L,sum_Feb#5492L,sum_Mar#5493L,sum_Apr#5494L,sum_May#5495L,sum_Jun#5496L,sum_Jul#5497L,sum_Aug#5498L,sum_Sep#5499L,sum_Oct#5500L,sum_Nov#5501L,sum_Dec#5502L])\n                  +- Project [cast(hotel_id#5542L as bigint) AS hotel_id#5490L, cast(sum_Jan#5478L as bigint) AS sum_Jan#5491L, cast(sum_Feb#5479L as bigint) AS sum_Feb#5492L, cast(sum_Mar#5480L as bigint) AS sum_Mar#5493L, cast(sum_Apr#5481L as bigint) AS sum_Apr#5494L, cast(sum_May#5482L as bigint) AS sum_May#5495L, cast(sum_Jun#5483L as bigint) AS sum_Jun#5496L, cast(sum_Jul#5484L as bigint) AS sum_Jul#5497L, cast(sum_Aug#5485L as bigint) AS sum_Aug#5498L, cast(sum_Sep#5486L as bigint) AS sum_Sep#5499L, cast(sum_Oct#5487L as bigint) AS sum_Oct#5500L, cast(sum_Nov#5488L as bigint) AS sum_Nov#5501L, cast(sum_Dec#5489L as bigint) AS sum_Dec#5502L]\n                     +- Aggregate [hotel_id#5542L], [hotel_id#5542L, coalesce(sum(Jan#5571L), cast(0 as bigint)) AS sum_Jan#5478L, coalesce(sum(Feb#5572L), cast(0 as bigint)) AS sum_Feb#5479L, coalesce(sum(Mar#5573L), cast(0 as bigint)) AS sum_Mar#5480L, coalesce(sum(Apr#5574L), cast(0 as bigint)) AS sum_Apr#5481L, coalesce(sum(May#5575L), cast(0 as bigint)) AS sum_May#5482L, coalesce(sum(Jun#5576L), cast(0 as bigint)) AS sum_Jun#5483L, coalesce(sum(Jul#5577L), cast(0 as bigint)) AS sum_Jul#5484L, coalesce(sum(Aug#5578L), cast(0 as bigint)) AS sum_Aug#5485L, coalesce(sum(Sep#5579L), cast(0 as bigint)) AS sum_Sep#5486L, coalesce(sum(Oct#5580L), cast(0 as bigint)) AS sum_Oct#5487L, coalesce(sum(Nov#5581L), cast(0 as bigint)) AS sum_Nov#5488L, coalesce(sum(Dec#5582L), cast(0 as bigint)) AS sum_Dec#5489L]\n                        +- Project [hotel_id#5542L, srch_co_month#5465, __pivot_count(1) AS `count(1)`#5570[0] AS Jan#5571L, __pivot_count(1) AS `count(1)`#5570[1] AS Feb#5572L, __pivot_count(1) AS `count(1)`#5570[2] AS Mar#5573L, __pivot_count(1) AS `count(1)`#5570[3] AS Apr#5574L, __pivot_count(1) AS `count(1)`#5570[4] AS May#5575L, __pivot_count(1) AS `count(1)`#5570[5] AS Jun#5576L, __pivot_count(1) AS `count(1)`#5570[6] AS Jul#5577L, __pivot_count(1) AS `count(1)`#5570[7] AS Aug#5578L, __pivot_count(1) AS `count(1)`#5570[8] AS Sep#5579L, __pivot_count(1) AS `count(1)`#5570[9] AS Oct#5580L, __pivot_count(1) AS `count(1)`#5570[10] AS Nov#5581L, __pivot_count(1) AS `count(1)`#5570[11] AS Dec#5582L]\n                           +- Aggregate [hotel_id#5542L, srch_co_month#5465], [hotel_id#5542L, srch_co_month#5465, pivotfirst(srch_ci_month#5464, count(1)#5544L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS __pivot_count(1) AS `count(1)`#5570]\n                              +- Aggregate [hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464], [hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464, count(1) AS count(1)#5544L]\n                                 +- SubqueryAlias __auto_generated_subquery_name\n                                    +- Project [hotel_id#5542L, month(cast(srch_ci#5535 as date)) AS srch_ci_month#5464, month(cast(srch_co#5536 as date)) AS srch_co_month#5465]\n                                       +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                          +- Relation[id#5523L,date_time#5524,site_name#5525,posa_continent#5526,user_location_country#5527,user_location_region#5528,user_location_city#5529,orig_destination_distance#5530,user_id#5531,is_mobile#5532,is_package#5533,channel#5534,srch_ci#5535,srch_co#5536,srch_adults_cnt#5537,srch_children_cnt#5538,srch_rm_cnt#5539,srch_destination_id#5540,srch_destination_type_id#5541,hotel_id#5542L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Mar, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Mar#5493L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#5542L], [hotel_id#5542L, coalesce(sum(Mar#5573L), 0) AS sum_Mar#5493L]\n            +- Aggregate [hotel_id#5542L, srch_co_month#5465], [hotel_id#5542L, pivotfirst(srch_ci_month#5464, count(1)#5544L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)[2] AS Mar#5573L]\n               +- Aggregate [hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464], [hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464, count(1) AS count(1)#5544L]\n                  +- Project [hotel_id#5542L, month(cast(srch_ci#5535 as date)) AS srch_ci_month#5464, month(cast(srch_co#5536 as date)) AS srch_co_month#5465]\n                     +- Relation[id#5523L,date_time#5524,site_name#5525,posa_continent#5526,user_location_country#5527,user_location_region#5528,user_location_city#5529,orig_destination_distance#5530,user_id#5531,is_mobile#5532,is_package#5533,channel#5534,srch_ci#5535,srch_co#5536,srch_adults_cnt#5537,srch_children_cnt#5538,srch_rm_cnt#5539,srch_destination_id#5540,srch_destination_type_id#5541,hotel_id#5542L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#5667L, num_inserted_rows#5668L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Mar, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_Mar#5493L DESC NULLS LAST], output=[hotel_id#5542L,sum_Mar#5493L])\n      +- HashAggregate(keys=[hotel_id#5542L], functions=[finalmerge_sum(merge sum#5646L) AS sum(Mar#5573L)#5585L], output=[hotel_id#5542L, sum_Mar#5493L])\n         +- Exchange hashpartitioning(hotel_id#5542L, 200), ENSURE_REQUIREMENTS, [id=#2868]\n            +- HashAggregate(keys=[hotel_id#5542L], functions=[partial_sum(Mar#5573L) AS sum#5646L], output=[hotel_id#5542L, sum#5646L])\n               +- HashAggregate(keys=[hotel_id#5542L, srch_co_month#5465], functions=[finalmerge_pivotfirst(merge 1#5557L, 2#5558L, 3#5559L, 4#5560L, 5#5561L, 6#5562L, 7#5563L, 8#5564L, 9#5565L, 10#5566L, 11#5567L, 12#5568L) AS pivotfirst(srch_ci_month#5464, count(1)#5544L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)#5569], output=[hotel_id#5542L, Mar#5573L])\n                  +- Exchange hashpartitioning(hotel_id#5542L, srch_co_month#5465, 200), ENSURE_REQUIREMENTS, [id=#2864]\n                     +- HashAggregate(keys=[hotel_id#5542L, srch_co_month#5465], functions=[partial_pivotfirst(srch_ci_month#5464, count(1)#5544L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS (1#5557L, 2#5558L, 3#5559L, 4#5560L, 5#5561L, 6#5562L, 7#5563L, 8#5564L, 9#5565L, 10#5566L, 11#5567L, 12#5568L)], output=[hotel_id#5542L, srch_co_month#5465, 1#5557L, 2#5558L, 3#5559L, 4#5560L, 5#5561L, 6#5562L, 7#5563L, 8#5564L, 9#5565L, 10#5566L, 11#5567L, 12#5568L])\n                        +- HashAggregate(keys=[hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464], functions=[finalmerge_count(merge count#5648L) AS count(1)#5543L], output=[hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464, count(1)#5544L])\n                           +- Exchange hashpartitioning(hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464, 200), ENSURE_REQUIREMENTS, [id=#2860]\n                              +- HashAggregate(keys=[hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464], functions=[partial_count(1) AS count#5648L], output=[hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464, count#5648L])\n\n*** WARNING: skipped 54421 bytes of output ***\n\n                     +- Aggregate [hotel_id#16070L], [hotel_id#16070L, coalesce(sum(Jan#16099L), cast(0 as bigint)) AS sum_Jan#16006L, coalesce(sum(Feb#16100L), cast(0 as bigint)) AS sum_Feb#16007L, coalesce(sum(Mar#16101L), cast(0 as bigint)) AS sum_Mar#16008L, coalesce(sum(Apr#16102L), cast(0 as bigint)) AS sum_Apr#16009L, coalesce(sum(May#16103L), cast(0 as bigint)) AS sum_May#16010L, coalesce(sum(Jun#16104L), cast(0 as bigint)) AS sum_Jun#16011L, coalesce(sum(Jul#16105L), cast(0 as bigint)) AS sum_Jul#16012L, coalesce(sum(Aug#16106L), cast(0 as bigint)) AS sum_Aug#16013L, coalesce(sum(Sep#16107L), cast(0 as bigint)) AS sum_Sep#16014L, coalesce(sum(Oct#16108L), cast(0 as bigint)) AS sum_Oct#16015L, coalesce(sum(Nov#16109L), cast(0 as bigint)) AS sum_Nov#16016L, coalesce(sum(Dec#16110L), cast(0 as bigint)) AS sum_Dec#16017L]\n                        +- Project [hotel_id#16070L, srch_co_month#15993, __pivot_count(1) AS `count(1)`#16098[0] AS Jan#16099L, __pivot_count(1) AS `count(1)`#16098[1] AS Feb#16100L, __pivot_count(1) AS `count(1)`#16098[2] AS Mar#16101L, __pivot_count(1) AS `count(1)`#16098[3] AS Apr#16102L, __pivot_count(1) AS `count(1)`#16098[4] AS May#16103L, __pivot_count(1) AS `count(1)`#16098[5] AS Jun#16104L, __pivot_count(1) AS `count(1)`#16098[6] AS Jul#16105L, __pivot_count(1) AS `count(1)`#16098[7] AS Aug#16106L, __pivot_count(1) AS `count(1)`#16098[8] AS Sep#16107L, __pivot_count(1) AS `count(1)`#16098[9] AS Oct#16108L, __pivot_count(1) AS `count(1)`#16098[10] AS Nov#16109L, __pivot_count(1) AS `count(1)`#16098[11] AS Dec#16110L]\n                           +- Aggregate [hotel_id#16070L, srch_co_month#15993], [hotel_id#16070L, srch_co_month#15993, pivotfirst(srch_ci_month#15992, count(1)#16072L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS __pivot_count(1) AS `count(1)`#16098]\n                              +- Aggregate [hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992], [hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992, count(1) AS count(1)#16072L]\n                                 +- SubqueryAlias __auto_generated_subquery_name\n                                    +- Project [hotel_id#16070L, month(cast(srch_ci#16063 as date)) AS srch_ci_month#15992, month(cast(srch_co#16064 as date)) AS srch_co_month#15993]\n                                       +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                          +- Relation[id#16051L,date_time#16052,site_name#16053,posa_continent#16054,user_location_country#16055,user_location_region#16056,user_location_city#16057,orig_destination_distance#16058,user_id#16059,is_mobile#16060,is_package#16061,channel#16062,srch_ci#16063,srch_co#16064,srch_adults_cnt#16065,srch_children_cnt#16066,srch_rm_cnt#16067,srch_destination_id#16068,srch_destination_type_id#16069,hotel_id#16070L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Oct, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Oct#16028L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#16070L], [hotel_id#16070L, coalesce(sum(Oct#16108L), 0) AS sum_Oct#16028L]\n            +- Aggregate [hotel_id#16070L, srch_co_month#15993], [hotel_id#16070L, pivotfirst(srch_ci_month#15992, count(1)#16072L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)[9] AS Oct#16108L]\n               +- Aggregate [hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992], [hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992, count(1) AS count(1)#16072L]\n                  +- Project [hotel_id#16070L, month(cast(srch_ci#16063 as date)) AS srch_ci_month#15992, month(cast(srch_co#16064 as date)) AS srch_co_month#15993]\n                     +- Relation[id#16051L,date_time#16052,site_name#16053,posa_continent#16054,user_location_country#16055,user_location_region#16056,user_location_city#16057,orig_destination_distance#16058,user_id#16059,is_mobile#16060,is_package#16061,channel#16062,srch_ci#16063,srch_co#16064,srch_adults_cnt#16065,srch_children_cnt#16066,srch_rm_cnt#16067,srch_destination_id#16068,srch_destination_type_id#16069,hotel_id#16070L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#16195L, num_inserted_rows#16196L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Oct, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_Oct#16028L DESC NULLS LAST], output=[hotel_id#16070L,sum_Oct#16028L])\n      +- HashAggregate(keys=[hotel_id#16070L], functions=[finalmerge_sum(merge sum#16174L) AS sum(Oct#16108L)#16120L], output=[hotel_id#16070L, sum_Oct#16028L])\n         +- Exchange hashpartitioning(hotel_id#16070L, 200), ENSURE_REQUIREMENTS, [id=#9273]\n            +- HashAggregate(keys=[hotel_id#16070L], functions=[partial_sum(Oct#16108L) AS sum#16174L], output=[hotel_id#16070L, sum#16174L])\n               +- HashAggregate(keys=[hotel_id#16070L, srch_co_month#15993], functions=[finalmerge_pivotfirst(merge 1#16085L, 2#16086L, 3#16087L, 4#16088L, 5#16089L, 6#16090L, 7#16091L, 8#16092L, 9#16093L, 10#16094L, 11#16095L, 12#16096L) AS pivotfirst(srch_ci_month#15992, count(1)#16072L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)#16097], output=[hotel_id#16070L, Oct#16108L])\n                  +- Exchange hashpartitioning(hotel_id#16070L, srch_co_month#15993, 200), ENSURE_REQUIREMENTS, [id=#9269]\n                     +- HashAggregate(keys=[hotel_id#16070L, srch_co_month#15993], functions=[partial_pivotfirst(srch_ci_month#15992, count(1)#16072L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS (1#16085L, 2#16086L, 3#16087L, 4#16088L, 5#16089L, 6#16090L, 7#16091L, 8#16092L, 9#16093L, 10#16094L, 11#16095L, 12#16096L)], output=[hotel_id#16070L, srch_co_month#15993, 1#16085L, 2#16086L, 3#16087L, 4#16088L, 5#16089L, 6#16090L, 7#16091L, 8#16092L, 9#16093L, 10#16094L, 11#16095L, 12#16096L])\n                        +- HashAggregate(keys=[hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992], functions=[finalmerge_count(merge count#16176L) AS count(1)#16071L], output=[hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992, count(1)#16072L])\n                           +- Exchange hashpartitioning(hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992, 200), ENSURE_REQUIREMENTS, [id=#9265]\n                              +- HashAggregate(keys=[hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992], functions=[partial_count(1) AS count#16176L], output=[hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992, count#16176L])\n                                 +- Project [hotel_id#16070L, month(cast(srch_ci#16063 as date)) AS srch_ci_month#15992, month(cast(srch_co#16064 as date)) AS srch_co_month#15993]\n                                    +- FileScan parquet spark_sql.expedia[srch_ci#16063,srch_co#16064,hotel_id#16070L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_sum_Nov], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;sum_Nov DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;sum_Nov]\n            +- &#39;UnresolvedRelation [expedia_month_sum_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Nov, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Nov#17533L DESC NULLS LAST], true\n         +- Project [hotel_id#17522L, sum_Nov#17533L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_sum_view\n               +- View (`spark_sql`.`expedia_month_sum_view`, [hotel_id#17522L,sum_Jan#17523L,sum_Feb#17524L,sum_Mar#17525L,sum_Apr#17526L,sum_May#17527L,sum_Jun#17528L,sum_Jul#17529L,sum_Aug#17530L,sum_Sep#17531L,sum_Oct#17532L,sum_Nov#17533L,sum_Dec#17534L])\n                  +- Project [cast(hotel_id#17574L as bigint) AS hotel_id#17522L, cast(sum_Jan#17510L as bigint) AS sum_Jan#17523L, cast(sum_Feb#17511L as bigint) AS sum_Feb#17524L, cast(sum_Mar#17512L as bigint) AS sum_Mar#17525L, cast(sum_Apr#17513L as bigint) AS sum_Apr#17526L, cast(sum_May#17514L as bigint) AS sum_May#17527L, cast(sum_Jun#17515L as bigint) AS sum_Jun#17528L, cast(sum_Jul#17516L as bigint) AS sum_Jul#17529L, cast(sum_Aug#17517L as bigint) AS sum_Aug#17530L, cast(sum_Sep#17518L as bigint) AS sum_Sep#17531L, cast(sum_Oct#17519L as bigint) AS sum_Oct#17532L, cast(sum_Nov#17520L as bigint) AS sum_Nov#17533L, cast(sum_Dec#17521L as bigint) AS sum_Dec#17534L]\n                     +- Aggregate [hotel_id#17574L], [hotel_id#17574L, coalesce(sum(Jan#17603L), cast(0 as bigint)) AS sum_Jan#17510L, coalesce(sum(Feb#17604L), cast(0 as bigint)) AS sum_Feb#17511L, coalesce(sum(Mar#17605L), cast(0 as bigint)) AS sum_Mar#17512L, coalesce(sum(Apr#17606L), cast(0 as bigint)) AS sum_Apr#17513L, coalesce(sum(May#17607L), cast(0 as bigint)) AS sum_May#17514L, coalesce(sum(Jun#17608L), cast(0 as bigint)) AS sum_Jun#17515L, coalesce(sum(Jul#17609L), cast(0 as bigint)) AS sum_Jul#17516L, coalesce(sum(Aug#17610L), cast(0 as bigint)) AS sum_Aug#17517L, coalesce(sum(Sep#17611L), cast(0 as bigint)) AS sum_Sep#17518L, coalesce(sum(Oct#17612L), cast(0 as bigint)) AS sum_Oct#17519L, coalesce(sum(Nov#17613L), cast(0 as bigint)) AS sum_Nov#17520L, coalesce(sum(Dec#17614L), cast(0 as bigint)) AS sum_Dec#17521L]\n                        +- Project [hotel_id#17574L, srch_co_month#17497, __pivot_count(1) AS `count(1)`#17602[0] AS Jan#17603L, __pivot_count(1) AS `count(1)`#17602[1] AS Feb#17604L, __pivot_count(1) AS `count(1)`#17602[2] AS Mar#17605L, __pivot_count(1) AS `count(1)`#17602[3] AS Apr#17606L, __pivot_count(1) AS `count(1)`#17602[4] AS May#17607L, __pivot_count(1) AS `count(1)`#17602[5] AS Jun#17608L, __pivot_count(1) AS `count(1)`#17602[6] AS Jul#17609L, __pivot_count(1) AS `count(1)`#17602[7] AS Aug#17610L, __pivot_count(1) AS `count(1)`#17602[8] AS Sep#17611L, __pivot_count(1) AS `count(1)`#17602[9] AS Oct#17612L, __pivot_count(1) AS `count(1)`#17602[10] AS Nov#17613L, __pivot_count(1) AS `count(1)`#17602[11] AS Dec#17614L]\n                           +- Aggregate [hotel_id#17574L, srch_co_month#17497], [hotel_id#17574L, srch_co_month#17497, pivotfirst(srch_ci_month#17496, count(1)#17576L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS __pivot_count(1) AS `count(1)`#17602]\n                              +- Aggregate [hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496], [hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496, count(1) AS count(1)#17576L]\n                                 +- SubqueryAlias __auto_generated_subquery_name\n                                    +- Project [hotel_id#17574L, month(cast(srch_ci#17567 as date)) AS srch_ci_month#17496, month(cast(srch_co#17568 as date)) AS srch_co_month#17497]\n                                       +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                          +- Relation[id#17555L,date_time#17556,site_name#17557,posa_continent#17558,user_location_country#17559,user_location_region#17560,user_location_city#17561,orig_destination_distance#17562,user_id#17563,is_mobile#17564,is_package#17565,channel#17566,srch_ci#17567,srch_co#17568,srch_adults_cnt#17569,srch_children_cnt#17570,srch_rm_cnt#17571,srch_destination_id#17572,srch_destination_type_id#17573,hotel_id#17574L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Nov, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Nov#17533L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#17574L], [hotel_id#17574L, coalesce(sum(Nov#17613L), 0) AS sum_Nov#17533L]\n            +- Aggregate [hotel_id#17574L, srch_co_month#17497], [hotel_id#17574L, pivotfirst(srch_ci_month#17496, count(1)#17576L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)[10] AS Nov#17613L]\n               +- Aggregate [hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496], [hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496, count(1) AS count(1)#17576L]\n                  +- Project [hotel_id#17574L, month(cast(srch_ci#17567 as date)) AS srch_ci_month#17496, month(cast(srch_co#17568 as date)) AS srch_co_month#17497]\n                     +- Relation[id#17555L,date_time#17556,site_name#17557,posa_continent#17558,user_location_country#17559,user_location_region#17560,user_location_city#17561,orig_destination_distance#17562,user_id#17563,is_mobile#17564,is_package#17565,channel#17566,srch_ci#17567,srch_co#17568,srch_adults_cnt#17569,srch_children_cnt#17570,srch_rm_cnt#17571,srch_destination_id#17572,srch_destination_type_id#17573,hotel_id#17574L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#17699L, num_inserted_rows#17700L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Nov, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_Nov#17533L DESC NULLS LAST], output=[hotel_id#17574L,sum_Nov#17533L])\n      +- HashAggregate(keys=[hotel_id#17574L], functions=[finalmerge_sum(merge sum#17678L) AS sum(Nov#17613L)#17625L], output=[hotel_id#17574L, sum_Nov#17533L])\n         +- Exchange hashpartitioning(hotel_id#17574L, 200), ENSURE_REQUIREMENTS, [id=#10188]\n            +- HashAggregate(keys=[hotel_id#17574L], functions=[partial_sum(Nov#17613L) AS sum#17678L], output=[hotel_id#17574L, sum#17678L])\n               +- HashAggregate(keys=[hotel_id#17574L, srch_co_month#17497], functions=[finalmerge_pivotfirst(merge 1#17589L, 2#17590L, 3#17591L, 4#17592L, 5#17593L, 6#17594L, 7#17595L, 8#17596L, 9#17597L, 10#17598L, 11#17599L, 12#17600L) AS pivotfirst(srch_ci_month#17496, count(1)#17576L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)#17601], output=[hotel_id#17574L, Nov#17613L])\n                  +- Exchange hashpartitioning(hotel_id#17574L, srch_co_month#17497, 200), ENSURE_REQUIREMENTS, [id=#10184]\n                     +- HashAggregate(keys=[hotel_id#17574L, srch_co_month#17497], functions=[partial_pivotfirst(srch_ci_month#17496, count(1)#17576L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS (1#17589L, 2#17590L, 3#17591L, 4#17592L, 5#17593L, 6#17594L, 7#17595L, 8#17596L, 9#17597L, 10#17598L, 11#17599L, 12#17600L)], output=[hotel_id#17574L, srch_co_month#17497, 1#17589L, 2#17590L, 3#17591L, 4#17592L, 5#17593L, 6#17594L, 7#17595L, 8#17596L, 9#17597L, 10#17598L, 11#17599L, 12#17600L])\n                        +- HashAggregate(keys=[hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496], functions=[finalmerge_count(merge count#17680L) AS count(1)#17575L], output=[hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496, count(1)#17576L])\n                           +- Exchange hashpartitioning(hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496, 200), ENSURE_REQUIREMENTS, [id=#10180]\n                              +- HashAggregate(keys=[hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496], functions=[partial_count(1) AS count#17680L], output=[hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496, count#17680L])\n                                 +- Project [hotel_id#17574L, month(cast(srch_ci#17567 as date)) AS srch_ci_month#17496, month(cast(srch_co#17568 as date)) AS srch_co_month#17497]\n                                    +- FileScan parquet spark_sql.expedia[srch_ci#17567,srch_co#17568,hotel_id#17574L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_sum_Dec], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;sum_Dec DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;sum_Dec]\n            +- &#39;UnresolvedRelation [expedia_month_sum_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Dec, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Dec#19038L DESC NULLS LAST], true\n         +- Project [hotel_id#19026L, sum_Dec#19038L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_sum_view\n               +- View (`spark_sql`.`expedia_month_sum_view`, [hotel_id#19026L,sum_Jan#19027L,sum_Feb#19028L,sum_Mar#19029L,sum_Apr#19030L,sum_May#19031L,sum_Jun#19032L,sum_Jul#19033L,sum_Aug#19034L,sum_Sep#19035L,sum_Oct#19036L,sum_Nov#19037L,sum_Dec#19038L])\n                  +- Project [cast(hotel_id#19078L as bigint) AS hotel_id#19026L, cast(sum_Jan#19014L as bigint) AS sum_Jan#19027L, cast(sum_Feb#19015L as bigint) AS sum_Feb#19028L, cast(sum_Mar#19016L as bigint) AS sum_Mar#19029L, cast(sum_Apr#19017L as bigint) AS sum_Apr#19030L, cast(sum_May#19018L as bigint) AS sum_May#19031L, cast(sum_Jun#19019L as bigint) AS sum_Jun#19032L, cast(sum_Jul#19020L as bigint) AS sum_Jul#19033L, cast(sum_Aug#19021L as bigint) AS sum_Aug#19034L, cast(sum_Sep#19022L as bigint) AS sum_Sep#19035L, cast(sum_Oct#19023L as bigint) AS sum_Oct#19036L, cast(sum_Nov#19024L as bigint) AS sum_Nov#19037L, cast(sum_Dec#19025L as bigint) AS sum_Dec#19038L]\n                     +- Aggregate [hotel_id#19078L], [hotel_id#19078L, coalesce(sum(Jan#19107L), cast(0 as bigint)) AS sum_Jan#19014L, coalesce(sum(Feb#19108L), cast(0 as bigint)) AS sum_Feb#19015L, coalesce(sum(Mar#19109L), cast(0 as bigint)) AS sum_Mar#19016L, coalesce(sum(Apr#19110L), cast(0 as bigint)) AS sum_Apr#19017L, coalesce(sum(May#19111L), cast(0 as bigint)) AS sum_May#19018L, coalesce(sum(Jun#19112L), cast(0 as bigint)) AS sum_Jun#19019L, coalesce(sum(Jul#19113L), cast(0 as bigint)) AS sum_Jul#19020L, coalesce(sum(Aug#19114L), cast(0 as bigint)) AS sum_Aug#19021L, coalesce(sum(Sep#19115L), cast(0 as bigint)) AS sum_Sep#19022L, coalesce(sum(Oct#19116L), cast(0 as bigint)) AS sum_Oct#19023L, coalesce(sum(Nov#19117L), cast(0 as bigint)) AS sum_Nov#19024L, coalesce(sum(Dec#19118L), cast(0 as bigint)) AS sum_Dec#19025L]\n                        +- Project [hotel_id#19078L, srch_co_month#19001, __pivot_count(1) AS `count(1)`#19106[0] AS Jan#19107L, __pivot_count(1) AS `count(1)`#19106[1] AS Feb#19108L, __pivot_count(1) AS `count(1)`#19106[2] AS Mar#19109L, __pivot_count(1) AS `count(1)`#19106[3] AS Apr#19110L, __pivot_count(1) AS `count(1)`#19106[4] AS May#19111L, __pivot_count(1) AS `count(1)`#19106[5] AS Jun#19112L, __pivot_count(1) AS `count(1)`#19106[6] AS Jul#19113L, __pivot_count(1) AS `count(1)`#19106[7] AS Aug#19114L, __pivot_count(1) AS `count(1)`#19106[8] AS Sep#19115L, __pivot_count(1) AS `count(1)`#19106[9] AS Oct#19116L, __pivot_count(1) AS `count(1)`#19106[10] AS Nov#19117L, __pivot_count(1) AS `count(1)`#19106[11] AS Dec#19118L]\n                           +- Aggregate [hotel_id#19078L, srch_co_month#19001], [hotel_id#19078L, srch_co_month#19001, pivotfirst(srch_ci_month#19000, count(1)#19080L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS __pivot_count(1) AS `count(1)`#19106]\n                              +- Aggregate [hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000], [hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000, count(1) AS count(1)#19080L]\n                                 +- SubqueryAlias __auto_generated_subquery_name\n                                    +- Project [hotel_id#19078L, month(cast(srch_ci#19071 as date)) AS srch_ci_month#19000, month(cast(srch_co#19072 as date)) AS srch_co_month#19001]\n                                       +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                          +- Relation[id#19059L,date_time#19060,site_name#19061,posa_continent#19062,user_location_country#19063,user_location_region#19064,user_location_city#19065,orig_destination_distance#19066,user_id#19067,is_mobile#19068,is_package#19069,channel#19070,srch_ci#19071,srch_co#19072,srch_adults_cnt#19073,srch_children_cnt#19074,srch_rm_cnt#19075,srch_destination_id#19076,srch_destination_type_id#19077,hotel_id#19078L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Dec, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Dec#19038L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#19078L], [hotel_id#19078L, coalesce(sum(Dec#19118L), 0) AS sum_Dec#19038L]\n            +- Aggregate [hotel_id#19078L, srch_co_month#19001], [hotel_id#19078L, pivotfirst(srch_ci_month#19000, count(1)#19080L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)[11] AS Dec#19118L]\n               +- Aggregate [hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000], [hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000, count(1) AS count(1)#19080L]\n                  +- Project [hotel_id#19078L, month(cast(srch_ci#19071 as date)) AS srch_ci_month#19000, month(cast(srch_co#19072 as date)) AS srch_co_month#19001]\n                     +- Relation[id#19059L,date_time#19060,site_name#19061,posa_continent#19062,user_location_country#19063,user_location_region#19064,user_location_city#19065,orig_destination_distance#19066,user_id#19067,is_mobile#19068,is_package#19069,channel#19070,srch_ci#19071,srch_co#19072,srch_adults_cnt#19073,srch_children_cnt#19074,srch_rm_cnt#19075,srch_destination_id#19076,srch_destination_type_id#19077,hotel_id#19078L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#19203L, num_inserted_rows#19204L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Dec, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_Dec#19038L DESC NULLS LAST], output=[hotel_id#19078L,sum_Dec#19038L])\n      +- HashAggregate(keys=[hotel_id#19078L], functions=[finalmerge_sum(merge sum#19182L) AS sum(Dec#19118L)#19130L], output=[hotel_id#19078L, sum_Dec#19038L])\n         +- Exchange hashpartitioning(hotel_id#19078L, 200), ENSURE_REQUIREMENTS, [id=#11103]\n            +- HashAggregate(keys=[hotel_id#19078L], functions=[partial_sum(Dec#19118L) AS sum#19182L], output=[hotel_id#19078L, sum#19182L])\n               +- HashAggregate(keys=[hotel_id#19078L, srch_co_month#19001], functions=[finalmerge_pivotfirst(merge 1#19093L, 2#19094L, 3#19095L, 4#19096L, 5#19097L, 6#19098L, 7#19099L, 8#19100L, 9#19101L, 10#19102L, 11#19103L, 12#19104L) AS pivotfirst(srch_ci_month#19000, count(1)#19080L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)#19105], output=[hotel_id#19078L, Dec#19118L])\n                  +- Exchange hashpartitioning(hotel_id#19078L, srch_co_month#19001, 200), ENSURE_REQUIREMENTS, [id=#11099]\n                     +- HashAggregate(keys=[hotel_id#19078L, srch_co_month#19001], functions=[partial_pivotfirst(srch_ci_month#19000, count(1)#19080L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS (1#19093L, 2#19094L, 3#19095L, 4#19096L, 5#19097L, 6#19098L, 7#19099L, 8#19100L, 9#19101L, 10#19102L, 11#19103L, 12#19104L)], output=[hotel_id#19078L, srch_co_month#19001, 1#19093L, 2#19094L, 3#19095L, 4#19096L, 5#19097L, 6#19098L, 7#19099L, 8#19100L, 9#19101L, 10#19102L, 11#19103L, 12#19104L])\n                        +- HashAggregate(keys=[hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000], functions=[finalmerge_count(merge count#19184L) AS count(1)#19079L], output=[hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000, count(1)#19080L])\n                           +- Exchange hashpartitioning(hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000, 200), ENSURE_REQUIREMENTS, [id=#11095]\n                              +- HashAggregate(keys=[hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000], functions=[partial_count(1) AS count#19184L], output=[hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000, count#19184L])\n                                 +- Project [hotel_id#19078L, month(cast(srch_ci#19071 as date)) AS srch_ci_month#19000, month(cast(srch_co#19072 as date)) AS srch_co_month#19001]\n                                    +- FileScan parquet spark_sql.expedia[srch_ci#19071,srch_co#19072,hotel_id#19078L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_sum_Jan], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;sum_Jan DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;sum_Jan]\n            +- &#39;UnresolvedRelation [expedia_month_sum_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Jan, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Jan#2211L DESC NULLS LAST], true\n         +- Project [hotel_id#2210L, sum_Jan#2211L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_sum_view\n               +- View (`spark_sql`.`expedia_month_sum_view`, [hotel_id#2210L,sum_Jan#2211L,sum_Feb#2212L,sum_Mar#2213L,sum_Apr#2214L,sum_May#2215L,sum_Jun#2216L,sum_Jul#2217L,sum_Aug#2218L,sum_Sep#2219L,sum_Oct#2220L,sum_Nov#2221L,sum_Dec#2222L])\n                  +- Project [cast(hotel_id#2281L as bigint) AS hotel_id#2210L, cast(sum_Jan#2198L as bigint) AS sum_Jan#2211L, cast(sum_Feb#2199L as bigint) AS sum_Feb#2212L, cast(sum_Mar#2200L as bigint) AS sum_Mar#2213L, cast(sum_Apr#2201L as bigint) AS sum_Apr#2214L, cast(sum_May#2202L as bigint) AS sum_May#2215L, cast(sum_Jun#2203L as bigint) AS sum_Jun#2216L, cast(sum_Jul#2204L as bigint) AS sum_Jul#2217L, cast(sum_Aug#2205L as bigint) AS sum_Aug#2218L, cast(sum_Sep#2206L as bigint) AS sum_Sep#2219L, cast(sum_Oct#2207L as bigint) AS sum_Oct#2220L, cast(sum_Nov#2208L as bigint) AS sum_Nov#2221L, cast(sum_Dec#2209L as bigint) AS sum_Dec#2222L]\n                     +- Aggregate [hotel_id#2281L], [hotel_id#2281L, coalesce(sum(Jan#2310L), cast(0 as bigint)) AS sum_Jan#2198L, coalesce(sum(Feb#2311L), cast(0 as bigint)) AS sum_Feb#2199L, coalesce(sum(Mar#2312L), cast(0 as bigint)) AS sum_Mar#2200L, coalesce(sum(Apr#2313L), cast(0 as bigint)) AS sum_Apr#2201L, coalesce(sum(May#2314L), cast(0 as bigint)) AS sum_May#2202L, coalesce(sum(Jun#2315L), cast(0 as bigint)) AS sum_Jun#2203L, coalesce(sum(Jul#2316L), cast(0 as bigint)) AS sum_Jul#2204L, coalesce(sum(Aug#2317L), cast(0 as bigint)) AS sum_Aug#2205L, coalesce(sum(Sep#2318L), cast(0 as bigint)) AS sum_Sep#2206L, coalesce(sum(Oct#2319L), cast(0 as bigint)) AS sum_Oct#2207L, coalesce(sum(Nov#2320L), cast(0 as bigint)) AS sum_Nov#2208L, coalesce(sum(Dec#2321L), cast(0 as bigint)) AS sum_Dec#2209L]\n                        +- Project [hotel_id#2281L, srch_co_month#2185, __pivot_count(1) AS `count(1)`#2309[0] AS Jan#2310L, __pivot_count(1) AS `count(1)`#2309[1] AS Feb#2311L, __pivot_count(1) AS `count(1)`#2309[2] AS Mar#2312L, __pivot_count(1) AS `count(1)`#2309[3] AS Apr#2313L, __pivot_count(1) AS `count(1)`#2309[4] AS May#2314L, __pivot_count(1) AS `count(1)`#2309[5] AS Jun#2315L, __pivot_count(1) AS `count(1)`#2309[6] AS Jul#2316L, __pivot_count(1) AS `count(1)`#2309[7] AS Aug#2317L, __pivot_count(1) AS `count(1)`#2309[8] AS Sep#2318L, __pivot_count(1) AS `count(1)`#2309[9] AS Oct#2319L, __pivot_count(1) AS `count(1)`#2309[10] AS Nov#2320L, __pivot_count(1) AS `count(1)`#2309[11] AS Dec#2321L]\n                           +- Aggregate [hotel_id#2281L, srch_co_month#2185], [hotel_id#2281L, srch_co_month#2185, pivotfirst(srch_ci_month#2184, count(1)#2283L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS __pivot_count(1) AS `count(1)`#2309]\n                              +- Aggregate [hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184], [hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184, count(1) AS count(1)#2283L]\n                                 +- SubqueryAlias __auto_generated_subquery_name\n                                    +- Project [hotel_id#2281L, month(cast(srch_ci#2274 as date)) AS srch_ci_month#2184, month(cast(srch_co#2275 as date)) AS srch_co_month#2185]\n                                       +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                          +- Relation[id#2262L,date_time#2263,site_name#2264,posa_continent#2265,user_location_country#2266,user_location_region#2267,user_location_city#2268,orig_destination_distance#2269,user_id#2270,is_mobile#2271,is_package#2272,channel#2273,srch_ci#2274,srch_co#2275,srch_adults_cnt#2276,srch_children_cnt#2277,srch_rm_cnt#2278,srch_destination_id#2279,srch_destination_type_id#2280,hotel_id#2281L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Jan, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Jan#2211L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#2281L], [hotel_id#2281L, coalesce(sum(Jan#2310L), 0) AS sum_Jan#2211L]\n            +- Aggregate [hotel_id#2281L, srch_co_month#2185], [hotel_id#2281L, pivotfirst(srch_ci_month#2184, count(1)#2283L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)[0] AS Jan#2310L]\n               +- Aggregate [hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184], [hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184, count(1) AS count(1)#2283L]\n                  +- Project [hotel_id#2281L, month(cast(srch_ci#2274 as date)) AS srch_ci_month#2184, month(cast(srch_co#2275 as date)) AS srch_co_month#2185]\n                     +- Relation[id#2262L,date_time#2263,site_name#2264,posa_continent#2265,user_location_country#2266,user_location_region#2267,user_location_city#2268,orig_destination_distance#2269,user_id#2270,is_mobile#2271,is_package#2272,channel#2273,srch_ci#2274,srch_co#2275,srch_adults_cnt#2276,srch_children_cnt#2277,srch_rm_cnt#2278,srch_destination_id#2279,srch_destination_type_id#2280,hotel_id#2281L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#2640L, num_inserted_rows#2641L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Jan, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_Jan#2211L DESC NULLS LAST], output=[hotel_id#2281L,sum_Jan#2211L])\n      +- HashAggregate(keys=[hotel_id#2281L], functions=[finalmerge_sum(merge sum#2385L) AS sum(Jan#2310L)#2322L], output=[hotel_id#2281L, sum_Jan#2211L])\n         +- Exchange hashpartitioning(hotel_id#2281L, 200), ENSURE_REQUIREMENTS, [id=#1038]\n            +- HashAggregate(keys=[hotel_id#2281L], functions=[partial_sum(Jan#2310L) AS sum#2385L], output=[hotel_id#2281L, sum#2385L])\n               +- HashAggregate(keys=[hotel_id#2281L, srch_co_month#2185], functions=[finalmerge_pivotfirst(merge 1#2296L, 2#2297L, 3#2298L, 4#2299L, 5#2300L, 6#2301L, 7#2302L, 8#2303L, 9#2304L, 10#2305L, 11#2306L, 12#2307L) AS pivotfirst(srch_ci_month#2184, count(1)#2283L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)#2308], output=[hotel_id#2281L, Jan#2310L])\n                  +- Exchange hashpartitioning(hotel_id#2281L, srch_co_month#2185, 200), ENSURE_REQUIREMENTS, [id=#1034]\n                     +- HashAggregate(keys=[hotel_id#2281L, srch_co_month#2185], functions=[partial_pivotfirst(srch_ci_month#2184, count(1)#2283L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS (1#2296L, 2#2297L, 3#2298L, 4#2299L, 5#2300L, 6#2301L, 7#2302L, 8#2303L, 9#2304L, 10#2305L, 11#2306L, 12#2307L)], output=[hotel_id#2281L, srch_co_month#2185, 1#2296L, 2#2297L, 3#2298L, 4#2299L, 5#2300L, 6#2301L, 7#2302L, 8#2303L, 9#2304L, 10#2305L, 11#2306L, 12#2307L])\n                        +- HashAggregate(keys=[hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184], functions=[finalmerge_count(merge count#2387L) AS count(1)#2282L], output=[hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184, count(1)#2283L])\n                           +- Exchange hashpartitioning(hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184, 200), ENSURE_REQUIREMENTS, [id=#1030]\n                              +- HashAggregate(keys=[hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184], functions=[partial_count(1) AS count#2387L], output=[hotel_id#2281L, srch_co_month#2185, srch_ci_month#2184, count#2387L])\n                                 +- Project [hotel_id#2281L, month(cast(srch_ci#2274 as date)) AS srch_ci_month#2184, month(cast(srch_co#2275 as date)) AS srch_co_month#2185]\n                                    +- FileScan parquet spark_sql.expedia[srch_ci#2274,srch_co#2275,hotel_id#2281L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_sum_Feb], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;sum_Feb DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;sum_Feb]\n            +- &#39;UnresolvedRelation [expedia_month_sum_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Feb, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Feb#3988L DESC NULLS LAST], true\n         +- Project [hotel_id#3986L, sum_Feb#3988L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_sum_view\n               +- View (`spark_sql`.`expedia_month_sum_view`, [hotel_id#3986L,sum_Jan#3987L,sum_Feb#3988L,sum_Mar#3989L,sum_Apr#3990L,sum_May#3991L,sum_Jun#3992L,sum_Jul#3993L,sum_Aug#3994L,sum_Sep#3995L,sum_Oct#3996L,sum_Nov#3997L,sum_Dec#3998L])\n                  +- Project [cast(hotel_id#4038L as bigint) AS hotel_id#3986L, cast(sum_Jan#3974L as bigint) AS sum_Jan#3987L, cast(sum_Feb#3975L as bigint) AS sum_Feb#3988L, cast(sum_Mar#3976L as bigint) AS sum_Mar#3989L, cast(sum_Apr#3977L as bigint) AS sum_Apr#3990L, cast(sum_May#3978L as bigint) AS sum_May#3991L, cast(sum_Jun#3979L as bigint) AS sum_Jun#3992L, cast(sum_Jul#3980L as bigint) AS sum_Jul#3993L, cast(sum_Aug#3981L as bigint) AS sum_Aug#3994L, cast(sum_Sep#3982L as bigint) AS sum_Sep#3995L, cast(sum_Oct#3983L as bigint) AS sum_Oct#3996L, cast(sum_Nov#3984L as bigint) AS sum_Nov#3997L, cast(sum_Dec#3985L as bigint) AS sum_Dec#3998L]\n                     +- Aggregate [hotel_id#4038L], [hotel_id#4038L, coalesce(sum(Jan#4067L), cast(0 as bigint)) AS sum_Jan#3974L, coalesce(sum(Feb#4068L), cast(0 as bigint)) AS sum_Feb#3975L, coalesce(sum(Mar#4069L), cast(0 as bigint)) AS sum_Mar#3976L, coalesce(sum(Apr#4070L), cast(0 as bigint)) AS sum_Apr#3977L, coalesce(sum(May#4071L), cast(0 as bigint)) AS sum_May#3978L, coalesce(sum(Jun#4072L), cast(0 as bigint)) AS sum_Jun#3979L, coalesce(sum(Jul#4073L), cast(0 as bigint)) AS sum_Jul#3980L, coalesce(sum(Aug#4074L), cast(0 as bigint)) AS sum_Aug#3981L, coalesce(sum(Sep#4075L), cast(0 as bigint)) AS sum_Sep#3982L, coalesce(sum(Oct#4076L), cast(0 as bigint)) AS sum_Oct#3983L, coalesce(sum(Nov#4077L), cast(0 as bigint)) AS sum_Nov#3984L, coalesce(sum(Dec#4078L), cast(0 as bigint)) AS sum_Dec#3985L]\n                        +- Project [hotel_id#4038L, srch_co_month#3961, __pivot_count(1) AS `count(1)`#4066[0] AS Jan#4067L, __pivot_count(1) AS `count(1)`#4066[1] AS Feb#4068L, __pivot_count(1) AS `count(1)`#4066[2] AS Mar#4069L, __pivot_count(1) AS `count(1)`#4066[3] AS Apr#4070L, __pivot_count(1) AS `count(1)`#4066[4] AS May#4071L, __pivot_count(1) AS `count(1)`#4066[5] AS Jun#4072L, __pivot_count(1) AS `count(1)`#4066[6] AS Jul#4073L, __pivot_count(1) AS `count(1)`#4066[7] AS Aug#4074L, __pivot_count(1) AS `count(1)`#4066[8] AS Sep#4075L, __pivot_count(1) AS `count(1)`#4066[9] AS Oct#4076L, __pivot_count(1) AS `count(1)`#4066[10] AS Nov#4077L, __pivot_count(1) AS `count(1)`#4066[11] AS Dec#4078L]\n                           +- Aggregate [hotel_id#4038L, srch_co_month#3961], [hotel_id#4038L, srch_co_month#3961, pivotfirst(srch_ci_month#3960, count(1)#4040L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS __pivot_count(1) AS `count(1)`#4066]\n                              +- Aggregate [hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960], [hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960, count(1) AS count(1)#4040L]\n                                 +- SubqueryAlias __auto_generated_subquery_name\n                                    +- Project [hotel_id#4038L, month(cast(srch_ci#4031 as date)) AS srch_ci_month#3960, month(cast(srch_co#4032 as date)) AS srch_co_month#3961]\n                                       +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                          +- Relation[id#4019L,date_time#4020,site_name#4021,posa_continent#4022,user_location_country#4023,user_location_region#4024,user_location_city#4025,orig_destination_distance#4026,user_id#4027,is_mobile#4028,is_package#4029,channel#4030,srch_ci#4031,srch_co#4032,srch_adults_cnt#4033,srch_children_cnt#4034,srch_rm_cnt#4035,srch_destination_id#4036,srch_destination_type_id#4037,hotel_id#4038L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Feb, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Feb#3988L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#4038L], [hotel_id#4038L, coalesce(sum(Feb#4068L), 0) AS sum_Feb#3988L]\n            +- Aggregate [hotel_id#4038L, srch_co_month#3961], [hotel_id#4038L, pivotfirst(srch_ci_month#3960, count(1)#4040L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)[1] AS Feb#4068L]\n               +- Aggregate [hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960], [hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960, count(1) AS count(1)#4040L]\n                  +- Project [hotel_id#4038L, month(cast(srch_ci#4031 as date)) AS srch_ci_month#3960, month(cast(srch_co#4032 as date)) AS srch_co_month#3961]\n                     +- Relation[id#4019L,date_time#4020,site_name#4021,posa_continent#4022,user_location_country#4023,user_location_region#4024,user_location_city#4025,orig_destination_distance#4026,user_id#4027,is_mobile#4028,is_package#4029,channel#4030,srch_ci#4031,srch_co#4032,srch_adults_cnt#4033,srch_children_cnt#4034,srch_rm_cnt#4035,srch_destination_id#4036,srch_destination_type_id#4037,hotel_id#4038L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#4163L, num_inserted_rows#4164L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Feb, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_Feb#3988L DESC NULLS LAST], output=[hotel_id#4038L,sum_Feb#3988L])\n      +- HashAggregate(keys=[hotel_id#4038L], functions=[finalmerge_sum(merge sum#4142L) AS sum(Feb#4068L)#4080L], output=[hotel_id#4038L, sum_Feb#3988L])\n         +- Exchange hashpartitioning(hotel_id#4038L, 200), ENSURE_REQUIREMENTS, [id=#1953]\n            +- HashAggregate(keys=[hotel_id#4038L], functions=[partial_sum(Feb#4068L) AS sum#4142L], output=[hotel_id#4038L, sum#4142L])\n               +- HashAggregate(keys=[hotel_id#4038L, srch_co_month#3961], functions=[finalmerge_pivotfirst(merge 1#4053L, 2#4054L, 3#4055L, 4#4056L, 5#4057L, 6#4058L, 7#4059L, 8#4060L, 9#4061L, 10#4062L, 11#4063L, 12#4064L) AS pivotfirst(srch_ci_month#3960, count(1)#4040L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)#4065], output=[hotel_id#4038L, Feb#4068L])\n                  +- Exchange hashpartitioning(hotel_id#4038L, srch_co_month#3961, 200), ENSURE_REQUIREMENTS, [id=#1949]\n                     +- HashAggregate(keys=[hotel_id#4038L, srch_co_month#3961], functions=[partial_pivotfirst(srch_ci_month#3960, count(1)#4040L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS (1#4053L, 2#4054L, 3#4055L, 4#4056L, 5#4057L, 6#4058L, 7#4059L, 8#4060L, 9#4061L, 10#4062L, 11#4063L, 12#4064L)], output=[hotel_id#4038L, srch_co_month#3961, 1#4053L, 2#4054L, 3#4055L, 4#4056L, 5#4057L, 6#4058L, 7#4059L, 8#4060L, 9#4061L, 10#4062L, 11#4063L, 12#4064L])\n                        +- HashAggregate(keys=[hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960], functions=[finalmerge_count(merge count#4144L) AS count(1)#4039L], output=[hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960, count(1)#4040L])\n                           +- Exchange hashpartitioning(hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960, 200), ENSURE_REQUIREMENTS, [id=#1945]\n                              +- HashAggregate(keys=[hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960], functions=[partial_count(1) AS count#4144L], output=[hotel_id#4038L, srch_co_month#3961, srch_ci_month#3960, count#4144L])\n                                 +- Project [hotel_id#4038L, month(cast(srch_ci#4031 as date)) AS srch_ci_month#3960, month(cast(srch_co#4032 as date)) AS srch_co_month#3961]\n                                    +- FileScan parquet spark_sql.expedia[srch_ci#4031,srch_co#4032,hotel_id#4038L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_sum_Mar], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;sum_Mar DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;sum_Mar]\n            +- &#39;UnresolvedRelation [expedia_month_sum_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Mar, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Mar#5493L DESC NULLS LAST], true\n         +- Project [hotel_id#5490L, sum_Mar#5493L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_sum_view\n               +- View (`spark_sql`.`expedia_month_sum_view`, [hotel_id#5490L,sum_Jan#5491L,sum_Feb#5492L,sum_Mar#5493L,sum_Apr#5494L,sum_May#5495L,sum_Jun#5496L,sum_Jul#5497L,sum_Aug#5498L,sum_Sep#5499L,sum_Oct#5500L,sum_Nov#5501L,sum_Dec#5502L])\n                  +- Project [cast(hotel_id#5542L as bigint) AS hotel_id#5490L, cast(sum_Jan#5478L as bigint) AS sum_Jan#5491L, cast(sum_Feb#5479L as bigint) AS sum_Feb#5492L, cast(sum_Mar#5480L as bigint) AS sum_Mar#5493L, cast(sum_Apr#5481L as bigint) AS sum_Apr#5494L, cast(sum_May#5482L as bigint) AS sum_May#5495L, cast(sum_Jun#5483L as bigint) AS sum_Jun#5496L, cast(sum_Jul#5484L as bigint) AS sum_Jul#5497L, cast(sum_Aug#5485L as bigint) AS sum_Aug#5498L, cast(sum_Sep#5486L as bigint) AS sum_Sep#5499L, cast(sum_Oct#5487L as bigint) AS sum_Oct#5500L, cast(sum_Nov#5488L as bigint) AS sum_Nov#5501L, cast(sum_Dec#5489L as bigint) AS sum_Dec#5502L]\n                     +- Aggregate [hotel_id#5542L], [hotel_id#5542L, coalesce(sum(Jan#5571L), cast(0 as bigint)) AS sum_Jan#5478L, coalesce(sum(Feb#5572L), cast(0 as bigint)) AS sum_Feb#5479L, coalesce(sum(Mar#5573L), cast(0 as bigint)) AS sum_Mar#5480L, coalesce(sum(Apr#5574L), cast(0 as bigint)) AS sum_Apr#5481L, coalesce(sum(May#5575L), cast(0 as bigint)) AS sum_May#5482L, coalesce(sum(Jun#5576L), cast(0 as bigint)) AS sum_Jun#5483L, coalesce(sum(Jul#5577L), cast(0 as bigint)) AS sum_Jul#5484L, coalesce(sum(Aug#5578L), cast(0 as bigint)) AS sum_Aug#5485L, coalesce(sum(Sep#5579L), cast(0 as bigint)) AS sum_Sep#5486L, coalesce(sum(Oct#5580L), cast(0 as bigint)) AS sum_Oct#5487L, coalesce(sum(Nov#5581L), cast(0 as bigint)) AS sum_Nov#5488L, coalesce(sum(Dec#5582L), cast(0 as bigint)) AS sum_Dec#5489L]\n                        +- Project [hotel_id#5542L, srch_co_month#5465, __pivot_count(1) AS `count(1)`#5570[0] AS Jan#5571L, __pivot_count(1) AS `count(1)`#5570[1] AS Feb#5572L, __pivot_count(1) AS `count(1)`#5570[2] AS Mar#5573L, __pivot_count(1) AS `count(1)`#5570[3] AS Apr#5574L, __pivot_count(1) AS `count(1)`#5570[4] AS May#5575L, __pivot_count(1) AS `count(1)`#5570[5] AS Jun#5576L, __pivot_count(1) AS `count(1)`#5570[6] AS Jul#5577L, __pivot_count(1) AS `count(1)`#5570[7] AS Aug#5578L, __pivot_count(1) AS `count(1)`#5570[8] AS Sep#5579L, __pivot_count(1) AS `count(1)`#5570[9] AS Oct#5580L, __pivot_count(1) AS `count(1)`#5570[10] AS Nov#5581L, __pivot_count(1) AS `count(1)`#5570[11] AS Dec#5582L]\n                           +- Aggregate [hotel_id#5542L, srch_co_month#5465], [hotel_id#5542L, srch_co_month#5465, pivotfirst(srch_ci_month#5464, count(1)#5544L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS __pivot_count(1) AS `count(1)`#5570]\n                              +- Aggregate [hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464], [hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464, count(1) AS count(1)#5544L]\n                                 +- SubqueryAlias __auto_generated_subquery_name\n                                    +- Project [hotel_id#5542L, month(cast(srch_ci#5535 as date)) AS srch_ci_month#5464, month(cast(srch_co#5536 as date)) AS srch_co_month#5465]\n                                       +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                          +- Relation[id#5523L,date_time#5524,site_name#5525,posa_continent#5526,user_location_country#5527,user_location_region#5528,user_location_city#5529,orig_destination_distance#5530,user_id#5531,is_mobile#5532,is_package#5533,channel#5534,srch_ci#5535,srch_co#5536,srch_adults_cnt#5537,srch_children_cnt#5538,srch_rm_cnt#5539,srch_destination_id#5540,srch_destination_type_id#5541,hotel_id#5542L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Mar, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Mar#5493L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#5542L], [hotel_id#5542L, coalesce(sum(Mar#5573L), 0) AS sum_Mar#5493L]\n            +- Aggregate [hotel_id#5542L, srch_co_month#5465], [hotel_id#5542L, pivotfirst(srch_ci_month#5464, count(1)#5544L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)[2] AS Mar#5573L]\n               +- Aggregate [hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464], [hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464, count(1) AS count(1)#5544L]\n                  +- Project [hotel_id#5542L, month(cast(srch_ci#5535 as date)) AS srch_ci_month#5464, month(cast(srch_co#5536 as date)) AS srch_co_month#5465]\n                     +- Relation[id#5523L,date_time#5524,site_name#5525,posa_continent#5526,user_location_country#5527,user_location_region#5528,user_location_city#5529,orig_destination_distance#5530,user_id#5531,is_mobile#5532,is_package#5533,channel#5534,srch_ci#5535,srch_co#5536,srch_adults_cnt#5537,srch_children_cnt#5538,srch_rm_cnt#5539,srch_destination_id#5540,srch_destination_type_id#5541,hotel_id#5542L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#5667L, num_inserted_rows#5668L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Mar, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_Mar#5493L DESC NULLS LAST], output=[hotel_id#5542L,sum_Mar#5493L])\n      +- HashAggregate(keys=[hotel_id#5542L], functions=[finalmerge_sum(merge sum#5646L) AS sum(Mar#5573L)#5585L], output=[hotel_id#5542L, sum_Mar#5493L])\n         +- Exchange hashpartitioning(hotel_id#5542L, 200), ENSURE_REQUIREMENTS, [id=#2868]\n            +- HashAggregate(keys=[hotel_id#5542L], functions=[partial_sum(Mar#5573L) AS sum#5646L], output=[hotel_id#5542L, sum#5646L])\n               +- HashAggregate(keys=[hotel_id#5542L, srch_co_month#5465], functions=[finalmerge_pivotfirst(merge 1#5557L, 2#5558L, 3#5559L, 4#5560L, 5#5561L, 6#5562L, 7#5563L, 8#5564L, 9#5565L, 10#5566L, 11#5567L, 12#5568L) AS pivotfirst(srch_ci_month#5464, count(1)#5544L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)#5569], output=[hotel_id#5542L, Mar#5573L])\n                  +- Exchange hashpartitioning(hotel_id#5542L, srch_co_month#5465, 200), ENSURE_REQUIREMENTS, [id=#2864]\n                     +- HashAggregate(keys=[hotel_id#5542L, srch_co_month#5465], functions=[partial_pivotfirst(srch_ci_month#5464, count(1)#5544L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS (1#5557L, 2#5558L, 3#5559L, 4#5560L, 5#5561L, 6#5562L, 7#5563L, 8#5564L, 9#5565L, 10#5566L, 11#5567L, 12#5568L)], output=[hotel_id#5542L, srch_co_month#5465, 1#5557L, 2#5558L, 3#5559L, 4#5560L, 5#5561L, 6#5562L, 7#5563L, 8#5564L, 9#5565L, 10#5566L, 11#5567L, 12#5568L])\n                        +- HashAggregate(keys=[hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464], functions=[finalmerge_count(merge count#5648L) AS count(1)#5543L], output=[hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464, count(1)#5544L])\n                           +- Exchange hashpartitioning(hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464, 200), ENSURE_REQUIREMENTS, [id=#2860]\n                              +- HashAggregate(keys=[hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464], functions=[partial_count(1) AS count#5648L], output=[hotel_id#5542L, srch_co_month#5465, srch_ci_month#5464, count#5648L])\n\n*** WARNING: skipped 54421 bytes of output ***\n\n                     +- Aggregate [hotel_id#16070L], [hotel_id#16070L, coalesce(sum(Jan#16099L), cast(0 as bigint)) AS sum_Jan#16006L, coalesce(sum(Feb#16100L), cast(0 as bigint)) AS sum_Feb#16007L, coalesce(sum(Mar#16101L), cast(0 as bigint)) AS sum_Mar#16008L, coalesce(sum(Apr#16102L), cast(0 as bigint)) AS sum_Apr#16009L, coalesce(sum(May#16103L), cast(0 as bigint)) AS sum_May#16010L, coalesce(sum(Jun#16104L), cast(0 as bigint)) AS sum_Jun#16011L, coalesce(sum(Jul#16105L), cast(0 as bigint)) AS sum_Jul#16012L, coalesce(sum(Aug#16106L), cast(0 as bigint)) AS sum_Aug#16013L, coalesce(sum(Sep#16107L), cast(0 as bigint)) AS sum_Sep#16014L, coalesce(sum(Oct#16108L), cast(0 as bigint)) AS sum_Oct#16015L, coalesce(sum(Nov#16109L), cast(0 as bigint)) AS sum_Nov#16016L, coalesce(sum(Dec#16110L), cast(0 as bigint)) AS sum_Dec#16017L]\n                        +- Project [hotel_id#16070L, srch_co_month#15993, __pivot_count(1) AS `count(1)`#16098[0] AS Jan#16099L, __pivot_count(1) AS `count(1)`#16098[1] AS Feb#16100L, __pivot_count(1) AS `count(1)`#16098[2] AS Mar#16101L, __pivot_count(1) AS `count(1)`#16098[3] AS Apr#16102L, __pivot_count(1) AS `count(1)`#16098[4] AS May#16103L, __pivot_count(1) AS `count(1)`#16098[5] AS Jun#16104L, __pivot_count(1) AS `count(1)`#16098[6] AS Jul#16105L, __pivot_count(1) AS `count(1)`#16098[7] AS Aug#16106L, __pivot_count(1) AS `count(1)`#16098[8] AS Sep#16107L, __pivot_count(1) AS `count(1)`#16098[9] AS Oct#16108L, __pivot_count(1) AS `count(1)`#16098[10] AS Nov#16109L, __pivot_count(1) AS `count(1)`#16098[11] AS Dec#16110L]\n                           +- Aggregate [hotel_id#16070L, srch_co_month#15993], [hotel_id#16070L, srch_co_month#15993, pivotfirst(srch_ci_month#15992, count(1)#16072L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS __pivot_count(1) AS `count(1)`#16098]\n                              +- Aggregate [hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992], [hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992, count(1) AS count(1)#16072L]\n                                 +- SubqueryAlias __auto_generated_subquery_name\n                                    +- Project [hotel_id#16070L, month(cast(srch_ci#16063 as date)) AS srch_ci_month#15992, month(cast(srch_co#16064 as date)) AS srch_co_month#15993]\n                                       +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                          +- Relation[id#16051L,date_time#16052,site_name#16053,posa_continent#16054,user_location_country#16055,user_location_region#16056,user_location_city#16057,orig_destination_distance#16058,user_id#16059,is_mobile#16060,is_package#16061,channel#16062,srch_ci#16063,srch_co#16064,srch_adults_cnt#16065,srch_children_cnt#16066,srch_rm_cnt#16067,srch_destination_id#16068,srch_destination_type_id#16069,hotel_id#16070L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Oct, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Oct#16028L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#16070L], [hotel_id#16070L, coalesce(sum(Oct#16108L), 0) AS sum_Oct#16028L]\n            +- Aggregate [hotel_id#16070L, srch_co_month#15993], [hotel_id#16070L, pivotfirst(srch_ci_month#15992, count(1)#16072L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)[9] AS Oct#16108L]\n               +- Aggregate [hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992], [hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992, count(1) AS count(1)#16072L]\n                  +- Project [hotel_id#16070L, month(cast(srch_ci#16063 as date)) AS srch_ci_month#15992, month(cast(srch_co#16064 as date)) AS srch_co_month#15993]\n                     +- Relation[id#16051L,date_time#16052,site_name#16053,posa_continent#16054,user_location_country#16055,user_location_region#16056,user_location_city#16057,orig_destination_distance#16058,user_id#16059,is_mobile#16060,is_package#16061,channel#16062,srch_ci#16063,srch_co#16064,srch_adults_cnt#16065,srch_children_cnt#16066,srch_rm_cnt#16067,srch_destination_id#16068,srch_destination_type_id#16069,hotel_id#16070L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#16195L, num_inserted_rows#16196L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Oct, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_Oct#16028L DESC NULLS LAST], output=[hotel_id#16070L,sum_Oct#16028L])\n      +- HashAggregate(keys=[hotel_id#16070L], functions=[finalmerge_sum(merge sum#16174L) AS sum(Oct#16108L)#16120L], output=[hotel_id#16070L, sum_Oct#16028L])\n         +- Exchange hashpartitioning(hotel_id#16070L, 200), ENSURE_REQUIREMENTS, [id=#9273]\n            +- HashAggregate(keys=[hotel_id#16070L], functions=[partial_sum(Oct#16108L) AS sum#16174L], output=[hotel_id#16070L, sum#16174L])\n               +- HashAggregate(keys=[hotel_id#16070L, srch_co_month#15993], functions=[finalmerge_pivotfirst(merge 1#16085L, 2#16086L, 3#16087L, 4#16088L, 5#16089L, 6#16090L, 7#16091L, 8#16092L, 9#16093L, 10#16094L, 11#16095L, 12#16096L) AS pivotfirst(srch_ci_month#15992, count(1)#16072L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)#16097], output=[hotel_id#16070L, Oct#16108L])\n                  +- Exchange hashpartitioning(hotel_id#16070L, srch_co_month#15993, 200), ENSURE_REQUIREMENTS, [id=#9269]\n                     +- HashAggregate(keys=[hotel_id#16070L, srch_co_month#15993], functions=[partial_pivotfirst(srch_ci_month#15992, count(1)#16072L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS (1#16085L, 2#16086L, 3#16087L, 4#16088L, 5#16089L, 6#16090L, 7#16091L, 8#16092L, 9#16093L, 10#16094L, 11#16095L, 12#16096L)], output=[hotel_id#16070L, srch_co_month#15993, 1#16085L, 2#16086L, 3#16087L, 4#16088L, 5#16089L, 6#16090L, 7#16091L, 8#16092L, 9#16093L, 10#16094L, 11#16095L, 12#16096L])\n                        +- HashAggregate(keys=[hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992], functions=[finalmerge_count(merge count#16176L) AS count(1)#16071L], output=[hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992, count(1)#16072L])\n                           +- Exchange hashpartitioning(hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992, 200), ENSURE_REQUIREMENTS, [id=#9265]\n                              +- HashAggregate(keys=[hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992], functions=[partial_count(1) AS count#16176L], output=[hotel_id#16070L, srch_co_month#15993, srch_ci_month#15992, count#16176L])\n                                 +- Project [hotel_id#16070L, month(cast(srch_ci#16063 as date)) AS srch_ci_month#15992, month(cast(srch_co#16064 as date)) AS srch_co_month#15993]\n                                    +- FileScan parquet spark_sql.expedia[srch_ci#16063,srch_co#16064,hotel_id#16070L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_sum_Nov], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;sum_Nov DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;sum_Nov]\n            +- &#39;UnresolvedRelation [expedia_month_sum_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Nov, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Nov#17533L DESC NULLS LAST], true\n         +- Project [hotel_id#17522L, sum_Nov#17533L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_sum_view\n               +- View (`spark_sql`.`expedia_month_sum_view`, [hotel_id#17522L,sum_Jan#17523L,sum_Feb#17524L,sum_Mar#17525L,sum_Apr#17526L,sum_May#17527L,sum_Jun#17528L,sum_Jul#17529L,sum_Aug#17530L,sum_Sep#17531L,sum_Oct#17532L,sum_Nov#17533L,sum_Dec#17534L])\n                  +- Project [cast(hotel_id#17574L as bigint) AS hotel_id#17522L, cast(sum_Jan#17510L as bigint) AS sum_Jan#17523L, cast(sum_Feb#17511L as bigint) AS sum_Feb#17524L, cast(sum_Mar#17512L as bigint) AS sum_Mar#17525L, cast(sum_Apr#17513L as bigint) AS sum_Apr#17526L, cast(sum_May#17514L as bigint) AS sum_May#17527L, cast(sum_Jun#17515L as bigint) AS sum_Jun#17528L, cast(sum_Jul#17516L as bigint) AS sum_Jul#17529L, cast(sum_Aug#17517L as bigint) AS sum_Aug#17530L, cast(sum_Sep#17518L as bigint) AS sum_Sep#17531L, cast(sum_Oct#17519L as bigint) AS sum_Oct#17532L, cast(sum_Nov#17520L as bigint) AS sum_Nov#17533L, cast(sum_Dec#17521L as bigint) AS sum_Dec#17534L]\n                     +- Aggregate [hotel_id#17574L], [hotel_id#17574L, coalesce(sum(Jan#17603L), cast(0 as bigint)) AS sum_Jan#17510L, coalesce(sum(Feb#17604L), cast(0 as bigint)) AS sum_Feb#17511L, coalesce(sum(Mar#17605L), cast(0 as bigint)) AS sum_Mar#17512L, coalesce(sum(Apr#17606L), cast(0 as bigint)) AS sum_Apr#17513L, coalesce(sum(May#17607L), cast(0 as bigint)) AS sum_May#17514L, coalesce(sum(Jun#17608L), cast(0 as bigint)) AS sum_Jun#17515L, coalesce(sum(Jul#17609L), cast(0 as bigint)) AS sum_Jul#17516L, coalesce(sum(Aug#17610L), cast(0 as bigint)) AS sum_Aug#17517L, coalesce(sum(Sep#17611L), cast(0 as bigint)) AS sum_Sep#17518L, coalesce(sum(Oct#17612L), cast(0 as bigint)) AS sum_Oct#17519L, coalesce(sum(Nov#17613L), cast(0 as bigint)) AS sum_Nov#17520L, coalesce(sum(Dec#17614L), cast(0 as bigint)) AS sum_Dec#17521L]\n                        +- Project [hotel_id#17574L, srch_co_month#17497, __pivot_count(1) AS `count(1)`#17602[0] AS Jan#17603L, __pivot_count(1) AS `count(1)`#17602[1] AS Feb#17604L, __pivot_count(1) AS `count(1)`#17602[2] AS Mar#17605L, __pivot_count(1) AS `count(1)`#17602[3] AS Apr#17606L, __pivot_count(1) AS `count(1)`#17602[4] AS May#17607L, __pivot_count(1) AS `count(1)`#17602[5] AS Jun#17608L, __pivot_count(1) AS `count(1)`#17602[6] AS Jul#17609L, __pivot_count(1) AS `count(1)`#17602[7] AS Aug#17610L, __pivot_count(1) AS `count(1)`#17602[8] AS Sep#17611L, __pivot_count(1) AS `count(1)`#17602[9] AS Oct#17612L, __pivot_count(1) AS `count(1)`#17602[10] AS Nov#17613L, __pivot_count(1) AS `count(1)`#17602[11] AS Dec#17614L]\n                           +- Aggregate [hotel_id#17574L, srch_co_month#17497], [hotel_id#17574L, srch_co_month#17497, pivotfirst(srch_ci_month#17496, count(1)#17576L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS __pivot_count(1) AS `count(1)`#17602]\n                              +- Aggregate [hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496], [hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496, count(1) AS count(1)#17576L]\n                                 +- SubqueryAlias __auto_generated_subquery_name\n                                    +- Project [hotel_id#17574L, month(cast(srch_ci#17567 as date)) AS srch_ci_month#17496, month(cast(srch_co#17568 as date)) AS srch_co_month#17497]\n                                       +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                          +- Relation[id#17555L,date_time#17556,site_name#17557,posa_continent#17558,user_location_country#17559,user_location_region#17560,user_location_city#17561,orig_destination_distance#17562,user_id#17563,is_mobile#17564,is_package#17565,channel#17566,srch_ci#17567,srch_co#17568,srch_adults_cnt#17569,srch_children_cnt#17570,srch_rm_cnt#17571,srch_destination_id#17572,srch_destination_type_id#17573,hotel_id#17574L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Nov, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Nov#17533L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#17574L], [hotel_id#17574L, coalesce(sum(Nov#17613L), 0) AS sum_Nov#17533L]\n            +- Aggregate [hotel_id#17574L, srch_co_month#17497], [hotel_id#17574L, pivotfirst(srch_ci_month#17496, count(1)#17576L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)[10] AS Nov#17613L]\n               +- Aggregate [hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496], [hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496, count(1) AS count(1)#17576L]\n                  +- Project [hotel_id#17574L, month(cast(srch_ci#17567 as date)) AS srch_ci_month#17496, month(cast(srch_co#17568 as date)) AS srch_co_month#17497]\n                     +- Relation[id#17555L,date_time#17556,site_name#17557,posa_continent#17558,user_location_country#17559,user_location_region#17560,user_location_city#17561,orig_destination_distance#17562,user_id#17563,is_mobile#17564,is_package#17565,channel#17566,srch_ci#17567,srch_co#17568,srch_adults_cnt#17569,srch_children_cnt#17570,srch_rm_cnt#17571,srch_destination_id#17572,srch_destination_type_id#17573,hotel_id#17574L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#17699L, num_inserted_rows#17700L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Nov, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_Nov#17533L DESC NULLS LAST], output=[hotel_id#17574L,sum_Nov#17533L])\n      +- HashAggregate(keys=[hotel_id#17574L], functions=[finalmerge_sum(merge sum#17678L) AS sum(Nov#17613L)#17625L], output=[hotel_id#17574L, sum_Nov#17533L])\n         +- Exchange hashpartitioning(hotel_id#17574L, 200), ENSURE_REQUIREMENTS, [id=#10188]\n            +- HashAggregate(keys=[hotel_id#17574L], functions=[partial_sum(Nov#17613L) AS sum#17678L], output=[hotel_id#17574L, sum#17678L])\n               +- HashAggregate(keys=[hotel_id#17574L, srch_co_month#17497], functions=[finalmerge_pivotfirst(merge 1#17589L, 2#17590L, 3#17591L, 4#17592L, 5#17593L, 6#17594L, 7#17595L, 8#17596L, 9#17597L, 10#17598L, 11#17599L, 12#17600L) AS pivotfirst(srch_ci_month#17496, count(1)#17576L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)#17601], output=[hotel_id#17574L, Nov#17613L])\n                  +- Exchange hashpartitioning(hotel_id#17574L, srch_co_month#17497, 200), ENSURE_REQUIREMENTS, [id=#10184]\n                     +- HashAggregate(keys=[hotel_id#17574L, srch_co_month#17497], functions=[partial_pivotfirst(srch_ci_month#17496, count(1)#17576L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS (1#17589L, 2#17590L, 3#17591L, 4#17592L, 5#17593L, 6#17594L, 7#17595L, 8#17596L, 9#17597L, 10#17598L, 11#17599L, 12#17600L)], output=[hotel_id#17574L, srch_co_month#17497, 1#17589L, 2#17590L, 3#17591L, 4#17592L, 5#17593L, 6#17594L, 7#17595L, 8#17596L, 9#17597L, 10#17598L, 11#17599L, 12#17600L])\n                        +- HashAggregate(keys=[hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496], functions=[finalmerge_count(merge count#17680L) AS count(1)#17575L], output=[hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496, count(1)#17576L])\n                           +- Exchange hashpartitioning(hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496, 200), ENSURE_REQUIREMENTS, [id=#10180]\n                              +- HashAggregate(keys=[hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496], functions=[partial_count(1) AS count#17680L], output=[hotel_id#17574L, srch_co_month#17497, srch_ci_month#17496, count#17680L])\n                                 +- Project [hotel_id#17574L, month(cast(srch_ci#17567 as date)) AS srch_ci_month#17496, month(cast(srch_co#17568 as date)) AS srch_co_month#17497]\n                                    +- FileScan parquet spark_sql.expedia[srch_ci#17567,srch_co#17568,hotel_id#17574L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_sum_Dec], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;sum_Dec DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;sum_Dec]\n            +- &#39;UnresolvedRelation [expedia_month_sum_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Dec, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Dec#19038L DESC NULLS LAST], true\n         +- Project [hotel_id#19026L, sum_Dec#19038L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_sum_view\n               +- View (`spark_sql`.`expedia_month_sum_view`, [hotel_id#19026L,sum_Jan#19027L,sum_Feb#19028L,sum_Mar#19029L,sum_Apr#19030L,sum_May#19031L,sum_Jun#19032L,sum_Jul#19033L,sum_Aug#19034L,sum_Sep#19035L,sum_Oct#19036L,sum_Nov#19037L,sum_Dec#19038L])\n                  +- Project [cast(hotel_id#19078L as bigint) AS hotel_id#19026L, cast(sum_Jan#19014L as bigint) AS sum_Jan#19027L, cast(sum_Feb#19015L as bigint) AS sum_Feb#19028L, cast(sum_Mar#19016L as bigint) AS sum_Mar#19029L, cast(sum_Apr#19017L as bigint) AS sum_Apr#19030L, cast(sum_May#19018L as bigint) AS sum_May#19031L, cast(sum_Jun#19019L as bigint) AS sum_Jun#19032L, cast(sum_Jul#19020L as bigint) AS sum_Jul#19033L, cast(sum_Aug#19021L as bigint) AS sum_Aug#19034L, cast(sum_Sep#19022L as bigint) AS sum_Sep#19035L, cast(sum_Oct#19023L as bigint) AS sum_Oct#19036L, cast(sum_Nov#19024L as bigint) AS sum_Nov#19037L, cast(sum_Dec#19025L as bigint) AS sum_Dec#19038L]\n                     +- Aggregate [hotel_id#19078L], [hotel_id#19078L, coalesce(sum(Jan#19107L), cast(0 as bigint)) AS sum_Jan#19014L, coalesce(sum(Feb#19108L), cast(0 as bigint)) AS sum_Feb#19015L, coalesce(sum(Mar#19109L), cast(0 as bigint)) AS sum_Mar#19016L, coalesce(sum(Apr#19110L), cast(0 as bigint)) AS sum_Apr#19017L, coalesce(sum(May#19111L), cast(0 as bigint)) AS sum_May#19018L, coalesce(sum(Jun#19112L), cast(0 as bigint)) AS sum_Jun#19019L, coalesce(sum(Jul#19113L), cast(0 as bigint)) AS sum_Jul#19020L, coalesce(sum(Aug#19114L), cast(0 as bigint)) AS sum_Aug#19021L, coalesce(sum(Sep#19115L), cast(0 as bigint)) AS sum_Sep#19022L, coalesce(sum(Oct#19116L), cast(0 as bigint)) AS sum_Oct#19023L, coalesce(sum(Nov#19117L), cast(0 as bigint)) AS sum_Nov#19024L, coalesce(sum(Dec#19118L), cast(0 as bigint)) AS sum_Dec#19025L]\n                        +- Project [hotel_id#19078L, srch_co_month#19001, __pivot_count(1) AS `count(1)`#19106[0] AS Jan#19107L, __pivot_count(1) AS `count(1)`#19106[1] AS Feb#19108L, __pivot_count(1) AS `count(1)`#19106[2] AS Mar#19109L, __pivot_count(1) AS `count(1)`#19106[3] AS Apr#19110L, __pivot_count(1) AS `count(1)`#19106[4] AS May#19111L, __pivot_count(1) AS `count(1)`#19106[5] AS Jun#19112L, __pivot_count(1) AS `count(1)`#19106[6] AS Jul#19113L, __pivot_count(1) AS `count(1)`#19106[7] AS Aug#19114L, __pivot_count(1) AS `count(1)`#19106[8] AS Sep#19115L, __pivot_count(1) AS `count(1)`#19106[9] AS Oct#19116L, __pivot_count(1) AS `count(1)`#19106[10] AS Nov#19117L, __pivot_count(1) AS `count(1)`#19106[11] AS Dec#19118L]\n                           +- Aggregate [hotel_id#19078L, srch_co_month#19001], [hotel_id#19078L, srch_co_month#19001, pivotfirst(srch_ci_month#19000, count(1)#19080L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS __pivot_count(1) AS `count(1)`#19106]\n                              +- Aggregate [hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000], [hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000, count(1) AS count(1)#19080L]\n                                 +- SubqueryAlias __auto_generated_subquery_name\n                                    +- Project [hotel_id#19078L, month(cast(srch_ci#19071 as date)) AS srch_ci_month#19000, month(cast(srch_co#19072 as date)) AS srch_co_month#19001]\n                                       +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                          +- Relation[id#19059L,date_time#19060,site_name#19061,posa_continent#19062,user_location_country#19063,user_location_region#19064,user_location_city#19065,orig_destination_distance#19066,user_id#19067,is_mobile#19068,is_package#19069,channel#19070,srch_ci#19071,srch_co#19072,srch_adults_cnt#19073,srch_children_cnt#19074,srch_rm_cnt#19075,srch_destination_id#19076,srch_destination_type_id#19077,hotel_id#19078L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Dec, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_Dec#19038L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#19078L], [hotel_id#19078L, coalesce(sum(Dec#19118L), 0) AS sum_Dec#19038L]\n            +- Aggregate [hotel_id#19078L, srch_co_month#19001], [hotel_id#19078L, pivotfirst(srch_ci_month#19000, count(1)#19080L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)[11] AS Dec#19118L]\n               +- Aggregate [hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000], [hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000, count(1) AS count(1)#19080L]\n                  +- Project [hotel_id#19078L, month(cast(srch_ci#19071 as date)) AS srch_ci_month#19000, month(cast(srch_co#19072 as date)) AS srch_co_month#19001]\n                     +- Relation[id#19059L,date_time#19060,site_name#19061,posa_continent#19062,user_location_country#19063,user_location_region#19064,user_location_city#19065,orig_destination_distance#19066,user_id#19067,is_mobile#19068,is_package#19069,channel#19070,srch_ci#19071,srch_co#19072,srch_adults_cnt#19073,srch_children_cnt#19074,srch_rm_cnt#19075,srch_destination_id#19076,srch_destination_type_id#19077,hotel_id#19078L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#19203L, num_inserted_rows#19204L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_2_sum_Dec, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_Dec#19038L DESC NULLS LAST], output=[hotel_id#19078L,sum_Dec#19038L])\n      +- HashAggregate(keys=[hotel_id#19078L], functions=[finalmerge_sum(merge sum#19182L) AS sum(Dec#19118L)#19130L], output=[hotel_id#19078L, sum_Dec#19038L])\n         +- Exchange hashpartitioning(hotel_id#19078L, 200), ENSURE_REQUIREMENTS, [id=#11103]\n            +- HashAggregate(keys=[hotel_id#19078L], functions=[partial_sum(Dec#19118L) AS sum#19182L], output=[hotel_id#19078L, sum#19182L])\n               +- HashAggregate(keys=[hotel_id#19078L, srch_co_month#19001], functions=[finalmerge_pivotfirst(merge 1#19093L, 2#19094L, 3#19095L, 4#19096L, 5#19097L, 6#19098L, 7#19099L, 8#19100L, 9#19101L, 10#19102L, 11#19103L, 12#19104L) AS pivotfirst(srch_ci_month#19000, count(1)#19080L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0)#19105], output=[hotel_id#19078L, Dec#19118L])\n                  +- Exchange hashpartitioning(hotel_id#19078L, srch_co_month#19001, 200), ENSURE_REQUIREMENTS, [id=#11099]\n                     +- HashAggregate(keys=[hotel_id#19078L, srch_co_month#19001], functions=[partial_pivotfirst(srch_ci_month#19000, count(1)#19080L, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0) AS (1#19093L, 2#19094L, 3#19095L, 4#19096L, 5#19097L, 6#19098L, 7#19099L, 8#19100L, 9#19101L, 10#19102L, 11#19103L, 12#19104L)], output=[hotel_id#19078L, srch_co_month#19001, 1#19093L, 2#19094L, 3#19095L, 4#19096L, 5#19097L, 6#19098L, 7#19099L, 8#19100L, 9#19101L, 10#19102L, 11#19103L, 12#19104L])\n                        +- HashAggregate(keys=[hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000], functions=[finalmerge_count(merge count#19184L) AS count(1)#19079L], output=[hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000, count(1)#19080L])\n                           +- Exchange hashpartitioning(hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000, 200), ENSURE_REQUIREMENTS, [id=#11095]\n                              +- HashAggregate(keys=[hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000], functions=[partial_count(1) AS count#19184L], output=[hotel_id#19078L, srch_co_month#19001, srch_ci_month#19000, count#19184L])\n                                 +- Project [hotel_id#19078L, month(cast(srch_ci#19071 as date)) AS srch_ci_month#19000, month(cast(srch_co#19072 as date)) AS srch_co_month#19001]\n                                    +- FileScan parquet spark_sql.expedia[srch_ci#19071,srch_co#19072,hotel_id#19078L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"drop table if exists query_3\")\nsession.sql(\"drop view if exists join_data_view\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e0bae69-16ff-4d7c-97f5-a995e98cd5cd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"\"\"\n          create view join_data_view as\n          \n          select hw.id,hw.avg_tmpr_c,hw.wthr_date,ex.srch_ci,ex.srch_co\n          \n          from hotel_weather as hw inner join expedia as ex on hw.id = ex.hotel_id \n          where hw.wthr_date>=ex.srch_ci and hw.wthr_date<=ex.srch_co and datediff(ex.srch_co,ex.srch_ci)>7\n         \n          order by hw.id,hw.wthr_date\n          \"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Query 3 ( we need to create a view as joining tables with selecting and ordering by id and weather date )","showTitle":true,"inputWidgets":{},"nuid":"02289e12-11a9-4ea8-b1fe-99d603152518"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1933375258470369&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span>           &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">     11</span> \n<span class=\"ansi-green-fg\">---&gt; 12</span><span class=\"ansi-red-fg\"> </span>show_query<span class=\"ansi-blue-fg\">(</span>query<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">&lt;command-1093128981127366&gt;</span> in <span class=\"ansi-cyan-fg\">show_query</span><span class=\"ansi-blue-fg\">(sql_select)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> <span class=\"ansi-green-fg\">def</span> show_query<span class=\"ansi-blue-fg\">(</span>sql_select<span class=\"ansi-blue-fg\">:</span>str<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\">   </span>session<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>sql_select<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">sql</span><span class=\"ansi-blue-fg\">(self, sqlQuery)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    775</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row1&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row2&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row3&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 777</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>sqlQuery<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_wrapped<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    778</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    779</span>     <span class=\"ansi-green-fg\">def</span> table<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> tableName<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    114</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 116</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    117</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: View `spark_sql`.`join_data_view` already exists. If you want to update the view definition, please use ALTER VIEW AS or CREATE OR REPLACE VIEW AS</div>","errorSummary":"<span class=\"ansi-red-fg\">AnalysisException</span>: View `spark_sql`.`join_data_view` already exists. If you want to update the view definition, please use ALTER VIEW AS or CREATE OR REPLACE VIEW AS","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1933375258470369&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span>           &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">     11</span> \n<span class=\"ansi-green-fg\">---&gt; 12</span><span class=\"ansi-red-fg\"> </span>show_query<span class=\"ansi-blue-fg\">(</span>query<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">&lt;command-1093128981127366&gt;</span> in <span class=\"ansi-cyan-fg\">show_query</span><span class=\"ansi-blue-fg\">(sql_select)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> <span class=\"ansi-green-fg\">def</span> show_query<span class=\"ansi-blue-fg\">(</span>sql_select<span class=\"ansi-blue-fg\">:</span>str<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\">   </span>session<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>sql_select<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">sql</span><span class=\"ansi-blue-fg\">(self, sqlQuery)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    775</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row1&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row2&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row3&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 777</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>sqlQuery<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_wrapped<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    778</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    779</span>     <span class=\"ansi-green-fg\">def</span> table<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> tableName<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    114</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 116</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    117</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: View `spark_sql`.`join_data_view` already exists. If you want to update the view definition, please use ALTER VIEW AS or CREATE OR REPLACE VIEW AS</div>"]}}],"execution_count":0},{"cell_type":"code","source":["query = \"\"\"\n          create table if not exists query_3 as\n          \n          select id,avg(avg_tmpr_c) as avg_order_tmpr_c,srch_ci,srch_co,\n          \n          case when max(wthr_date)=srch_co and min(wthr_date)=srch_ci \n          then last(avg_tmpr_c)-first(avg_tmpr_c) else null end as tmpr_diff\n          \n          from join_data_view\n          \n          group by id,srch_ci,srch_co \n          \n          \"\"\"\nanalyze_plan(query)\nsave_query(query,\"query_3\",partition=(\"id\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Calculating average, first & last temperature difference for each order","showTitle":true,"inputWidgets":{},"nuid":"cce29114-2d02-44b7-898f-b7eb76d21501"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_3], false, true\n+- &#39;Aggregate [&#39;id, &#39;srch_ci, &#39;srch_co], [&#39;id, &#39;avg(&#39;avg_tmpr_c) AS avg_order_tmpr_c#24044, &#39;srch_ci, &#39;srch_co, CASE WHEN ((&#39;max(&#39;wthr_date) = &#39;srch_co) AND (&#39;min(&#39;wthr_date) = &#39;srch_ci)) THEN (last(&#39;avg_tmpr_c, false) - first(&#39;avg_tmpr_c, false)) ELSE null END AS tmpr_diff#24047]\n   +- &#39;UnresolvedRelation [join_data_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_3, true\n+- Aggregate [id#24048, srch_ci#24051, srch_co#24052], [id#24048, avg(avg_tmpr_c#24049) AS avg_order_tmpr_c#24044, srch_ci#24051, srch_co#24052, CASE WHEN ((max(wthr_date#24050) = srch_co#24052) AND (min(wthr_date#24050) = srch_ci#24051)) THEN (last(avg_tmpr_c#24049, false) - first(avg_tmpr_c#24049, false)) ELSE cast(null as double) END AS tmpr_diff#24047]\n   +- SubqueryAlias spark_catalog.spark_sql.join_data_view\n      +- View (`spark_sql`.`join_data_view`, [id#24048,avg_tmpr_c#24049,wthr_date#24050,srch_ci#24051,srch_co#24052])\n         +- Project [cast(id#24073 as string) AS id#24048, cast(avg_tmpr_c#24068 as double) AS avg_tmpr_c#24049, cast(wthr_date#24077 as string) AS wthr_date#24050, cast(srch_ci#24113 as string) AS srch_ci#24051, cast(srch_co#24114 as string) AS srch_co#24052]\n            +- Sort [id#24073 ASC NULLS FIRST, wthr_date#24077 ASC NULLS FIRST], true\n               +- Project [id#24073, avg_tmpr_c#24068, wthr_date#24077, srch_ci#24113, srch_co#24114]\n                  +- Filter (((wthr_date#24077 &gt;= srch_ci#24113) AND (wthr_date#24077 &lt;= srch_co#24114)) AND (datediff(cast(srch_co#24114 as date), cast(srch_ci#24113 as date)) &gt; 7))\n                     +- Join Inner, (cast(id#24073 as bigint) = hotel_id#24120L)\n                        :- SubqueryAlias hw\n                        :  +- SubqueryAlias spark_catalog.spark_sql.hotel_weather\n                        :     +- Relation[address#24067,avg_tmpr_c#24068,avg_tmpr_f#24069,city#24070,country#24071,geoHash#24072,id#24073,latitude#24074,longitude#24075,name#24076,wthr_date#24077,year#24078,month#24079,day#24080] parquet\n                        +- SubqueryAlias ex\n                           +- SubqueryAlias spark_catalog.spark_sql.expedia\n                              +- Relation[id#24101L,date_time#24102,site_name#24103,posa_continent#24104,user_location_country#24105,user_location_region#24106,user_location_city#24107,orig_destination_distance#24108,user_id#24109,is_mobile#24110,is_package#24111,channel#24112,srch_ci#24113,srch_co#24114,srch_adults_cnt#24115,srch_children_cnt#24116,srch_rm_cnt#24117,srch_destination_id#24118,srch_destination_type_id#24119,hotel_id#24120L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_3, true\n+- Aggregate [id#24073, srch_ci#24113, srch_co#24114], [id#24073, avg(avg_tmpr_c#24068) AS avg_order_tmpr_c#24044, srch_ci#24113, srch_co#24114, CASE WHEN ((max(wthr_date#24077) = srch_co#24114) AND (min(wthr_date#24077) = srch_ci#24113)) THEN (last(avg_tmpr_c#24068, false) - first(avg_tmpr_c#24068, false)) END AS tmpr_diff#24047]\n   +- Sort [id#24073 ASC NULLS FIRST, wthr_date#24077 ASC NULLS FIRST], true\n      +- Project [id#24073, avg_tmpr_c#24068, wthr_date#24077, srch_ci#24113, srch_co#24114]\n         +- Join Inner, (((wthr_date#24077 &gt;= srch_ci#24113) AND (wthr_date#24077 &lt;= srch_co#24114)) AND (cast(id#24073 as bigint) = hotel_id#24120L))\n            :- Project [avg_tmpr_c#24068, id#24073, wthr_date#24077]\n            :  +- Filter (isnotnull(wthr_date#24077) AND isnotnull(id#24073))\n            :     +- Relation[address#24067,avg_tmpr_c#24068,avg_tmpr_f#24069,city#24070,country#24071,geoHash#24072,id#24073,latitude#24074,longitude#24075,name#24076,wthr_date#24077,year#24078,month#24079,day#24080] parquet\n            +- Project [srch_ci#24113, srch_co#24114, hotel_id#24120L]\n               +- Filter (((isnotnull(srch_co#24114) AND isnotnull(srch_ci#24113)) AND (datediff(cast(srch_co#24114 as date), cast(srch_ci#24113 as date)) &gt; 7)) AND isnotnull(hotel_id#24120L))\n                  +- Relation[id#24101L,date_time#24102,site_name#24103,posa_continent#24104,user_location_country#24105,user_location_region#24106,user_location_city#24107,orig_destination_distance#24108,user_id#24109,is_mobile#24110,is_package#24111,channel#24112,srch_ci#24113,srch_co#24114,srch_adults_cnt#24115,srch_children_cnt#24116,srch_rm_cnt#24117,srch_destination_id#24118,srch_destination_type_id#24119,hotel_id#24120L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#24236L, num_inserted_rows#24237L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_3, Aggregate [id#24073, srch_ci#24113, srch_co#24114], [id#24073, avg(avg_tmpr_c#24068) AS avg_order_tmpr_c#24044, srch_ci#24113, srch_co#24114, CASE WHEN ((max(wthr_date#24077) = srch_co#24114) AND (min(wthr_date#24077) = srch_ci#24113)) THEN (last(avg_tmpr_c#24068, false) - first(avg_tmpr_c#24068, false)) END AS tmpr_diff#24047], [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- SortAggregate(key=[id#24073, srch_ci#24113, srch_co#24114], functions=[finalmerge_avg(merge sum#24184, count#24185L) AS avg(avg_tmpr_c#24068)#24121, finalmerge_max(merge max#24187) AS max(wthr_date#24077)#24122, finalmerge_min(merge min#24189) AS min(wthr_date#24077)#24123, finalmerge_last(merge last#24192, valueSet#24193) AS last(avg_tmpr_c#24068)()#24045, finalmerge_first(merge first#24196, valueSet#24197) AS first(avg_tmpr_c#24068)()#24046], output=[id#24073, avg_order_tmpr_c#24044, srch_ci#24113, srch_co#24114, tmpr_diff#24047])\n      +- Sort [id#24073 ASC NULLS FIRST, srch_ci#24113 ASC NULLS FIRST, srch_co#24114 ASC NULLS FIRST], false, 0\n         +- Exchange hashpartitioning(id#24073, srch_ci#24113, srch_co#24114, 200), ENSURE_REQUIREMENTS, [id=#14897]\n            +- SortAggregate(key=[id#24073, srch_ci#24113, srch_co#24114], functions=[partial_avg(avg_tmpr_c#24068) AS (sum#24184, count#24185L), partial_max(wthr_date#24077) AS max#24187, partial_min(wthr_date#24077) AS min#24189, partial_last(avg_tmpr_c#24068, false) AS (last#24192, valueSet#24193), partial_first(avg_tmpr_c#24068, false) AS (first#24196, valueSet#24197)], output=[id#24073, srch_ci#24113, srch_co#24114, sum#24184, count#24185L, max#24187, min#24189, last#24192, valueSet#24193, first#24196, valueSet#24197])\n               +- Sort [id#24073 ASC NULLS FIRST, srch_ci#24113 ASC NULLS FIRST, srch_co#24114 ASC NULLS FIRST], false, 0\n                  +- Sort [id#24073 ASC NULLS FIRST, wthr_date#24077 ASC NULLS FIRST], true, 0\n                     +- Exchange rangepartitioning(id#24073 ASC NULLS FIRST, wthr_date#24077 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#14891]\n                        +- Project [id#24073, avg_tmpr_c#24068, wthr_date#24077, srch_ci#24113, srch_co#24114]\n                           +- BroadcastHashJoin [cast(id#24073 as bigint)], [hotel_id#24120L], Inner, BuildLeft, ((wthr_date#24077 &gt;= srch_ci#24113) AND (wthr_date#24077 &lt;= srch_co#24114)), false\n                              :- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[1, string, false] as bigint)),false), [id=#14887]\n                              :  +- Filter (isnotnull(wthr_date#24077) AND isnotnull(id#24073))\n                              :     +- FileScan parquet spark_sql.hotel_weather[avg_tmpr_c#24068,id#24073,wthr_date#24077] Batched: true, DataFilters: [isnotnull(wthr_date#24077), isnotnull(id#24073)], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/hotel_weather], PartitionFilters: [], PushedFilters: [IsNotNull(wthr_date), IsNotNull(id)], ReadSchema: struct&lt;avg_tmpr_c:double,id:string,wthr_date:string&gt;\n                              +- Filter (((isnotnull(srch_co#24114) AND isnotnull(srch_ci#24113)) AND (datediff(cast(srch_co#24114 as date), cast(srch_ci#24113 as date)) &gt; 7)) AND isnotnull(hotel_id#24120L))\n                                 +- FileScan parquet spark_sql.expedia[srch_ci#24113,srch_co#24114,hotel_id#24120L] Batched: true, DataFilters: [isnotnull(srch_co#24114), isnotnull(srch_ci#24113), (datediff(cast(srch_co#24114 as date), cast(..., Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [IsNotNull(srch_co), IsNotNull(srch_ci), IsNotNull(hotel_id)], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_3], false, true\n+- &#39;Aggregate [&#39;id, &#39;srch_ci, &#39;srch_co], [&#39;id, &#39;avg(&#39;avg_tmpr_c) AS avg_order_tmpr_c#24044, &#39;srch_ci, &#39;srch_co, CASE WHEN ((&#39;max(&#39;wthr_date) = &#39;srch_co) AND (&#39;min(&#39;wthr_date) = &#39;srch_ci)) THEN (last(&#39;avg_tmpr_c, false) - first(&#39;avg_tmpr_c, false)) ELSE null END AS tmpr_diff#24047]\n   +- &#39;UnresolvedRelation [join_data_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_3, true\n+- Aggregate [id#24048, srch_ci#24051, srch_co#24052], [id#24048, avg(avg_tmpr_c#24049) AS avg_order_tmpr_c#24044, srch_ci#24051, srch_co#24052, CASE WHEN ((max(wthr_date#24050) = srch_co#24052) AND (min(wthr_date#24050) = srch_ci#24051)) THEN (last(avg_tmpr_c#24049, false) - first(avg_tmpr_c#24049, false)) ELSE cast(null as double) END AS tmpr_diff#24047]\n   +- SubqueryAlias spark_catalog.spark_sql.join_data_view\n      +- View (`spark_sql`.`join_data_view`, [id#24048,avg_tmpr_c#24049,wthr_date#24050,srch_ci#24051,srch_co#24052])\n         +- Project [cast(id#24073 as string) AS id#24048, cast(avg_tmpr_c#24068 as double) AS avg_tmpr_c#24049, cast(wthr_date#24077 as string) AS wthr_date#24050, cast(srch_ci#24113 as string) AS srch_ci#24051, cast(srch_co#24114 as string) AS srch_co#24052]\n            +- Sort [id#24073 ASC NULLS FIRST, wthr_date#24077 ASC NULLS FIRST], true\n               +- Project [id#24073, avg_tmpr_c#24068, wthr_date#24077, srch_ci#24113, srch_co#24114]\n                  +- Filter (((wthr_date#24077 &gt;= srch_ci#24113) AND (wthr_date#24077 &lt;= srch_co#24114)) AND (datediff(cast(srch_co#24114 as date), cast(srch_ci#24113 as date)) &gt; 7))\n                     +- Join Inner, (cast(id#24073 as bigint) = hotel_id#24120L)\n                        :- SubqueryAlias hw\n                        :  +- SubqueryAlias spark_catalog.spark_sql.hotel_weather\n                        :     +- Relation[address#24067,avg_tmpr_c#24068,avg_tmpr_f#24069,city#24070,country#24071,geoHash#24072,id#24073,latitude#24074,longitude#24075,name#24076,wthr_date#24077,year#24078,month#24079,day#24080] parquet\n                        +- SubqueryAlias ex\n                           +- SubqueryAlias spark_catalog.spark_sql.expedia\n                              +- Relation[id#24101L,date_time#24102,site_name#24103,posa_continent#24104,user_location_country#24105,user_location_region#24106,user_location_city#24107,orig_destination_distance#24108,user_id#24109,is_mobile#24110,is_package#24111,channel#24112,srch_ci#24113,srch_co#24114,srch_adults_cnt#24115,srch_children_cnt#24116,srch_rm_cnt#24117,srch_destination_id#24118,srch_destination_type_id#24119,hotel_id#24120L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_3, true\n+- Aggregate [id#24073, srch_ci#24113, srch_co#24114], [id#24073, avg(avg_tmpr_c#24068) AS avg_order_tmpr_c#24044, srch_ci#24113, srch_co#24114, CASE WHEN ((max(wthr_date#24077) = srch_co#24114) AND (min(wthr_date#24077) = srch_ci#24113)) THEN (last(avg_tmpr_c#24068, false) - first(avg_tmpr_c#24068, false)) END AS tmpr_diff#24047]\n   +- Sort [id#24073 ASC NULLS FIRST, wthr_date#24077 ASC NULLS FIRST], true\n      +- Project [id#24073, avg_tmpr_c#24068, wthr_date#24077, srch_ci#24113, srch_co#24114]\n         +- Join Inner, (((wthr_date#24077 &gt;= srch_ci#24113) AND (wthr_date#24077 &lt;= srch_co#24114)) AND (cast(id#24073 as bigint) = hotel_id#24120L))\n            :- Project [avg_tmpr_c#24068, id#24073, wthr_date#24077]\n            :  +- Filter (isnotnull(wthr_date#24077) AND isnotnull(id#24073))\n            :     +- Relation[address#24067,avg_tmpr_c#24068,avg_tmpr_f#24069,city#24070,country#24071,geoHash#24072,id#24073,latitude#24074,longitude#24075,name#24076,wthr_date#24077,year#24078,month#24079,day#24080] parquet\n            +- Project [srch_ci#24113, srch_co#24114, hotel_id#24120L]\n               +- Filter (((isnotnull(srch_co#24114) AND isnotnull(srch_ci#24113)) AND (datediff(cast(srch_co#24114 as date), cast(srch_ci#24113 as date)) &gt; 7)) AND isnotnull(hotel_id#24120L))\n                  +- Relation[id#24101L,date_time#24102,site_name#24103,posa_continent#24104,user_location_country#24105,user_location_region#24106,user_location_city#24107,orig_destination_distance#24108,user_id#24109,is_mobile#24110,is_package#24111,channel#24112,srch_ci#24113,srch_co#24114,srch_adults_cnt#24115,srch_children_cnt#24116,srch_rm_cnt#24117,srch_destination_id#24118,srch_destination_type_id#24119,hotel_id#24120L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#24236L, num_inserted_rows#24237L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5f0842b1, spark_sql.query_3, Aggregate [id#24073, srch_ci#24113, srch_co#24114], [id#24073, avg(avg_tmpr_c#24068) AS avg_order_tmpr_c#24044, srch_ci#24113, srch_co#24114, CASE WHEN ((max(wthr_date#24077) = srch_co#24114) AND (min(wthr_date#24077) = srch_ci#24113)) THEN (last(avg_tmpr_c#24068, false) - first(avg_tmpr_c#24068, false)) END AS tmpr_diff#24047], [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- SortAggregate(key=[id#24073, srch_ci#24113, srch_co#24114], functions=[finalmerge_avg(merge sum#24184, count#24185L) AS avg(avg_tmpr_c#24068)#24121, finalmerge_max(merge max#24187) AS max(wthr_date#24077)#24122, finalmerge_min(merge min#24189) AS min(wthr_date#24077)#24123, finalmerge_last(merge last#24192, valueSet#24193) AS last(avg_tmpr_c#24068)()#24045, finalmerge_first(merge first#24196, valueSet#24197) AS first(avg_tmpr_c#24068)()#24046], output=[id#24073, avg_order_tmpr_c#24044, srch_ci#24113, srch_co#24114, tmpr_diff#24047])\n      +- Sort [id#24073 ASC NULLS FIRST, srch_ci#24113 ASC NULLS FIRST, srch_co#24114 ASC NULLS FIRST], false, 0\n         +- Exchange hashpartitioning(id#24073, srch_ci#24113, srch_co#24114, 200), ENSURE_REQUIREMENTS, [id=#14897]\n            +- SortAggregate(key=[id#24073, srch_ci#24113, srch_co#24114], functions=[partial_avg(avg_tmpr_c#24068) AS (sum#24184, count#24185L), partial_max(wthr_date#24077) AS max#24187, partial_min(wthr_date#24077) AS min#24189, partial_last(avg_tmpr_c#24068, false) AS (last#24192, valueSet#24193), partial_first(avg_tmpr_c#24068, false) AS (first#24196, valueSet#24197)], output=[id#24073, srch_ci#24113, srch_co#24114, sum#24184, count#24185L, max#24187, min#24189, last#24192, valueSet#24193, first#24196, valueSet#24197])\n               +- Sort [id#24073 ASC NULLS FIRST, srch_ci#24113 ASC NULLS FIRST, srch_co#24114 ASC NULLS FIRST], false, 0\n                  +- Sort [id#24073 ASC NULLS FIRST, wthr_date#24077 ASC NULLS FIRST], true, 0\n                     +- Exchange rangepartitioning(id#24073 ASC NULLS FIRST, wthr_date#24077 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#14891]\n                        +- Project [id#24073, avg_tmpr_c#24068, wthr_date#24077, srch_ci#24113, srch_co#24114]\n                           +- BroadcastHashJoin [cast(id#24073 as bigint)], [hotel_id#24120L], Inner, BuildLeft, ((wthr_date#24077 &gt;= srch_ci#24113) AND (wthr_date#24077 &lt;= srch_co#24114)), false\n                              :- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[1, string, false] as bigint)),false), [id=#14887]\n                              :  +- Filter (isnotnull(wthr_date#24077) AND isnotnull(id#24073))\n                              :     +- FileScan parquet spark_sql.hotel_weather[avg_tmpr_c#24068,id#24073,wthr_date#24077] Batched: true, DataFilters: [isnotnull(wthr_date#24077), isnotnull(id#24073)], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/hotel_weather], PartitionFilters: [], PushedFilters: [IsNotNull(wthr_date), IsNotNull(id)], ReadSchema: struct&lt;avg_tmpr_c:double,id:string,wthr_date:string&gt;\n                              +- Filter (((isnotnull(srch_co#24114) AND isnotnull(srch_ci#24113)) AND (datediff(cast(srch_co#24114 as date), cast(srch_ci#24113 as date)) &gt; 7)) AND isnotnull(hotel_id#24120L))\n                                 +- FileScan parquet spark_sql.expedia[srch_ci#24113,srch_co#24114,hotel_id#24120L] Batched: true, DataFilters: [isnotnull(srch_co#24114), isnotnull(srch_ci#24113), (datediff(cast(srch_co#24114 as date), cast(..., Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [IsNotNull(srch_co), IsNotNull(srch_ci), IsNotNull(hotel_id)], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"spark_sql","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1211130925213075}},"nbformat":4,"nbformat_minor":0}
=======
{"cells":[{"cell_type":"markdown","source":["# Spark SQL\n* Top 10 hotels with max absolute temperature difference by month.\n* Top 10 busy (e.g., with the biggest visits count) hotels for each month. If visit dates refer to several months, it should be counted for all affected months.\n* For visits with extended stay (more than 7 days) calculate weather trend (the day temperature difference between last and first day of stay) and average temperature during stay."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56881a3c-061d-4626-8ca5-2500727e1d4e"}}},{"cell_type":"code","source":["from pyspark import sql\nimport os"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b68c7ce3-de9d-46d1-8078-00b95828e9b7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["session = sql.SparkSession.builder.getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1c4393d-6e57-4fe6-ad66-c64f43a577be"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"create database if not exists spark_sql\")\nsession.sql(\"use spark_sql\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"438f7088-966c-402d-85a2-1d1f42a9dbc9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[145]: DataFrame[]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[145]: DataFrame[]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["session.conf.set(\"fs.azure.account.auth.type.{}.dfs.core.windows.net\".format(os.getenv(\"account_load_name\")),os.getenv(\"auth_type\"))\nsession.conf.set(\"fs.azure.account.oauth.provider.type.{}.dfs.core.windows.net\".format(os.getenv(\"account_load_name\")),os.getenv(\"provider_type\"))\nsession.conf.set(\"fs.azure.account.oauth2.client.id.{}.dfs.core.windows.net\".format(os.getenv(\"account_load_name\")),os.getenv(\"client_id\"))\nsession.conf.set(\"fs.azure.account.oauth2.client.secret.{}.dfs.core.windows.net\".format(os.getenv(\"account_load_name\")),os.getenv(\"client_secret\"))\nsession.conf.set(\"fs.azure.account.oauth2.client.endpoint.{}.dfs.core.windows.net\".format(os.getenv(\"account_load_name\")),os.getenv(\"client_endpoint\"))\nsession.conf.set(\"fs.azure.account.key.{}.dfs.core.windows.net\".format(os.getenv(\"account_upload_name\")),os.getenv(\"account_key\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70886f16-6ac3-40c1-874f-0264784a5b44"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["hotel_weather_DF= session.read.parquet(os.getenv(\"hotel_weather_path\"))\nexpedia_DF = session.read.format(\"avro\").load(os.getenv(\"expedia_path\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Creating DFs according to data from Azure storage ","showTitle":true,"inputWidgets":{},"nuid":"0590d695-027f-46f3-87e3-81e615764856"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"drop table if exists hotel_weather\")\nsession.sql(\"drop table if exists expedia\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a66d916-83c8-40f2-9d1f-1a370869348c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["hotel_weather_DF.orderBy(\"wthr_date\").write.saveAsTable(\"hotel_weather\")\nexpedia_DF.write.saveAsTable(\"expedia\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Creating SQL tables from DFs","showTitle":true,"inputWidgets":{},"nuid":"1ef01973-d153-4b50-9b67-08d4ec194bca"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["session.sql(\"optimize hotel_weather\")\nsession.sql(\"optimize expedia\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a578090-a7db-485b-8d3d-24ab776f3ce3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"drop view if exists expedia_month_sum_view\")\nsession.sql(\"drop view if exists join_data_view\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad381d50-d5a3-4303-9a89-383739342cf4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Support procedures\n* analyze_plan - provide detailed plan information about sql statement\n* show_query - execute sql request and demonstrate result\n* save_query - execute sql request and save data from table to Azure blo storage"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f3032c63-fde8-4576-adc3-1e51d4e4d2e3"}}},{"cell_type":"code","source":["def analyze_plan(sql_select:str,is_extended: bool = True) -> None:\n  session.sql(sql_select).explain(extended=is_extended)\n\ndef show_query(sql_select:str) -> None:\n  session.sql(sql_select).show()\n\ndef save_query(sql_select:str,table:str,upload_path:str=os.getenv(\"upload_path\"),mode:str=\"overwrite\",partition:tuple=()) -> None:\n  \n  session.sql(sql_select)\n\n  session.table(table).write.parquet(path=\"{}/{}/\".format(upload_path,table),mode=mode,partitionBy=partition)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f50d6712-ef54-4f5c-8ccf-f458465df844"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"drop table if exists query_1\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7eb764e8-021f-4211-b717-68c767c9e18e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Spark SQL - Query 1\n* Summarize avg_tmpr_c by id,year,month\n* After grouping we need to calculate the difference between previously month and apply abs function"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18f9378b-29c0-4db7-a31b-01fa58dcbbe5"}}},{"cell_type":"markdown","source":["# Full plan for query 1\n\n** Parsed Logical Plan **\n\n*In general on this step we need to pasre our request for checking sql syntax, columns or table name, as we can see: 1) the first entry point feature is CreateTableAsSelectStatement that allows to create table as select in case of need; 2) define limit clause in query (in our case is 10); 3) define sort type and values (in our case is sum_avg_tmpr_c_diff with DESC); 4) in Project feature we can select number of select statements (names, definitions); 5) drafting subqueries are for selecting data from a table referenced in the outer query; 6) Add aggregate functions (in our case sum for avg_tmpr_c ). *\n\n** Analyzed Plan **\n\n*After parsing logical plan we can start to analyze (resolve semantics) it, for this, we will use catalog (repository with info about Spark table, DF or dataset): 1) num_affected_rows function returns the number of affected rows 2) feature CreateTableAsSelectStatement allows to create table according to DeltaCatalog; 3) define limit clause in query (in our case is 10); 4) define sort type and values (in our case is sum_avg_tmpr_c_diff with DESC); 5) analytics fucntions in context; 6) in Project feature we can select number of select statements (names, definitions); 7) drafting subqueries are for selecting data from a table referenced in the outer query; 8) Add aggregate functions (in our case sum for avg_tmpr_c ); 9) setting up relations from Catalog. *\n\n** Optimized Logical Plan **\n\n*In this step, we can start to optimize the plan using inner functionality - Catalust Optimize (CO) : in general, all steps from previous plan are the same, but in our case, CO will try to checks all the tasks which can be performed and computed together in one stage and optimize the query by evaluating the filter clause. *\n\n** Physical Plan **\n\n*This important plan generates different kinds of execution strategies and then keeps comparing them in the Cost Model (it estimates the execution time and resources to be taken by each strategy). Finally, whichever strategy is going to be the best optimal one is selected as the Best Physical Plan : 1) the entry point feature is AtomicCreateTableAsSelect for creating table and checking num_affected_rows and num_inserted_rows; 2) involve feature TakeOrderedAndProject that allows giving a sub-query block a name , which can be referenced in several places within the query; 3) define sort type and values (in our case is sum_avg_tmpr_c_diff with DESC); 4) apply Exchange hashpartitioning for defining which rows are distributed across partitions based on the MurMur3 hash of partitioning expressions, because in our case we will group values (with default total count of partitions = 200); 5) apply HashAggregate operator, because in our case we will use sum function; 6) apply FileScan (it's logical scans over data sources) for batch queries. *"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc5f9be0-b1a8-4049-8978-ee9885fa80d2"}}},{"cell_type":"code","source":["query=\"\"\" \n          create table if not exists query_1 as\n          \n          select id,year,month,abs(sum_avg_tmpr_c - lag(sum_avg_tmpr_c) over (partition by id,year order by month)) as sum_avg_tmpr_c_diff from \n          \n          (select id,year,month,sum(avg_tmpr_c) as sum_avg_tmpr_c from hotel_weather group by id,year,month)\n          \n          order by sum_avg_tmpr_c_diff desc limit 10\"\"\"\n\nanalyze_plan(query)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"083a1424-ff3f-4964-86b9-54619e19950a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_1], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;sum_avg_tmpr_c_diff DESC NULLS LAST], true\n         +- &#39;Project [&#39;id, &#39;year, &#39;month, &#39;abs((&#39;sum_avg_tmpr_c - &#39;lag(&#39;sum_avg_tmpr_c) windowspecdefinition(&#39;id, &#39;year, &#39;month ASC NULLS FIRST, unspecifiedframe$()))) AS sum_avg_tmpr_c_diff#42]\n            +- &#39;SubqueryAlias __auto_generated_subquery_name\n               +- &#39;Aggregate [&#39;id, &#39;year, &#39;month], [&#39;id, &#39;year, &#39;month, &#39;sum(&#39;avg_tmpr_c) AS sum_avg_tmpr_c#41]\n                  +- &#39;UnresolvedRelation [hotel_weather], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5d29974a, default.query_1, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_avg_tmpr_c_diff#42 DESC NULLS LAST], true\n         +- Window [id#93, year#98, month#99, abs((sum_avg_tmpr_c#41 - lag(sum_avg_tmpr_c#41, -1, null) windowspecdefinition(id#93, year#98, month#99 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1))), false) AS sum_avg_tmpr_c_diff#42], [id#93, year#98], [month#99 ASC NULLS FIRST]\n            +- Project [id#93, year#98, month#99, sum_avg_tmpr_c#41]\n               +- SubqueryAlias __auto_generated_subquery_name\n                  +- Aggregate [id#93, year#98, month#99], [id#93, year#98, month#99, sum(avg_tmpr_c#88) AS sum_avg_tmpr_c#41]\n                     +- SubqueryAlias spark_catalog.default.hotel_weather\n                        +- Relation[address#87,avg_tmpr_c#88,avg_tmpr_f#89,city#90,country#91,geoHash#92,id#93,latitude#94,longitude#95,name#96,wthr_date#97,year#98,month#99,day#100] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5d29974a, default.query_1, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_avg_tmpr_c_diff#42 DESC NULLS LAST], true\n         +- Window [id#93, year#98, month#99, abs((sum_avg_tmpr_c#41 - lag(sum_avg_tmpr_c#41, -1, null) windowspecdefinition(id#93, year#98, month#99 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1))), false) AS sum_avg_tmpr_c_diff#42], [id#93, year#98], [month#99 ASC NULLS FIRST]\n            +- Aggregate [id#93, year#98, month#99], [id#93, year#98, month#99, sum(avg_tmpr_c#88) AS sum_avg_tmpr_c#41]\n               +- Project [avg_tmpr_c#88, id#93, year#98, month#99]\n                  +- Relation[address#87,avg_tmpr_c#88,avg_tmpr_f#89,city#90,country#91,geoHash#92,id#93,latitude#94,longitude#95,name#96,wthr_date#97,year#98,month#99,day#100] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#359L, num_inserted_rows#360L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5d29974a, default.query_1, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_avg_tmpr_c_diff#42 DESC NULLS LAST], output=[id#93,year#98,month#99,sum_avg_tmpr_c_diff#42])\n      +- Window [id#93, year#98, month#99, abs((sum_avg_tmpr_c#41 - lag(sum_avg_tmpr_c#41, -1, null) windowspecdefinition(id#93, year#98, month#99 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1))), false) AS sum_avg_tmpr_c_diff#42], [id#93, year#98], [month#99 ASC NULLS FIRST]\n         +- Sort [id#93 ASC NULLS FIRST, year#98 ASC NULLS FIRST, month#99 ASC NULLS FIRST], false, 0\n            +- Exchange hashpartitioning(id#93, year#98, 200), ENSURE_REQUIREMENTS, [id=#60]\n               +- HashAggregate(keys=[id#93, year#98, month#99], functions=[finalmerge_sum(merge sum#137) AS sum(avg_tmpr_c#88)#101], output=[id#93, year#98, month#99, sum_avg_tmpr_c#41])\n                  +- Exchange hashpartitioning(id#93, year#98, month#99, 200), ENSURE_REQUIREMENTS, [id=#57]\n                     +- HashAggregate(keys=[id#93, year#98, month#99], functions=[partial_sum(avg_tmpr_c#88) AS sum#137], output=[id#93, year#98, month#99, sum#137])\n                        +- FileScan parquet default.hotel_weather[avg_tmpr_c#88,id#93,year#98,month#99] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/hotel_weather], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;avg_tmpr_c:double,id:string,year:int,month:int&gt;\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_1], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;sum_avg_tmpr_c_diff DESC NULLS LAST], true\n         +- &#39;Project [&#39;id, &#39;year, &#39;month, &#39;abs((&#39;sum_avg_tmpr_c - &#39;lag(&#39;sum_avg_tmpr_c) windowspecdefinition(&#39;id, &#39;year, &#39;month ASC NULLS FIRST, unspecifiedframe$()))) AS sum_avg_tmpr_c_diff#42]\n            +- &#39;SubqueryAlias __auto_generated_subquery_name\n               +- &#39;Aggregate [&#39;id, &#39;year, &#39;month], [&#39;id, &#39;year, &#39;month, &#39;sum(&#39;avg_tmpr_c) AS sum_avg_tmpr_c#41]\n                  +- &#39;UnresolvedRelation [hotel_weather], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5d29974a, default.query_1, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_avg_tmpr_c_diff#42 DESC NULLS LAST], true\n         +- Window [id#93, year#98, month#99, abs((sum_avg_tmpr_c#41 - lag(sum_avg_tmpr_c#41, -1, null) windowspecdefinition(id#93, year#98, month#99 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1))), false) AS sum_avg_tmpr_c_diff#42], [id#93, year#98], [month#99 ASC NULLS FIRST]\n            +- Project [id#93, year#98, month#99, sum_avg_tmpr_c#41]\n               +- SubqueryAlias __auto_generated_subquery_name\n                  +- Aggregate [id#93, year#98, month#99], [id#93, year#98, month#99, sum(avg_tmpr_c#88) AS sum_avg_tmpr_c#41]\n                     +- SubqueryAlias spark_catalog.default.hotel_weather\n                        +- Relation[address#87,avg_tmpr_c#88,avg_tmpr_f#89,city#90,country#91,geoHash#92,id#93,latitude#94,longitude#95,name#96,wthr_date#97,year#98,month#99,day#100] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5d29974a, default.query_1, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [sum_avg_tmpr_c_diff#42 DESC NULLS LAST], true\n         +- Window [id#93, year#98, month#99, abs((sum_avg_tmpr_c#41 - lag(sum_avg_tmpr_c#41, -1, null) windowspecdefinition(id#93, year#98, month#99 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1))), false) AS sum_avg_tmpr_c_diff#42], [id#93, year#98], [month#99 ASC NULLS FIRST]\n            +- Aggregate [id#93, year#98, month#99], [id#93, year#98, month#99, sum(avg_tmpr_c#88) AS sum_avg_tmpr_c#41]\n               +- Project [avg_tmpr_c#88, id#93, year#98, month#99]\n                  +- Relation[address#87,avg_tmpr_c#88,avg_tmpr_f#89,city#90,country#91,geoHash#92,id#93,latitude#94,longitude#95,name#96,wthr_date#97,year#98,month#99,day#100] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#359L, num_inserted_rows#360L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@5d29974a, default.query_1, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[sum_avg_tmpr_c_diff#42 DESC NULLS LAST], output=[id#93,year#98,month#99,sum_avg_tmpr_c_diff#42])\n      +- Window [id#93, year#98, month#99, abs((sum_avg_tmpr_c#41 - lag(sum_avg_tmpr_c#41, -1, null) windowspecdefinition(id#93, year#98, month#99 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1))), false) AS sum_avg_tmpr_c_diff#42], [id#93, year#98], [month#99 ASC NULLS FIRST]\n         +- Sort [id#93 ASC NULLS FIRST, year#98 ASC NULLS FIRST, month#99 ASC NULLS FIRST], false, 0\n            +- Exchange hashpartitioning(id#93, year#98, 200), ENSURE_REQUIREMENTS, [id=#60]\n               +- HashAggregate(keys=[id#93, year#98, month#99], functions=[finalmerge_sum(merge sum#137) AS sum(avg_tmpr_c#88)#101], output=[id#93, year#98, month#99, sum_avg_tmpr_c#41])\n                  +- Exchange hashpartitioning(id#93, year#98, month#99, 200), ENSURE_REQUIREMENTS, [id=#57]\n                     +- HashAggregate(keys=[id#93, year#98, month#99], functions=[partial_sum(avg_tmpr_c#88) AS sum#137], output=[id#93, year#98, month#99, sum#137])\n                        +- FileScan parquet default.hotel_weather[avg_tmpr_c#88,id#93,year#98,month#99] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/hotel_weather], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;avg_tmpr_c:double,id:string,year:int,month:int&gt;\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"drop view if exists expedia_month_view\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4cbad62-d971-40ee-b836-d65f3bb77251"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Spark SQL - Query 2\n* First, we need to create a view that allows calculating the order expedia count for each month and hotel according to srch_co and srch_ci using maxtrix crossing and case functionality (as example order with date from 31.12.2018 to 02.01.2019 will refer to Jan (+1) and Dec (+1))\n* Select top 10 hotels for each month according to the max count by grouping and filtering"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5150ec0-056a-4b74-ab86-62e4ef5faad6"}}},{"cell_type":"code","source":["month_touple = \"(1,2,3,4,5,6,7,8,9,10,11,12)\"\n\nsession.sql(f\"\"\"\n        \n        create view expedia_month_view as \n        \n        select hotel_id,\n        \n        count(case when (month(srch_ci) in {month_touple} and month(srch_co) = 1) or\n        (month(srch_co) in {month_touple} and month(srch_ci) = 1) then 1 end) as jan,\n        \n        count(case when (month(srch_ci) in {month_touple} and month(srch_co) = 2) or\n        (month(srch_co) in {month_touple} and month(srch_ci) = 2) then 1 end) as feb,\n        \n        count(case when (month(srch_ci) in {month_touple} and month(srch_co) = 3) or\n        (month(srch_co) in {month_touple} and month(srch_ci) = 3) then 1 end) as mar,\n        \n        count(case when (month(srch_ci) in {month_touple} and month(srch_co) = 4) or\n        (month(srch_co) in {month_touple} and month(srch_ci) = 4) then 1 end) as apr,\n        \n        count(case when (month(srch_ci) in {month_touple} and month(srch_co) = 5) or\n        (month(srch_co) in {month_touple} and month(srch_ci) = 5) then 1 end) as may,\n        \n        count(case when (month(srch_ci) in {month_touple} and month(srch_co) = 6) or\n        (month(srch_co) in {month_touple} and month(srch_ci) = 6) then 1 end) as jun,\n        \n        count(case when (month(srch_ci) in {month_touple} and month(srch_co) = 7) or\n        (month(srch_co) in {month_touple} and month(srch_ci) = 7) then 1 end) as jul,\n        \n        count(case when (month(srch_ci) in {month_touple} and month(srch_co) = 8) or\n        (month(srch_co) in {month_touple} and month(srch_ci) = 8) then 1 end) as aug,\n        \n        count(case when (month(srch_ci) in {month_touple} and month(srch_co) = 9) or\n        (month(srch_co) in {month_touple} and month(srch_ci) = 9) then 1 end) as sep,\n        \n        count(case when (month(srch_ci) in {month_touple} and month(srch_co) = 10) or\n        (month(srch_co) in {month_touple} and month(srch_ci) = 10) then 1 end) as oct,\n        \n        count(case when (month(srch_ci) in {month_touple} and month(srch_co) = 11) or\n        (month(srch_co) in {month_touple} and month(srch_ci) = 11) then 1 end) as nov,\n        \n        count(case when (month(srch_ci) in {month_touple} and month(srch_co) = 12) or\n        (month(srch_co) in {month_touple} and month(srch_ci) = 12) then 1 end) as dec\n        \n        from (select hotel_id,srch_ci,srch_co from expedia)\n        \n        group by hotel_id\n        \n        \"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1eac07ac-85be-4a36-9331-757619033a77"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[9]: DataFrame[]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: DataFrame[]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["for month in ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']:\n    session.sql(f\"drop table if exists query_2_{month}\")\n    query = f\"create table if not exists query_2_{month} as select hotel_id,{month} from expedia_month_view order by {month} desc limit 10\"\n    analyze_plan(query)\n    save_query(query,f\"query_2_{month}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Iterating through months for selecting top 10 hotels according to the view","showTitle":true,"inputWidgets":{},"nuid":"caa66749-2df4-4e37-9ec0-10d7109482b0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_jan], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;jan DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;jan]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_jan, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [jan#29170L DESC NULLS LAST], true\n         +- Project [hotel_id#29169L, jan#29170L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_view\n               +- View (`spark_sql`.`expedia_month_view`, [hotel_id#29169L,jan#29170L,feb#29171L,mar#29172L,apr#29173L,may#29174L,jun#29175L,jul#29176L,aug#29177L,sep#29178L,oct#29179L,nov#29180L,dec#29181L])\n                  +- Project [cast(hotel_id#29221L as bigint) AS hotel_id#29169L, cast(jan#29157L as bigint) AS jan#29170L, cast(feb#29158L as bigint) AS feb#29171L, cast(mar#29159L as bigint) AS mar#29172L, cast(apr#29160L as bigint) AS apr#29173L, cast(may#29161L as bigint) AS may#29174L, cast(jun#29162L as bigint) AS jun#29175L, cast(jul#29163L as bigint) AS jul#29176L, cast(aug#29164L as bigint) AS aug#29177L, cast(sep#29165L as bigint) AS sep#29178L, cast(oct#29166L as bigint) AS oct#29179L, cast(nov#29167L as bigint) AS nov#29180L, cast(dec#29168L as bigint) AS dec#29181L]\n                     +- Aggregate [hotel_id#29221L], [hotel_id#29221L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 1)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 1))) THEN 1 END) AS jan#29157L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 2)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 2))) THEN 1 END) AS feb#29158L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 3)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 3))) THEN 1 END) AS mar#29159L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 4)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 4))) THEN 1 END) AS apr#29160L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 5)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 5))) THEN 1 END) AS may#29161L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 6)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 6))) THEN 1 END) AS jun#29162L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 7)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 7))) THEN 1 END) AS jul#29163L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 8)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 8))) THEN 1 END) AS aug#29164L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 9)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 9))) THEN 1 END) AS sep#29165L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 10)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 10))) THEN 1 END) AS oct#29166L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 11)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 11))) THEN 1 END) AS nov#29167L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 12)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 12))) THEN 1 END) AS dec#29168L]\n                        +- SubqueryAlias __auto_generated_subquery_name\n                           +- Project [hotel_id#29221L, srch_ci#29214, srch_co#29215]\n                              +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                 +- Relation[id#29202L,date_time#29203,site_name#29204,posa_continent#29205,user_location_country#29206,user_location_region#29207,user_location_city#29208,orig_destination_distance#29209,user_id#29210,is_mobile#29211,is_package#29212,channel#29213,srch_ci#29214,srch_co#29215,srch_adults_cnt#29216,srch_children_cnt#29217,srch_rm_cnt#29218,srch_destination_id#29219,srch_destination_type_id#29220,hotel_id#29221L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_jan, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [jan#29170L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#29221L], [hotel_id#29221L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#29215 as date)) = 1)) OR (month(cast(srch_co#29215 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#29214 as date)) = 1))) THEN 1 END) AS jan#29170L]\n            +- Project [hotel_id#29221L, srch_ci#29214, srch_co#29215]\n               +- Relation[id#29202L,date_time#29203,site_name#29204,posa_continent#29205,user_location_country#29206,user_location_region#29207,user_location_city#29208,orig_destination_distance#29209,user_id#29210,is_mobile#29211,is_package#29212,channel#29213,srch_ci#29214,srch_co#29215,srch_adults_cnt#29216,srch_children_cnt#29217,srch_rm_cnt#29218,srch_destination_id#29219,srch_destination_type_id#29220,hotel_id#29221L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#29278L, num_inserted_rows#29279L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_jan, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[jan#29170L DESC NULLS LAST], output=[hotel_id#29221L,jan#29170L])\n      +- HashAggregate(keys=[hotel_id#29221L], functions=[finalmerge_count(merge count#29261L) AS count(CASE WHEN ((month(cast(srch_ci#29214 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#29215 as date)) = 1)) OR (month(cast(srch_co#29215 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#29214 as date)) = 1))) THEN 1 END)#29222L], output=[hotel_id#29221L, jan#29170L])\n         +- Exchange hashpartitioning(hotel_id#29221L, 200), ENSURE_REQUIREMENTS, [id=#12849]\n            +- HashAggregate(keys=[hotel_id#29221L], functions=[partial_count(CASE WHEN ((month(cast(srch_ci#29214 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#29215 as date)) = 1)) OR (month(cast(srch_co#29215 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#29214 as date)) = 1))) THEN 1 END) AS count#29261L], output=[hotel_id#29221L, count#29261L])\n               +- FileScan parquet spark_sql.expedia[srch_ci#29214,srch_co#29215,hotel_id#29221L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_feb], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;feb DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;feb]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_feb, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [feb#29773L DESC NULLS LAST], true\n         +- Project [hotel_id#29771L, feb#29773L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_view\n               +- View (`spark_sql`.`expedia_month_view`, [hotel_id#29771L,jan#29772L,feb#29773L,mar#29774L,apr#29775L,may#29776L,jun#29777L,jul#29778L,aug#29779L,sep#29780L,oct#29781L,nov#29782L,dec#29783L])\n                  +- Project [cast(hotel_id#29823L as bigint) AS hotel_id#29771L, cast(jan#29759L as bigint) AS jan#29772L, cast(feb#29760L as bigint) AS feb#29773L, cast(mar#29761L as bigint) AS mar#29774L, cast(apr#29762L as bigint) AS apr#29775L, cast(may#29763L as bigint) AS may#29776L, cast(jun#29764L as bigint) AS jun#29777L, cast(jul#29765L as bigint) AS jul#29778L, cast(aug#29766L as bigint) AS aug#29779L, cast(sep#29767L as bigint) AS sep#29780L, cast(oct#29768L as bigint) AS oct#29781L, cast(nov#29769L as bigint) AS nov#29782L, cast(dec#29770L as bigint) AS dec#29783L]\n                     +- Aggregate [hotel_id#29823L], [hotel_id#29823L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 1)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 1))) THEN 1 END) AS jan#29759L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 2)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 2))) THEN 1 END) AS feb#29760L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 3)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 3))) THEN 1 END) AS mar#29761L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 4)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 4))) THEN 1 END) AS apr#29762L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 5)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 5))) THEN 1 END) AS may#29763L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 6)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 6))) THEN 1 END) AS jun#29764L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 7)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 7))) THEN 1 END) AS jul#29765L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 8)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 8))) THEN 1 END) AS aug#29766L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 9)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 9))) THEN 1 END) AS sep#29767L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 10)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 10))) THEN 1 END) AS oct#29768L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 11)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 11))) THEN 1 END) AS nov#29769L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 12)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 12))) THEN 1 END) AS dec#29770L]\n                        +- SubqueryAlias __auto_generated_subquery_name\n                           +- Project [hotel_id#29823L, srch_ci#29816, srch_co#29817]\n                              +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                 +- Relation[id#29804L,date_time#29805,site_name#29806,posa_continent#29807,user_location_country#29808,user_location_region#29809,user_location_city#29810,orig_destination_distance#29811,user_id#29812,is_mobile#29813,is_package#29814,channel#29815,srch_ci#29816,srch_co#29817,srch_adults_cnt#29818,srch_children_cnt#29819,srch_rm_cnt#29820,srch_destination_id#29821,srch_destination_type_id#29822,hotel_id#29823L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_feb, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [feb#29773L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#29823L], [hotel_id#29823L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#29817 as date)) = 2)) OR (month(cast(srch_co#29817 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#29816 as date)) = 2))) THEN 1 END) AS feb#29773L]\n            +- Project [hotel_id#29823L, srch_ci#29816, srch_co#29817]\n               +- Relation[id#29804L,date_time#29805,site_name#29806,posa_continent#29807,user_location_country#29808,user_location_region#29809,user_location_city#29810,orig_destination_distance#29811,user_id#29812,is_mobile#29813,is_package#29814,channel#29815,srch_ci#29816,srch_co#29817,srch_adults_cnt#29818,srch_children_cnt#29819,srch_rm_cnt#29820,srch_destination_id#29821,srch_destination_type_id#29822,hotel_id#29823L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#29880L, num_inserted_rows#29881L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_feb, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[feb#29773L DESC NULLS LAST], output=[hotel_id#29823L,feb#29773L])\n      +- HashAggregate(keys=[hotel_id#29823L], functions=[finalmerge_count(merge count#29863L) AS count(CASE WHEN ((month(cast(srch_ci#29816 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#29817 as date)) = 2)) OR (month(cast(srch_co#29817 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#29816 as date)) = 2))) THEN 1 END)#29825L], output=[hotel_id#29823L, feb#29773L])\n         +- Exchange hashpartitioning(hotel_id#29823L, 200), ENSURE_REQUIREMENTS, [id=#13324]\n            +- HashAggregate(keys=[hotel_id#29823L], functions=[partial_count(CASE WHEN ((month(cast(srch_ci#29816 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#29817 as date)) = 2)) OR (month(cast(srch_co#29817 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#29816 as date)) = 2))) THEN 1 END) AS count#29863L], output=[hotel_id#29823L, count#29863L])\n               +- FileScan parquet spark_sql.expedia[srch_ci#29816,srch_co#29817,hotel_id#29823L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_mar], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;mar DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;mar]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_mar, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [mar#30376L DESC NULLS LAST], true\n         +- Project [hotel_id#30373L, mar#30376L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_view\n               +- View (`spark_sql`.`expedia_month_view`, [hotel_id#30373L,jan#30374L,feb#30375L,mar#30376L,apr#30377L,may#30378L,jun#30379L,jul#30380L,aug#30381L,sep#30382L,oct#30383L,nov#30384L,dec#30385L])\n                  +- Project [cast(hotel_id#30425L as bigint) AS hotel_id#30373L, cast(jan#30361L as bigint) AS jan#30374L, cast(feb#30362L as bigint) AS feb#30375L, cast(mar#30363L as bigint) AS mar#30376L, cast(apr#30364L as bigint) AS apr#30377L, cast(may#30365L as bigint) AS may#30378L, cast(jun#30366L as bigint) AS jun#30379L, cast(jul#30367L as bigint) AS jul#30380L, cast(aug#30368L as bigint) AS aug#30381L, cast(sep#30369L as bigint) AS sep#30382L, cast(oct#30370L as bigint) AS oct#30383L, cast(nov#30371L as bigint) AS nov#30384L, cast(dec#30372L as bigint) AS dec#30385L]\n                     +- Aggregate [hotel_id#30425L], [hotel_id#30425L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 1)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 1))) THEN 1 END) AS jan#30361L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 2)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 2))) THEN 1 END) AS feb#30362L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 3)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 3))) THEN 1 END) AS mar#30363L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 4)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 4))) THEN 1 END) AS apr#30364L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 5)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 5))) THEN 1 END) AS may#30365L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 6)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 6))) THEN 1 END) AS jun#30366L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 7)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 7))) THEN 1 END) AS jul#30367L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 8)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 8))) THEN 1 END) AS aug#30368L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 9)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 9))) THEN 1 END) AS sep#30369L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 10)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 10))) THEN 1 END) AS oct#30370L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 11)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 11))) THEN 1 END) AS nov#30371L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 12)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 12))) THEN 1 END) AS dec#30372L]\n                        +- SubqueryAlias __auto_generated_subquery_name\n                           +- Project [hotel_id#30425L, srch_ci#30418, srch_co#30419]\n                              +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                 +- Relation[id#30406L,date_time#30407,site_name#30408,posa_continent#30409,user_location_country#30410,user_location_region#30411,user_location_city#30412,orig_destination_distance#30413,user_id#30414,is_mobile#30415,is_package#30416,channel#30417,srch_ci#30418,srch_co#30419,srch_adults_cnt#30420,srch_children_cnt#30421,srch_rm_cnt#30422,srch_destination_id#30423,srch_destination_type_id#30424,hotel_id#30425L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_mar, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [mar#30376L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#30425L], [hotel_id#30425L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#30419 as date)) = 3)) OR (month(cast(srch_co#30419 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#30418 as date)) = 3))) THEN 1 END) AS mar#30376L]\n            +- Project [hotel_id#30425L, srch_ci#30418, srch_co#30419]\n               +- Relation[id#30406L,date_time#30407,site_name#30408,posa_continent#30409,user_location_country#30410,user_location_region#30411,user_location_city#30412,orig_destination_distance#30413,user_id#30414,is_mobile#30415,is_package#30416,channel#30417,srch_ci#30418,srch_co#30419,srch_adults_cnt#30420,srch_children_cnt#30421,srch_rm_cnt#30422,srch_destination_id#30423,srch_destination_type_id#30424,hotel_id#30425L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#30482L, num_inserted_rows#30483L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_mar, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[mar#30376L DESC NULLS LAST], output=[hotel_id#30425L,mar#30376L])\n      +- HashAggregate(keys=[hotel_id#30425L], functions=[finalmerge_count(merge count#30465L) AS count(CASE WHEN ((month(cast(srch_ci#30418 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#30419 as date)) = 3)) OR (month(cast(srch_co#30419 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#30418 as date)) = 3))) THEN 1 END)#30428L], output=[hotel_id#30425L, mar#30376L])\n         +- Exchange hashpartitioning(hotel_id#30425L, 200), ENSURE_REQUIREMENTS, [id=#13799]\n            +- HashAggregate(keys=[hotel_id#30425L], functions=[partial_count(CASE WHEN ((month(cast(srch_ci#30418 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#30419 as date)) = 3)) OR (month(cast(srch_co#30419 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#30418 as date)) = 3))) THEN 1 END) AS count#30465L], output=[hotel_id#30425L, count#30465L])\n               +- FileScan parquet spark_sql.expedia[srch_ci#30418,srch_co#30419,hotel_id#30425L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_apr], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;apr DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;apr]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n*** WARNING: skipped 49274 bytes of output ***\n\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_oct], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;oct DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;oct]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_oct, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [oct#34597L DESC NULLS LAST], true\n         +- Project [hotel_id#34587L, oct#34597L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_view\n               +- View (`spark_sql`.`expedia_month_view`, [hotel_id#34587L,jan#34588L,feb#34589L,mar#34590L,apr#34591L,may#34592L,jun#34593L,jul#34594L,aug#34595L,sep#34596L,oct#34597L,nov#34598L,dec#34599L])\n                  +- Project [cast(hotel_id#34639L as bigint) AS hotel_id#34587L, cast(jan#34575L as bigint) AS jan#34588L, cast(feb#34576L as bigint) AS feb#34589L, cast(mar#34577L as bigint) AS mar#34590L, cast(apr#34578L as bigint) AS apr#34591L, cast(may#34579L as bigint) AS may#34592L, cast(jun#34580L as bigint) AS jun#34593L, cast(jul#34581L as bigint) AS jul#34594L, cast(aug#34582L as bigint) AS aug#34595L, cast(sep#34583L as bigint) AS sep#34596L, cast(oct#34584L as bigint) AS oct#34597L, cast(nov#34585L as bigint) AS nov#34598L, cast(dec#34586L as bigint) AS dec#34599L]\n                     +- Aggregate [hotel_id#34639L], [hotel_id#34639L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 1)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 1))) THEN 1 END) AS jan#34575L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 2)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 2))) THEN 1 END) AS feb#34576L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 3)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 3))) THEN 1 END) AS mar#34577L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 4)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 4))) THEN 1 END) AS apr#34578L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 5)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 5))) THEN 1 END) AS may#34579L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 6)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 6))) THEN 1 END) AS jun#34580L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 7)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 7))) THEN 1 END) AS jul#34581L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 8)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 8))) THEN 1 END) AS aug#34582L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 9)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 9))) THEN 1 END) AS sep#34583L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 10)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 10))) THEN 1 END) AS oct#34584L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 11)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 11))) THEN 1 END) AS nov#34585L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 12)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 12))) THEN 1 END) AS dec#34586L]\n                        +- SubqueryAlias __auto_generated_subquery_name\n                           +- Project [hotel_id#34639L, srch_ci#34632, srch_co#34633]\n                              +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                 +- Relation[id#34620L,date_time#34621,site_name#34622,posa_continent#34623,user_location_country#34624,user_location_region#34625,user_location_city#34626,orig_destination_distance#34627,user_id#34628,is_mobile#34629,is_package#34630,channel#34631,srch_ci#34632,srch_co#34633,srch_adults_cnt#34634,srch_children_cnt#34635,srch_rm_cnt#34636,srch_destination_id#34637,srch_destination_type_id#34638,hotel_id#34639L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_oct, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [oct#34597L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#34639L], [hotel_id#34639L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#34633 as date)) = 10)) OR (month(cast(srch_co#34633 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#34632 as date)) = 10))) THEN 1 END) AS oct#34597L]\n            +- Project [hotel_id#34639L, srch_ci#34632, srch_co#34633]\n               +- Relation[id#34620L,date_time#34621,site_name#34622,posa_continent#34623,user_location_country#34624,user_location_region#34625,user_location_city#34626,orig_destination_distance#34627,user_id#34628,is_mobile#34629,is_package#34630,channel#34631,srch_ci#34632,srch_co#34633,srch_adults_cnt#34634,srch_children_cnt#34635,srch_rm_cnt#34636,srch_destination_id#34637,srch_destination_type_id#34638,hotel_id#34639L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#34696L, num_inserted_rows#34697L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_oct, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[oct#34597L DESC NULLS LAST], output=[hotel_id#34639L,oct#34597L])\n      +- HashAggregate(keys=[hotel_id#34639L], functions=[finalmerge_count(merge count#34679L) AS count(CASE WHEN ((month(cast(srch_ci#34632 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#34633 as date)) = 10)) OR (month(cast(srch_co#34633 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#34632 as date)) = 10))) THEN 1 END)#34649L], output=[hotel_id#34639L, oct#34597L])\n         +- Exchange hashpartitioning(hotel_id#34639L, 200), ENSURE_REQUIREMENTS, [id=#17124]\n            +- HashAggregate(keys=[hotel_id#34639L], functions=[partial_count(CASE WHEN ((month(cast(srch_ci#34632 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#34633 as date)) = 10)) OR (month(cast(srch_co#34633 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#34632 as date)) = 10))) THEN 1 END) AS count#34679L], output=[hotel_id#34639L, count#34679L])\n               +- FileScan parquet spark_sql.expedia[srch_ci#34632,srch_co#34633,hotel_id#34639L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_nov], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;nov DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;nov]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_nov, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [nov#35200L DESC NULLS LAST], true\n         +- Project [hotel_id#35189L, nov#35200L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_view\n               +- View (`spark_sql`.`expedia_month_view`, [hotel_id#35189L,jan#35190L,feb#35191L,mar#35192L,apr#35193L,may#35194L,jun#35195L,jul#35196L,aug#35197L,sep#35198L,oct#35199L,nov#35200L,dec#35201L])\n                  +- Project [cast(hotel_id#35241L as bigint) AS hotel_id#35189L, cast(jan#35177L as bigint) AS jan#35190L, cast(feb#35178L as bigint) AS feb#35191L, cast(mar#35179L as bigint) AS mar#35192L, cast(apr#35180L as bigint) AS apr#35193L, cast(may#35181L as bigint) AS may#35194L, cast(jun#35182L as bigint) AS jun#35195L, cast(jul#35183L as bigint) AS jul#35196L, cast(aug#35184L as bigint) AS aug#35197L, cast(sep#35185L as bigint) AS sep#35198L, cast(oct#35186L as bigint) AS oct#35199L, cast(nov#35187L as bigint) AS nov#35200L, cast(dec#35188L as bigint) AS dec#35201L]\n                     +- Aggregate [hotel_id#35241L], [hotel_id#35241L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 1)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 1))) THEN 1 END) AS jan#35177L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 2)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 2))) THEN 1 END) AS feb#35178L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 3)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 3))) THEN 1 END) AS mar#35179L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 4)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 4))) THEN 1 END) AS apr#35180L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 5)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 5))) THEN 1 END) AS may#35181L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 6)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 6))) THEN 1 END) AS jun#35182L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 7)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 7))) THEN 1 END) AS jul#35183L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 8)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 8))) THEN 1 END) AS aug#35184L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 9)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 9))) THEN 1 END) AS sep#35185L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 10)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 10))) THEN 1 END) AS oct#35186L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 11)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 11))) THEN 1 END) AS nov#35187L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 12)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 12))) THEN 1 END) AS dec#35188L]\n                        +- SubqueryAlias __auto_generated_subquery_name\n                           +- Project [hotel_id#35241L, srch_ci#35234, srch_co#35235]\n                              +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                 +- Relation[id#35222L,date_time#35223,site_name#35224,posa_continent#35225,user_location_country#35226,user_location_region#35227,user_location_city#35228,orig_destination_distance#35229,user_id#35230,is_mobile#35231,is_package#35232,channel#35233,srch_ci#35234,srch_co#35235,srch_adults_cnt#35236,srch_children_cnt#35237,srch_rm_cnt#35238,srch_destination_id#35239,srch_destination_type_id#35240,hotel_id#35241L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_nov, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [nov#35200L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#35241L], [hotel_id#35241L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#35235 as date)) = 11)) OR (month(cast(srch_co#35235 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#35234 as date)) = 11))) THEN 1 END) AS nov#35200L]\n            +- Project [hotel_id#35241L, srch_ci#35234, srch_co#35235]\n               +- Relation[id#35222L,date_time#35223,site_name#35224,posa_continent#35225,user_location_country#35226,user_location_region#35227,user_location_city#35228,orig_destination_distance#35229,user_id#35230,is_mobile#35231,is_package#35232,channel#35233,srch_ci#35234,srch_co#35235,srch_adults_cnt#35236,srch_children_cnt#35237,srch_rm_cnt#35238,srch_destination_id#35239,srch_destination_type_id#35240,hotel_id#35241L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#35298L, num_inserted_rows#35299L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_nov, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[nov#35200L DESC NULLS LAST], output=[hotel_id#35241L,nov#35200L])\n      +- HashAggregate(keys=[hotel_id#35241L], functions=[finalmerge_count(merge count#35281L) AS count(CASE WHEN ((month(cast(srch_ci#35234 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#35235 as date)) = 11)) OR (month(cast(srch_co#35235 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#35234 as date)) = 11))) THEN 1 END)#35252L], output=[hotel_id#35241L, nov#35200L])\n         +- Exchange hashpartitioning(hotel_id#35241L, 200), ENSURE_REQUIREMENTS, [id=#17599]\n            +- HashAggregate(keys=[hotel_id#35241L], functions=[partial_count(CASE WHEN ((month(cast(srch_ci#35234 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#35235 as date)) = 11)) OR (month(cast(srch_co#35235 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#35234 as date)) = 11))) THEN 1 END) AS count#35281L], output=[hotel_id#35241L, count#35281L])\n               +- FileScan parquet spark_sql.expedia[srch_ci#35234,srch_co#35235,hotel_id#35241L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_dec], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;dec DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;dec]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_dec, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [dec#35803L DESC NULLS LAST], true\n         +- Project [hotel_id#35791L, dec#35803L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_view\n               +- View (`spark_sql`.`expedia_month_view`, [hotel_id#35791L,jan#35792L,feb#35793L,mar#35794L,apr#35795L,may#35796L,jun#35797L,jul#35798L,aug#35799L,sep#35800L,oct#35801L,nov#35802L,dec#35803L])\n                  +- Project [cast(hotel_id#35843L as bigint) AS hotel_id#35791L, cast(jan#35779L as bigint) AS jan#35792L, cast(feb#35780L as bigint) AS feb#35793L, cast(mar#35781L as bigint) AS mar#35794L, cast(apr#35782L as bigint) AS apr#35795L, cast(may#35783L as bigint) AS may#35796L, cast(jun#35784L as bigint) AS jun#35797L, cast(jul#35785L as bigint) AS jul#35798L, cast(aug#35786L as bigint) AS aug#35799L, cast(sep#35787L as bigint) AS sep#35800L, cast(oct#35788L as bigint) AS oct#35801L, cast(nov#35789L as bigint) AS nov#35802L, cast(dec#35790L as bigint) AS dec#35803L]\n                     +- Aggregate [hotel_id#35843L], [hotel_id#35843L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 1)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 1))) THEN 1 END) AS jan#35779L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 2)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 2))) THEN 1 END) AS feb#35780L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 3)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 3))) THEN 1 END) AS mar#35781L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 4)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 4))) THEN 1 END) AS apr#35782L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 5)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 5))) THEN 1 END) AS may#35783L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 6)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 6))) THEN 1 END) AS jun#35784L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 7)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 7))) THEN 1 END) AS jul#35785L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 8)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 8))) THEN 1 END) AS aug#35786L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 9)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 9))) THEN 1 END) AS sep#35787L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 10)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 10))) THEN 1 END) AS oct#35788L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 11)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 11))) THEN 1 END) AS nov#35789L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 12)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 12))) THEN 1 END) AS dec#35790L]\n                        +- SubqueryAlias __auto_generated_subquery_name\n                           +- Project [hotel_id#35843L, srch_ci#35836, srch_co#35837]\n                              +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                 +- Relation[id#35824L,date_time#35825,site_name#35826,posa_continent#35827,user_location_country#35828,user_location_region#35829,user_location_city#35830,orig_destination_distance#35831,user_id#35832,is_mobile#35833,is_package#35834,channel#35835,srch_ci#35836,srch_co#35837,srch_adults_cnt#35838,srch_children_cnt#35839,srch_rm_cnt#35840,srch_destination_id#35841,srch_destination_type_id#35842,hotel_id#35843L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_dec, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [dec#35803L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#35843L], [hotel_id#35843L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#35837 as date)) = 12)) OR (month(cast(srch_co#35837 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#35836 as date)) = 12))) THEN 1 END) AS dec#35803L]\n            +- Project [hotel_id#35843L, srch_ci#35836, srch_co#35837]\n               +- Relation[id#35824L,date_time#35825,site_name#35826,posa_continent#35827,user_location_country#35828,user_location_region#35829,user_location_city#35830,orig_destination_distance#35831,user_id#35832,is_mobile#35833,is_package#35834,channel#35835,srch_ci#35836,srch_co#35837,srch_adults_cnt#35838,srch_children_cnt#35839,srch_rm_cnt#35840,srch_destination_id#35841,srch_destination_type_id#35842,hotel_id#35843L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#35900L, num_inserted_rows#35901L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_dec, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[dec#35803L DESC NULLS LAST], output=[hotel_id#35843L,dec#35803L])\n      +- HashAggregate(keys=[hotel_id#35843L], functions=[finalmerge_count(merge count#35883L) AS count(CASE WHEN ((month(cast(srch_ci#35836 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#35837 as date)) = 12)) OR (month(cast(srch_co#35837 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#35836 as date)) = 12))) THEN 1 END)#35855L], output=[hotel_id#35843L, dec#35803L])\n         +- Exchange hashpartitioning(hotel_id#35843L, 200), ENSURE_REQUIREMENTS, [id=#18074]\n            +- HashAggregate(keys=[hotel_id#35843L], functions=[partial_count(CASE WHEN ((month(cast(srch_ci#35836 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#35837 as date)) = 12)) OR (month(cast(srch_co#35837 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#35836 as date)) = 12))) THEN 1 END) AS count#35883L], output=[hotel_id#35843L, count#35883L])\n               +- FileScan parquet spark_sql.expedia[srch_ci#35836,srch_co#35837,hotel_id#35843L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_jan], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;jan DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;jan]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_jan, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [jan#29170L DESC NULLS LAST], true\n         +- Project [hotel_id#29169L, jan#29170L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_view\n               +- View (`spark_sql`.`expedia_month_view`, [hotel_id#29169L,jan#29170L,feb#29171L,mar#29172L,apr#29173L,may#29174L,jun#29175L,jul#29176L,aug#29177L,sep#29178L,oct#29179L,nov#29180L,dec#29181L])\n                  +- Project [cast(hotel_id#29221L as bigint) AS hotel_id#29169L, cast(jan#29157L as bigint) AS jan#29170L, cast(feb#29158L as bigint) AS feb#29171L, cast(mar#29159L as bigint) AS mar#29172L, cast(apr#29160L as bigint) AS apr#29173L, cast(may#29161L as bigint) AS may#29174L, cast(jun#29162L as bigint) AS jun#29175L, cast(jul#29163L as bigint) AS jul#29176L, cast(aug#29164L as bigint) AS aug#29177L, cast(sep#29165L as bigint) AS sep#29178L, cast(oct#29166L as bigint) AS oct#29179L, cast(nov#29167L as bigint) AS nov#29180L, cast(dec#29168L as bigint) AS dec#29181L]\n                     +- Aggregate [hotel_id#29221L], [hotel_id#29221L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 1)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 1))) THEN 1 END) AS jan#29157L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 2)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 2))) THEN 1 END) AS feb#29158L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 3)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 3))) THEN 1 END) AS mar#29159L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 4)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 4))) THEN 1 END) AS apr#29160L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 5)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 5))) THEN 1 END) AS may#29161L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 6)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 6))) THEN 1 END) AS jun#29162L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 7)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 7))) THEN 1 END) AS jul#29163L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 8)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 8))) THEN 1 END) AS aug#29164L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 9)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 9))) THEN 1 END) AS sep#29165L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 10)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 10))) THEN 1 END) AS oct#29166L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 11)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 11))) THEN 1 END) AS nov#29167L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29215 as date)) = 12)) OR (month(cast(srch_co#29215 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29214 as date)) = 12))) THEN 1 END) AS dec#29168L]\n                        +- SubqueryAlias __auto_generated_subquery_name\n                           +- Project [hotel_id#29221L, srch_ci#29214, srch_co#29215]\n                              +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                 +- Relation[id#29202L,date_time#29203,site_name#29204,posa_continent#29205,user_location_country#29206,user_location_region#29207,user_location_city#29208,orig_destination_distance#29209,user_id#29210,is_mobile#29211,is_package#29212,channel#29213,srch_ci#29214,srch_co#29215,srch_adults_cnt#29216,srch_children_cnt#29217,srch_rm_cnt#29218,srch_destination_id#29219,srch_destination_type_id#29220,hotel_id#29221L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_jan, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [jan#29170L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#29221L], [hotel_id#29221L, count(CASE WHEN ((month(cast(srch_ci#29214 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#29215 as date)) = 1)) OR (month(cast(srch_co#29215 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#29214 as date)) = 1))) THEN 1 END) AS jan#29170L]\n            +- Project [hotel_id#29221L, srch_ci#29214, srch_co#29215]\n               +- Relation[id#29202L,date_time#29203,site_name#29204,posa_continent#29205,user_location_country#29206,user_location_region#29207,user_location_city#29208,orig_destination_distance#29209,user_id#29210,is_mobile#29211,is_package#29212,channel#29213,srch_ci#29214,srch_co#29215,srch_adults_cnt#29216,srch_children_cnt#29217,srch_rm_cnt#29218,srch_destination_id#29219,srch_destination_type_id#29220,hotel_id#29221L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#29278L, num_inserted_rows#29279L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_jan, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[jan#29170L DESC NULLS LAST], output=[hotel_id#29221L,jan#29170L])\n      +- HashAggregate(keys=[hotel_id#29221L], functions=[finalmerge_count(merge count#29261L) AS count(CASE WHEN ((month(cast(srch_ci#29214 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#29215 as date)) = 1)) OR (month(cast(srch_co#29215 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#29214 as date)) = 1))) THEN 1 END)#29222L], output=[hotel_id#29221L, jan#29170L])\n         +- Exchange hashpartitioning(hotel_id#29221L, 200), ENSURE_REQUIREMENTS, [id=#12849]\n            +- HashAggregate(keys=[hotel_id#29221L], functions=[partial_count(CASE WHEN ((month(cast(srch_ci#29214 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#29215 as date)) = 1)) OR (month(cast(srch_co#29215 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#29214 as date)) = 1))) THEN 1 END) AS count#29261L], output=[hotel_id#29221L, count#29261L])\n               +- FileScan parquet spark_sql.expedia[srch_ci#29214,srch_co#29215,hotel_id#29221L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_feb], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;feb DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;feb]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_feb, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [feb#29773L DESC NULLS LAST], true\n         +- Project [hotel_id#29771L, feb#29773L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_view\n               +- View (`spark_sql`.`expedia_month_view`, [hotel_id#29771L,jan#29772L,feb#29773L,mar#29774L,apr#29775L,may#29776L,jun#29777L,jul#29778L,aug#29779L,sep#29780L,oct#29781L,nov#29782L,dec#29783L])\n                  +- Project [cast(hotel_id#29823L as bigint) AS hotel_id#29771L, cast(jan#29759L as bigint) AS jan#29772L, cast(feb#29760L as bigint) AS feb#29773L, cast(mar#29761L as bigint) AS mar#29774L, cast(apr#29762L as bigint) AS apr#29775L, cast(may#29763L as bigint) AS may#29776L, cast(jun#29764L as bigint) AS jun#29777L, cast(jul#29765L as bigint) AS jul#29778L, cast(aug#29766L as bigint) AS aug#29779L, cast(sep#29767L as bigint) AS sep#29780L, cast(oct#29768L as bigint) AS oct#29781L, cast(nov#29769L as bigint) AS nov#29782L, cast(dec#29770L as bigint) AS dec#29783L]\n                     +- Aggregate [hotel_id#29823L], [hotel_id#29823L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 1)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 1))) THEN 1 END) AS jan#29759L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 2)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 2))) THEN 1 END) AS feb#29760L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 3)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 3))) THEN 1 END) AS mar#29761L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 4)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 4))) THEN 1 END) AS apr#29762L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 5)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 5))) THEN 1 END) AS may#29763L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 6)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 6))) THEN 1 END) AS jun#29764L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 7)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 7))) THEN 1 END) AS jul#29765L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 8)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 8))) THEN 1 END) AS aug#29766L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 9)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 9))) THEN 1 END) AS sep#29767L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 10)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 10))) THEN 1 END) AS oct#29768L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 11)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 11))) THEN 1 END) AS nov#29769L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#29817 as date)) = 12)) OR (month(cast(srch_co#29817 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#29816 as date)) = 12))) THEN 1 END) AS dec#29770L]\n                        +- SubqueryAlias __auto_generated_subquery_name\n                           +- Project [hotel_id#29823L, srch_ci#29816, srch_co#29817]\n                              +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                 +- Relation[id#29804L,date_time#29805,site_name#29806,posa_continent#29807,user_location_country#29808,user_location_region#29809,user_location_city#29810,orig_destination_distance#29811,user_id#29812,is_mobile#29813,is_package#29814,channel#29815,srch_ci#29816,srch_co#29817,srch_adults_cnt#29818,srch_children_cnt#29819,srch_rm_cnt#29820,srch_destination_id#29821,srch_destination_type_id#29822,hotel_id#29823L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_feb, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [feb#29773L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#29823L], [hotel_id#29823L, count(CASE WHEN ((month(cast(srch_ci#29816 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#29817 as date)) = 2)) OR (month(cast(srch_co#29817 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#29816 as date)) = 2))) THEN 1 END) AS feb#29773L]\n            +- Project [hotel_id#29823L, srch_ci#29816, srch_co#29817]\n               +- Relation[id#29804L,date_time#29805,site_name#29806,posa_continent#29807,user_location_country#29808,user_location_region#29809,user_location_city#29810,orig_destination_distance#29811,user_id#29812,is_mobile#29813,is_package#29814,channel#29815,srch_ci#29816,srch_co#29817,srch_adults_cnt#29818,srch_children_cnt#29819,srch_rm_cnt#29820,srch_destination_id#29821,srch_destination_type_id#29822,hotel_id#29823L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#29880L, num_inserted_rows#29881L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_feb, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[feb#29773L DESC NULLS LAST], output=[hotel_id#29823L,feb#29773L])\n      +- HashAggregate(keys=[hotel_id#29823L], functions=[finalmerge_count(merge count#29863L) AS count(CASE WHEN ((month(cast(srch_ci#29816 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#29817 as date)) = 2)) OR (month(cast(srch_co#29817 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#29816 as date)) = 2))) THEN 1 END)#29825L], output=[hotel_id#29823L, feb#29773L])\n         +- Exchange hashpartitioning(hotel_id#29823L, 200), ENSURE_REQUIREMENTS, [id=#13324]\n            +- HashAggregate(keys=[hotel_id#29823L], functions=[partial_count(CASE WHEN ((month(cast(srch_ci#29816 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#29817 as date)) = 2)) OR (month(cast(srch_co#29817 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#29816 as date)) = 2))) THEN 1 END) AS count#29863L], output=[hotel_id#29823L, count#29863L])\n               +- FileScan parquet spark_sql.expedia[srch_ci#29816,srch_co#29817,hotel_id#29823L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_mar], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;mar DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;mar]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_mar, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [mar#30376L DESC NULLS LAST], true\n         +- Project [hotel_id#30373L, mar#30376L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_view\n               +- View (`spark_sql`.`expedia_month_view`, [hotel_id#30373L,jan#30374L,feb#30375L,mar#30376L,apr#30377L,may#30378L,jun#30379L,jul#30380L,aug#30381L,sep#30382L,oct#30383L,nov#30384L,dec#30385L])\n                  +- Project [cast(hotel_id#30425L as bigint) AS hotel_id#30373L, cast(jan#30361L as bigint) AS jan#30374L, cast(feb#30362L as bigint) AS feb#30375L, cast(mar#30363L as bigint) AS mar#30376L, cast(apr#30364L as bigint) AS apr#30377L, cast(may#30365L as bigint) AS may#30378L, cast(jun#30366L as bigint) AS jun#30379L, cast(jul#30367L as bigint) AS jul#30380L, cast(aug#30368L as bigint) AS aug#30381L, cast(sep#30369L as bigint) AS sep#30382L, cast(oct#30370L as bigint) AS oct#30383L, cast(nov#30371L as bigint) AS nov#30384L, cast(dec#30372L as bigint) AS dec#30385L]\n                     +- Aggregate [hotel_id#30425L], [hotel_id#30425L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 1)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 1))) THEN 1 END) AS jan#30361L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 2)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 2))) THEN 1 END) AS feb#30362L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 3)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 3))) THEN 1 END) AS mar#30363L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 4)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 4))) THEN 1 END) AS apr#30364L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 5)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 5))) THEN 1 END) AS may#30365L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 6)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 6))) THEN 1 END) AS jun#30366L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 7)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 7))) THEN 1 END) AS jul#30367L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 8)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 8))) THEN 1 END) AS aug#30368L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 9)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 9))) THEN 1 END) AS sep#30369L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 10)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 10))) THEN 1 END) AS oct#30370L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 11)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 11))) THEN 1 END) AS nov#30371L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#30419 as date)) = 12)) OR (month(cast(srch_co#30419 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#30418 as date)) = 12))) THEN 1 END) AS dec#30372L]\n                        +- SubqueryAlias __auto_generated_subquery_name\n                           +- Project [hotel_id#30425L, srch_ci#30418, srch_co#30419]\n                              +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                 +- Relation[id#30406L,date_time#30407,site_name#30408,posa_continent#30409,user_location_country#30410,user_location_region#30411,user_location_city#30412,orig_destination_distance#30413,user_id#30414,is_mobile#30415,is_package#30416,channel#30417,srch_ci#30418,srch_co#30419,srch_adults_cnt#30420,srch_children_cnt#30421,srch_rm_cnt#30422,srch_destination_id#30423,srch_destination_type_id#30424,hotel_id#30425L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_mar, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [mar#30376L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#30425L], [hotel_id#30425L, count(CASE WHEN ((month(cast(srch_ci#30418 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#30419 as date)) = 3)) OR (month(cast(srch_co#30419 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#30418 as date)) = 3))) THEN 1 END) AS mar#30376L]\n            +- Project [hotel_id#30425L, srch_ci#30418, srch_co#30419]\n               +- Relation[id#30406L,date_time#30407,site_name#30408,posa_continent#30409,user_location_country#30410,user_location_region#30411,user_location_city#30412,orig_destination_distance#30413,user_id#30414,is_mobile#30415,is_package#30416,channel#30417,srch_ci#30418,srch_co#30419,srch_adults_cnt#30420,srch_children_cnt#30421,srch_rm_cnt#30422,srch_destination_id#30423,srch_destination_type_id#30424,hotel_id#30425L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#30482L, num_inserted_rows#30483L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_mar, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[mar#30376L DESC NULLS LAST], output=[hotel_id#30425L,mar#30376L])\n      +- HashAggregate(keys=[hotel_id#30425L], functions=[finalmerge_count(merge count#30465L) AS count(CASE WHEN ((month(cast(srch_ci#30418 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#30419 as date)) = 3)) OR (month(cast(srch_co#30419 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#30418 as date)) = 3))) THEN 1 END)#30428L], output=[hotel_id#30425L, mar#30376L])\n         +- Exchange hashpartitioning(hotel_id#30425L, 200), ENSURE_REQUIREMENTS, [id=#13799]\n            +- HashAggregate(keys=[hotel_id#30425L], functions=[partial_count(CASE WHEN ((month(cast(srch_ci#30418 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#30419 as date)) = 3)) OR (month(cast(srch_co#30419 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#30418 as date)) = 3))) THEN 1 END) AS count#30465L], output=[hotel_id#30425L, count#30465L])\n               +- FileScan parquet spark_sql.expedia[srch_ci#30418,srch_co#30419,hotel_id#30425L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_apr], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;apr DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;apr]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n*** WARNING: skipped 49274 bytes of output ***\n\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_oct], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;oct DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;oct]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_oct, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [oct#34597L DESC NULLS LAST], true\n         +- Project [hotel_id#34587L, oct#34597L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_view\n               +- View (`spark_sql`.`expedia_month_view`, [hotel_id#34587L,jan#34588L,feb#34589L,mar#34590L,apr#34591L,may#34592L,jun#34593L,jul#34594L,aug#34595L,sep#34596L,oct#34597L,nov#34598L,dec#34599L])\n                  +- Project [cast(hotel_id#34639L as bigint) AS hotel_id#34587L, cast(jan#34575L as bigint) AS jan#34588L, cast(feb#34576L as bigint) AS feb#34589L, cast(mar#34577L as bigint) AS mar#34590L, cast(apr#34578L as bigint) AS apr#34591L, cast(may#34579L as bigint) AS may#34592L, cast(jun#34580L as bigint) AS jun#34593L, cast(jul#34581L as bigint) AS jul#34594L, cast(aug#34582L as bigint) AS aug#34595L, cast(sep#34583L as bigint) AS sep#34596L, cast(oct#34584L as bigint) AS oct#34597L, cast(nov#34585L as bigint) AS nov#34598L, cast(dec#34586L as bigint) AS dec#34599L]\n                     +- Aggregate [hotel_id#34639L], [hotel_id#34639L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 1)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 1))) THEN 1 END) AS jan#34575L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 2)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 2))) THEN 1 END) AS feb#34576L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 3)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 3))) THEN 1 END) AS mar#34577L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 4)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 4))) THEN 1 END) AS apr#34578L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 5)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 5))) THEN 1 END) AS may#34579L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 6)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 6))) THEN 1 END) AS jun#34580L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 7)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 7))) THEN 1 END) AS jul#34581L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 8)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 8))) THEN 1 END) AS aug#34582L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 9)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 9))) THEN 1 END) AS sep#34583L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 10)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 10))) THEN 1 END) AS oct#34584L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 11)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 11))) THEN 1 END) AS nov#34585L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#34633 as date)) = 12)) OR (month(cast(srch_co#34633 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#34632 as date)) = 12))) THEN 1 END) AS dec#34586L]\n                        +- SubqueryAlias __auto_generated_subquery_name\n                           +- Project [hotel_id#34639L, srch_ci#34632, srch_co#34633]\n                              +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                 +- Relation[id#34620L,date_time#34621,site_name#34622,posa_continent#34623,user_location_country#34624,user_location_region#34625,user_location_city#34626,orig_destination_distance#34627,user_id#34628,is_mobile#34629,is_package#34630,channel#34631,srch_ci#34632,srch_co#34633,srch_adults_cnt#34634,srch_children_cnt#34635,srch_rm_cnt#34636,srch_destination_id#34637,srch_destination_type_id#34638,hotel_id#34639L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_oct, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [oct#34597L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#34639L], [hotel_id#34639L, count(CASE WHEN ((month(cast(srch_ci#34632 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#34633 as date)) = 10)) OR (month(cast(srch_co#34633 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#34632 as date)) = 10))) THEN 1 END) AS oct#34597L]\n            +- Project [hotel_id#34639L, srch_ci#34632, srch_co#34633]\n               +- Relation[id#34620L,date_time#34621,site_name#34622,posa_continent#34623,user_location_country#34624,user_location_region#34625,user_location_city#34626,orig_destination_distance#34627,user_id#34628,is_mobile#34629,is_package#34630,channel#34631,srch_ci#34632,srch_co#34633,srch_adults_cnt#34634,srch_children_cnt#34635,srch_rm_cnt#34636,srch_destination_id#34637,srch_destination_type_id#34638,hotel_id#34639L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#34696L, num_inserted_rows#34697L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_oct, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[oct#34597L DESC NULLS LAST], output=[hotel_id#34639L,oct#34597L])\n      +- HashAggregate(keys=[hotel_id#34639L], functions=[finalmerge_count(merge count#34679L) AS count(CASE WHEN ((month(cast(srch_ci#34632 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#34633 as date)) = 10)) OR (month(cast(srch_co#34633 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#34632 as date)) = 10))) THEN 1 END)#34649L], output=[hotel_id#34639L, oct#34597L])\n         +- Exchange hashpartitioning(hotel_id#34639L, 200), ENSURE_REQUIREMENTS, [id=#17124]\n            +- HashAggregate(keys=[hotel_id#34639L], functions=[partial_count(CASE WHEN ((month(cast(srch_ci#34632 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#34633 as date)) = 10)) OR (month(cast(srch_co#34633 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#34632 as date)) = 10))) THEN 1 END) AS count#34679L], output=[hotel_id#34639L, count#34679L])\n               +- FileScan parquet spark_sql.expedia[srch_ci#34632,srch_co#34633,hotel_id#34639L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_nov], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;nov DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;nov]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_nov, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [nov#35200L DESC NULLS LAST], true\n         +- Project [hotel_id#35189L, nov#35200L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_view\n               +- View (`spark_sql`.`expedia_month_view`, [hotel_id#35189L,jan#35190L,feb#35191L,mar#35192L,apr#35193L,may#35194L,jun#35195L,jul#35196L,aug#35197L,sep#35198L,oct#35199L,nov#35200L,dec#35201L])\n                  +- Project [cast(hotel_id#35241L as bigint) AS hotel_id#35189L, cast(jan#35177L as bigint) AS jan#35190L, cast(feb#35178L as bigint) AS feb#35191L, cast(mar#35179L as bigint) AS mar#35192L, cast(apr#35180L as bigint) AS apr#35193L, cast(may#35181L as bigint) AS may#35194L, cast(jun#35182L as bigint) AS jun#35195L, cast(jul#35183L as bigint) AS jul#35196L, cast(aug#35184L as bigint) AS aug#35197L, cast(sep#35185L as bigint) AS sep#35198L, cast(oct#35186L as bigint) AS oct#35199L, cast(nov#35187L as bigint) AS nov#35200L, cast(dec#35188L as bigint) AS dec#35201L]\n                     +- Aggregate [hotel_id#35241L], [hotel_id#35241L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 1)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 1))) THEN 1 END) AS jan#35177L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 2)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 2))) THEN 1 END) AS feb#35178L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 3)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 3))) THEN 1 END) AS mar#35179L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 4)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 4))) THEN 1 END) AS apr#35180L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 5)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 5))) THEN 1 END) AS may#35181L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 6)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 6))) THEN 1 END) AS jun#35182L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 7)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 7))) THEN 1 END) AS jul#35183L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 8)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 8))) THEN 1 END) AS aug#35184L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 9)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 9))) THEN 1 END) AS sep#35185L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 10)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 10))) THEN 1 END) AS oct#35186L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 11)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 11))) THEN 1 END) AS nov#35187L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35235 as date)) = 12)) OR (month(cast(srch_co#35235 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35234 as date)) = 12))) THEN 1 END) AS dec#35188L]\n                        +- SubqueryAlias __auto_generated_subquery_name\n                           +- Project [hotel_id#35241L, srch_ci#35234, srch_co#35235]\n                              +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                 +- Relation[id#35222L,date_time#35223,site_name#35224,posa_continent#35225,user_location_country#35226,user_location_region#35227,user_location_city#35228,orig_destination_distance#35229,user_id#35230,is_mobile#35231,is_package#35232,channel#35233,srch_ci#35234,srch_co#35235,srch_adults_cnt#35236,srch_children_cnt#35237,srch_rm_cnt#35238,srch_destination_id#35239,srch_destination_type_id#35240,hotel_id#35241L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_nov, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [nov#35200L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#35241L], [hotel_id#35241L, count(CASE WHEN ((month(cast(srch_ci#35234 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#35235 as date)) = 11)) OR (month(cast(srch_co#35235 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#35234 as date)) = 11))) THEN 1 END) AS nov#35200L]\n            +- Project [hotel_id#35241L, srch_ci#35234, srch_co#35235]\n               +- Relation[id#35222L,date_time#35223,site_name#35224,posa_continent#35225,user_location_country#35226,user_location_region#35227,user_location_city#35228,orig_destination_distance#35229,user_id#35230,is_mobile#35231,is_package#35232,channel#35233,srch_ci#35234,srch_co#35235,srch_adults_cnt#35236,srch_children_cnt#35237,srch_rm_cnt#35238,srch_destination_id#35239,srch_destination_type_id#35240,hotel_id#35241L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#35298L, num_inserted_rows#35299L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_nov, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[nov#35200L DESC NULLS LAST], output=[hotel_id#35241L,nov#35200L])\n      +- HashAggregate(keys=[hotel_id#35241L], functions=[finalmerge_count(merge count#35281L) AS count(CASE WHEN ((month(cast(srch_ci#35234 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#35235 as date)) = 11)) OR (month(cast(srch_co#35235 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#35234 as date)) = 11))) THEN 1 END)#35252L], output=[hotel_id#35241L, nov#35200L])\n         +- Exchange hashpartitioning(hotel_id#35241L, 200), ENSURE_REQUIREMENTS, [id=#17599]\n            +- HashAggregate(keys=[hotel_id#35241L], functions=[partial_count(CASE WHEN ((month(cast(srch_ci#35234 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#35235 as date)) = 11)) OR (month(cast(srch_co#35235 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#35234 as date)) = 11))) THEN 1 END) AS count#35281L], output=[hotel_id#35241L, count#35281L])\n               +- FileScan parquet spark_sql.expedia[srch_ci#35234,srch_co#35235,hotel_id#35241L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_2_dec], false, true\n+- &#39;GlobalLimit 10\n   +- &#39;LocalLimit 10\n      +- &#39;Sort [&#39;dec DESC NULLS LAST], true\n         +- &#39;Project [&#39;hotel_id, &#39;dec]\n            +- &#39;UnresolvedRelation [expedia_month_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_dec, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [dec#35803L DESC NULLS LAST], true\n         +- Project [hotel_id#35791L, dec#35803L]\n            +- SubqueryAlias spark_catalog.spark_sql.expedia_month_view\n               +- View (`spark_sql`.`expedia_month_view`, [hotel_id#35791L,jan#35792L,feb#35793L,mar#35794L,apr#35795L,may#35796L,jun#35797L,jul#35798L,aug#35799L,sep#35800L,oct#35801L,nov#35802L,dec#35803L])\n                  +- Project [cast(hotel_id#35843L as bigint) AS hotel_id#35791L, cast(jan#35779L as bigint) AS jan#35792L, cast(feb#35780L as bigint) AS feb#35793L, cast(mar#35781L as bigint) AS mar#35794L, cast(apr#35782L as bigint) AS apr#35795L, cast(may#35783L as bigint) AS may#35796L, cast(jun#35784L as bigint) AS jun#35797L, cast(jul#35785L as bigint) AS jul#35798L, cast(aug#35786L as bigint) AS aug#35799L, cast(sep#35787L as bigint) AS sep#35800L, cast(oct#35788L as bigint) AS oct#35801L, cast(nov#35789L as bigint) AS nov#35802L, cast(dec#35790L as bigint) AS dec#35803L]\n                     +- Aggregate [hotel_id#35843L], [hotel_id#35843L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 1)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 1))) THEN 1 END) AS jan#35779L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 2)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 2))) THEN 1 END) AS feb#35780L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 3)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 3))) THEN 1 END) AS mar#35781L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 4)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 4))) THEN 1 END) AS apr#35782L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 5)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 5))) THEN 1 END) AS may#35783L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 6)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 6))) THEN 1 END) AS jun#35784L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 7)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 7))) THEN 1 END) AS jul#35785L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 8)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 8))) THEN 1 END) AS aug#35786L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 9)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 9))) THEN 1 END) AS sep#35787L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 10)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 10))) THEN 1 END) AS oct#35788L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 11)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 11))) THEN 1 END) AS nov#35789L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_co#35837 as date)) = 12)) OR (month(cast(srch_co#35837 as date)) IN (1,2,3,4,5,6,7,8,9,10,11,12) AND (month(cast(srch_ci#35836 as date)) = 12))) THEN 1 END) AS dec#35790L]\n                        +- SubqueryAlias __auto_generated_subquery_name\n                           +- Project [hotel_id#35843L, srch_ci#35836, srch_co#35837]\n                              +- SubqueryAlias spark_catalog.spark_sql.expedia\n                                 +- Relation[id#35824L,date_time#35825,site_name#35826,posa_continent#35827,user_location_country#35828,user_location_region#35829,user_location_city#35830,orig_destination_distance#35831,user_id#35832,is_mobile#35833,is_package#35834,channel#35835,srch_ci#35836,srch_co#35837,srch_adults_cnt#35838,srch_children_cnt#35839,srch_rm_cnt#35840,srch_destination_id#35841,srch_destination_type_id#35842,hotel_id#35843L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_dec, true\n+- GlobalLimit 10\n   +- LocalLimit 10\n      +- Sort [dec#35803L DESC NULLS LAST], true\n         +- Aggregate [hotel_id#35843L], [hotel_id#35843L, count(CASE WHEN ((month(cast(srch_ci#35836 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#35837 as date)) = 12)) OR (month(cast(srch_co#35837 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#35836 as date)) = 12))) THEN 1 END) AS dec#35803L]\n            +- Project [hotel_id#35843L, srch_ci#35836, srch_co#35837]\n               +- Relation[id#35824L,date_time#35825,site_name#35826,posa_continent#35827,user_location_country#35828,user_location_region#35829,user_location_city#35830,orig_destination_distance#35831,user_id#35832,is_mobile#35833,is_package#35834,channel#35835,srch_ci#35836,srch_co#35837,srch_adults_cnt#35838,srch_children_cnt#35839,srch_rm_cnt#35840,srch_destination_id#35841,srch_destination_type_id#35842,hotel_id#35843L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#35900L, num_inserted_rows#35901L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_2_dec, GlobalLimit 10, [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- TakeOrderedAndProject(limit=10, orderBy=[dec#35803L DESC NULLS LAST], output=[hotel_id#35843L,dec#35803L])\n      +- HashAggregate(keys=[hotel_id#35843L], functions=[finalmerge_count(merge count#35883L) AS count(CASE WHEN ((month(cast(srch_ci#35836 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#35837 as date)) = 12)) OR (month(cast(srch_co#35837 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#35836 as date)) = 12))) THEN 1 END)#35855L], output=[hotel_id#35843L, dec#35803L])\n         +- Exchange hashpartitioning(hotel_id#35843L, 200), ENSURE_REQUIREMENTS, [id=#18074]\n            +- HashAggregate(keys=[hotel_id#35843L], functions=[partial_count(CASE WHEN ((month(cast(srch_ci#35836 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_co#35837 as date)) = 12)) OR (month(cast(srch_co#35837 as date)) INSET (5,10,1,6,9,2,12,7,3,11,8,4) AND (month(cast(srch_ci#35836 as date)) = 12))) THEN 1 END) AS count#35883L], output=[hotel_id#35843L, count#35883L])\n               +- FileScan parquet spark_sql.expedia[srch_ci#35836,srch_co#35837,hotel_id#35843L] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["session.sql(\"drop table if exists query_3\")\nsession.sql(\"drop view if exists join_data_view\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e0bae69-16ff-4d7c-97f5-a995e98cd5cd"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Spark SQL - Query 3\n* First, we need to create a view by joining expedia and hotel_weather, sort data by condition - extended stay (more than 7 days) and logical restriction - available weather in this period\n* Select expedia orders with calculating average, the temperature difference between first & last days (important note: for order without weather info in first or last days difference is null)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96f9c086-bcc3-4beb-a801-682fe29fd114"}}},{"cell_type":"code","source":["session.sql(\"\"\"\n          create view join_data_view as\n          \n          select hw.id,hw.avg_tmpr_c,hw.wthr_date,ex.srch_ci,ex.srch_co\n          \n          from hotel_weather as hw inner join expedia as ex on hw.id = ex.hotel_id \n          where hw.wthr_date>=ex.srch_ci and hw.wthr_date<=ex.srch_co and datediff(ex.srch_co,ex.srch_ci)>7\n         \n          order by hw.id,hw.wthr_date\n          \"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Query 3 ( we need to create a view as joining tables with selecting and ordering by id and weather date )","showTitle":false,"inputWidgets":{},"nuid":"02289e12-11a9-4ea8-b1fe-99d603152518"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[156]: DataFrame[]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[156]: DataFrame[]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["query = \"\"\"\n          create table if not exists query_3 as\n          \n          select id,avg(avg_tmpr_c) as avg_order_tmpr_c,srch_ci,srch_co,\n          \n          case when max(wthr_date)=srch_co and min(wthr_date)=srch_ci \n          then last(avg_tmpr_c)-first(avg_tmpr_c) else null end as tmpr_diff\n          \n          from join_data_view\n          \n          group by id,srch_ci,srch_co \n          \n          \"\"\"\nanalyze_plan(query)\nsave_query(query,\"query_3\",partition=(\"id\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Calculating average, first & last temperature difference for each order","showTitle":true,"inputWidgets":{},"nuid":"cce29114-2d02-44b7-898f-b7eb76d21501"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_3], false, true\n+- &#39;Aggregate [&#39;id, &#39;srch_ci, &#39;srch_co], [&#39;id, &#39;avg(&#39;avg_tmpr_c) AS avg_order_tmpr_c#36449, &#39;srch_ci, &#39;srch_co, CASE WHEN ((&#39;max(&#39;wthr_date) = &#39;srch_co) AND (&#39;min(&#39;wthr_date) = &#39;srch_ci)) THEN (last(&#39;avg_tmpr_c, false) - first(&#39;avg_tmpr_c, false)) ELSE null END AS tmpr_diff#36452]\n   +- &#39;UnresolvedRelation [join_data_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_3, true\n+- Aggregate [id#36453, srch_ci#36456, srch_co#36457], [id#36453, avg(avg_tmpr_c#36454) AS avg_order_tmpr_c#36449, srch_ci#36456, srch_co#36457, CASE WHEN ((max(wthr_date#36455) = srch_co#36457) AND (min(wthr_date#36455) = srch_ci#36456)) THEN (last(avg_tmpr_c#36454, false) - first(avg_tmpr_c#36454, false)) ELSE cast(null as double) END AS tmpr_diff#36452]\n   +- SubqueryAlias spark_catalog.spark_sql.join_data_view\n      +- View (`spark_sql`.`join_data_view`, [id#36453,avg_tmpr_c#36454,wthr_date#36455,srch_ci#36456,srch_co#36457])\n         +- Project [cast(id#36498 as string) AS id#36453, cast(avg_tmpr_c#36493 as double) AS avg_tmpr_c#36454, cast(wthr_date#36502 as string) AS wthr_date#36455, cast(srch_ci#36518 as string) AS srch_ci#36456, cast(srch_co#36519 as string) AS srch_co#36457]\n            +- Sort [id#36498 ASC NULLS FIRST, wthr_date#36502 ASC NULLS FIRST], true\n               +- Project [id#36498, avg_tmpr_c#36493, wthr_date#36502, srch_ci#36518, srch_co#36519]\n                  +- Filter (((wthr_date#36502 &gt;= srch_ci#36518) AND (wthr_date#36502 &lt;= srch_co#36519)) AND (datediff(cast(srch_co#36519 as date), cast(srch_ci#36518 as date)) &gt; 7))\n                     +- Join Inner, (cast(id#36498 as bigint) = hotel_id#36525L)\n                        :- SubqueryAlias hw\n                        :  +- SubqueryAlias spark_catalog.spark_sql.hotel_weather\n                        :     +- Relation[address#36492,avg_tmpr_c#36493,avg_tmpr_f#36494,city#36495,country#36496,geoHash#36497,id#36498,latitude#36499,longitude#36500,name#36501,wthr_date#36502,year#36503,month#36504,day#36505] parquet\n                        +- SubqueryAlias ex\n                           +- SubqueryAlias spark_catalog.spark_sql.expedia\n                              +- Relation[id#36506L,date_time#36507,site_name#36508,posa_continent#36509,user_location_country#36510,user_location_region#36511,user_location_city#36512,orig_destination_distance#36513,user_id#36514,is_mobile#36515,is_package#36516,channel#36517,srch_ci#36518,srch_co#36519,srch_adults_cnt#36520,srch_children_cnt#36521,srch_rm_cnt#36522,srch_destination_id#36523,srch_destination_type_id#36524,hotel_id#36525L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_3, true\n+- Aggregate [id#36498, srch_ci#36518, srch_co#36519], [id#36498, avg(avg_tmpr_c#36493) AS avg_order_tmpr_c#36449, srch_ci#36518, srch_co#36519, CASE WHEN ((max(wthr_date#36502) = srch_co#36519) AND (min(wthr_date#36502) = srch_ci#36518)) THEN (last(avg_tmpr_c#36493, false) - first(avg_tmpr_c#36493, false)) END AS tmpr_diff#36452]\n   +- Sort [id#36498 ASC NULLS FIRST, wthr_date#36502 ASC NULLS FIRST], true\n      +- Project [id#36498, avg_tmpr_c#36493, wthr_date#36502, srch_ci#36518, srch_co#36519]\n         +- Join Inner, (((wthr_date#36502 &gt;= srch_ci#36518) AND (wthr_date#36502 &lt;= srch_co#36519)) AND (cast(id#36498 as bigint) = hotel_id#36525L))\n            :- Project [avg_tmpr_c#36493, id#36498, wthr_date#36502]\n            :  +- Filter (isnotnull(wthr_date#36502) AND isnotnull(id#36498))\n            :     +- Relation[address#36492,avg_tmpr_c#36493,avg_tmpr_f#36494,city#36495,country#36496,geoHash#36497,id#36498,latitude#36499,longitude#36500,name#36501,wthr_date#36502,year#36503,month#36504,day#36505] parquet\n            +- Project [srch_ci#36518, srch_co#36519, hotel_id#36525L]\n               +- Filter (((isnotnull(srch_co#36519) AND isnotnull(srch_ci#36518)) AND (datediff(cast(srch_co#36519 as date), cast(srch_ci#36518 as date)) &gt; 7)) AND isnotnull(hotel_id#36525L))\n                  +- Relation[id#36506L,date_time#36507,site_name#36508,posa_continent#36509,user_location_country#36510,user_location_region#36511,user_location_city#36512,orig_destination_distance#36513,user_id#36514,is_mobile#36515,is_package#36516,channel#36517,srch_ci#36518,srch_co#36519,srch_adults_cnt#36520,srch_children_cnt#36521,srch_rm_cnt#36522,srch_destination_id#36523,srch_destination_type_id#36524,hotel_id#36525L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#36641L, num_inserted_rows#36642L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_3, Aggregate [id#36498, srch_ci#36518, srch_co#36519], [id#36498, avg(avg_tmpr_c#36493) AS avg_order_tmpr_c#36449, srch_ci#36518, srch_co#36519, CASE WHEN ((max(wthr_date#36502) = srch_co#36519) AND (min(wthr_date#36502) = srch_ci#36518)) THEN (last(avg_tmpr_c#36493, false) - first(avg_tmpr_c#36493, false)) END AS tmpr_diff#36452], [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- SortAggregate(key=[id#36498, srch_ci#36518, srch_co#36519], functions=[finalmerge_avg(merge sum#36589, count#36590L) AS avg(avg_tmpr_c#36493)#36526, finalmerge_max(merge max#36592) AS max(wthr_date#36502)#36527, finalmerge_min(merge min#36594) AS min(wthr_date#36502)#36528, finalmerge_last(merge last#36597, valueSet#36598) AS last(avg_tmpr_c#36493)()#36450, finalmerge_first(merge first#36601, valueSet#36602) AS first(avg_tmpr_c#36493)()#36451], output=[id#36498, avg_order_tmpr_c#36449, srch_ci#36518, srch_co#36519, tmpr_diff#36452])\n      +- Sort [id#36498 ASC NULLS FIRST, srch_ci#36518 ASC NULLS FIRST, srch_co#36519 ASC NULLS FIRST], false, 0\n         +- Exchange hashpartitioning(id#36498, srch_ci#36518, srch_co#36519, 200), ENSURE_REQUIREMENTS, [id=#18583]\n            +- SortAggregate(key=[id#36498, srch_ci#36518, srch_co#36519], functions=[partial_avg(avg_tmpr_c#36493) AS (sum#36589, count#36590L), partial_max(wthr_date#36502) AS max#36592, partial_min(wthr_date#36502) AS min#36594, partial_last(avg_tmpr_c#36493, false) AS (last#36597, valueSet#36598), partial_first(avg_tmpr_c#36493, false) AS (first#36601, valueSet#36602)], output=[id#36498, srch_ci#36518, srch_co#36519, sum#36589, count#36590L, max#36592, min#36594, last#36597, valueSet#36598, first#36601, valueSet#36602])\n               +- Sort [id#36498 ASC NULLS FIRST, srch_ci#36518 ASC NULLS FIRST, srch_co#36519 ASC NULLS FIRST], false, 0\n                  +- Sort [id#36498 ASC NULLS FIRST, wthr_date#36502 ASC NULLS FIRST], true, 0\n                     +- Exchange rangepartitioning(id#36498 ASC NULLS FIRST, wthr_date#36502 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#18577]\n                        +- Project [id#36498, avg_tmpr_c#36493, wthr_date#36502, srch_ci#36518, srch_co#36519]\n                           +- BroadcastHashJoin [cast(id#36498 as bigint)], [hotel_id#36525L], Inner, BuildLeft, ((wthr_date#36502 &gt;= srch_ci#36518) AND (wthr_date#36502 &lt;= srch_co#36519)), false\n                              :- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[1, string, false] as bigint)),false), [id=#18573]\n                              :  +- Filter (isnotnull(wthr_date#36502) AND isnotnull(id#36498))\n                              :     +- FileScan parquet spark_sql.hotel_weather[avg_tmpr_c#36493,id#36498,wthr_date#36502] Batched: true, DataFilters: [isnotnull(wthr_date#36502), isnotnull(id#36498)], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/hotel_weather], PartitionFilters: [], PushedFilters: [IsNotNull(wthr_date), IsNotNull(id)], ReadSchema: struct&lt;avg_tmpr_c:double,id:string,wthr_date:string&gt;\n                              +- Filter (((isnotnull(srch_co#36519) AND isnotnull(srch_ci#36518)) AND (datediff(cast(srch_co#36519 as date), cast(srch_ci#36518 as date)) &gt; 7)) AND isnotnull(hotel_id#36525L))\n                                 +- FileScan parquet spark_sql.expedia[srch_ci#36518,srch_co#36519,hotel_id#36525L] Batched: true, DataFilters: [isnotnull(srch_co#36519), isnotnull(srch_ci#36518), (datediff(cast(srch_co#36519 as date), cast(..., Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [IsNotNull(srch_co), IsNotNull(srch_ci), IsNotNull(hotel_id)], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">== Parsed Logical Plan ==\n&#39;CreateTableAsSelectStatement [query_3], false, true\n+- &#39;Aggregate [&#39;id, &#39;srch_ci, &#39;srch_co], [&#39;id, &#39;avg(&#39;avg_tmpr_c) AS avg_order_tmpr_c#36449, &#39;srch_ci, &#39;srch_co, CASE WHEN ((&#39;max(&#39;wthr_date) = &#39;srch_co) AND (&#39;min(&#39;wthr_date) = &#39;srch_ci)) THEN (last(&#39;avg_tmpr_c, false) - first(&#39;avg_tmpr_c, false)) ELSE null END AS tmpr_diff#36452]\n   +- &#39;UnresolvedRelation [join_data_view], [], false\n\n== Analyzed Logical Plan ==\nnum_affected_rows: bigint, num_inserted_rows: bigint\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_3, true\n+- Aggregate [id#36453, srch_ci#36456, srch_co#36457], [id#36453, avg(avg_tmpr_c#36454) AS avg_order_tmpr_c#36449, srch_ci#36456, srch_co#36457, CASE WHEN ((max(wthr_date#36455) = srch_co#36457) AND (min(wthr_date#36455) = srch_ci#36456)) THEN (last(avg_tmpr_c#36454, false) - first(avg_tmpr_c#36454, false)) ELSE cast(null as double) END AS tmpr_diff#36452]\n   +- SubqueryAlias spark_catalog.spark_sql.join_data_view\n      +- View (`spark_sql`.`join_data_view`, [id#36453,avg_tmpr_c#36454,wthr_date#36455,srch_ci#36456,srch_co#36457])\n         +- Project [cast(id#36498 as string) AS id#36453, cast(avg_tmpr_c#36493 as double) AS avg_tmpr_c#36454, cast(wthr_date#36502 as string) AS wthr_date#36455, cast(srch_ci#36518 as string) AS srch_ci#36456, cast(srch_co#36519 as string) AS srch_co#36457]\n            +- Sort [id#36498 ASC NULLS FIRST, wthr_date#36502 ASC NULLS FIRST], true\n               +- Project [id#36498, avg_tmpr_c#36493, wthr_date#36502, srch_ci#36518, srch_co#36519]\n                  +- Filter (((wthr_date#36502 &gt;= srch_ci#36518) AND (wthr_date#36502 &lt;= srch_co#36519)) AND (datediff(cast(srch_co#36519 as date), cast(srch_ci#36518 as date)) &gt; 7))\n                     +- Join Inner, (cast(id#36498 as bigint) = hotel_id#36525L)\n                        :- SubqueryAlias hw\n                        :  +- SubqueryAlias spark_catalog.spark_sql.hotel_weather\n                        :     +- Relation[address#36492,avg_tmpr_c#36493,avg_tmpr_f#36494,city#36495,country#36496,geoHash#36497,id#36498,latitude#36499,longitude#36500,name#36501,wthr_date#36502,year#36503,month#36504,day#36505] parquet\n                        +- SubqueryAlias ex\n                           +- SubqueryAlias spark_catalog.spark_sql.expedia\n                              +- Relation[id#36506L,date_time#36507,site_name#36508,posa_continent#36509,user_location_country#36510,user_location_region#36511,user_location_city#36512,orig_destination_distance#36513,user_id#36514,is_mobile#36515,is_package#36516,channel#36517,srch_ci#36518,srch_co#36519,srch_adults_cnt#36520,srch_children_cnt#36521,srch_rm_cnt#36522,srch_destination_id#36523,srch_destination_type_id#36524,hotel_id#36525L] parquet\n\n== Optimized Logical Plan ==\nCreateTableAsSelect com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_3, true\n+- Aggregate [id#36498, srch_ci#36518, srch_co#36519], [id#36498, avg(avg_tmpr_c#36493) AS avg_order_tmpr_c#36449, srch_ci#36518, srch_co#36519, CASE WHEN ((max(wthr_date#36502) = srch_co#36519) AND (min(wthr_date#36502) = srch_ci#36518)) THEN (last(avg_tmpr_c#36493, false) - first(avg_tmpr_c#36493, false)) END AS tmpr_diff#36452]\n   +- Sort [id#36498 ASC NULLS FIRST, wthr_date#36502 ASC NULLS FIRST], true\n      +- Project [id#36498, avg_tmpr_c#36493, wthr_date#36502, srch_ci#36518, srch_co#36519]\n         +- Join Inner, (((wthr_date#36502 &gt;= srch_ci#36518) AND (wthr_date#36502 &lt;= srch_co#36519)) AND (cast(id#36498 as bigint) = hotel_id#36525L))\n            :- Project [avg_tmpr_c#36493, id#36498, wthr_date#36502]\n            :  +- Filter (isnotnull(wthr_date#36502) AND isnotnull(id#36498))\n            :     +- Relation[address#36492,avg_tmpr_c#36493,avg_tmpr_f#36494,city#36495,country#36496,geoHash#36497,id#36498,latitude#36499,longitude#36500,name#36501,wthr_date#36502,year#36503,month#36504,day#36505] parquet\n            +- Project [srch_ci#36518, srch_co#36519, hotel_id#36525L]\n               +- Filter (((isnotnull(srch_co#36519) AND isnotnull(srch_ci#36518)) AND (datediff(cast(srch_co#36519 as date), cast(srch_ci#36518 as date)) &gt; 7)) AND isnotnull(hotel_id#36525L))\n                  +- Relation[id#36506L,date_time#36507,site_name#36508,posa_continent#36509,user_location_country#36510,user_location_region#36511,user_location_city#36512,orig_destination_distance#36513,user_id#36514,is_mobile#36515,is_package#36516,channel#36517,srch_ci#36518,srch_co#36519,srch_adults_cnt#36520,srch_children_cnt#36521,srch_rm_cnt#36522,srch_destination_id#36523,srch_destination_type_id#36524,hotel_id#36525L] parquet\n\n== Physical Plan ==\nAtomicCreateTableAsSelect [num_affected_rows#36641L, num_inserted_rows#36642L], com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog@d2cd778, spark_sql.query_3, Aggregate [id#36498, srch_ci#36518, srch_co#36519], [id#36498, avg(avg_tmpr_c#36493) AS avg_order_tmpr_c#36449, srch_ci#36518, srch_co#36519, CASE WHEN ((max(wthr_date#36502) = srch_co#36519) AND (min(wthr_date#36502) = srch_ci#36518)) THEN (last(avg_tmpr_c#36493, false) - first(avg_tmpr_c#36493, false)) END AS tmpr_diff#36452], [owner=root], [], true\n+- AdaptiveSparkPlan isFinalPlan=false\n   +- SortAggregate(key=[id#36498, srch_ci#36518, srch_co#36519], functions=[finalmerge_avg(merge sum#36589, count#36590L) AS avg(avg_tmpr_c#36493)#36526, finalmerge_max(merge max#36592) AS max(wthr_date#36502)#36527, finalmerge_min(merge min#36594) AS min(wthr_date#36502)#36528, finalmerge_last(merge last#36597, valueSet#36598) AS last(avg_tmpr_c#36493)()#36450, finalmerge_first(merge first#36601, valueSet#36602) AS first(avg_tmpr_c#36493)()#36451], output=[id#36498, avg_order_tmpr_c#36449, srch_ci#36518, srch_co#36519, tmpr_diff#36452])\n      +- Sort [id#36498 ASC NULLS FIRST, srch_ci#36518 ASC NULLS FIRST, srch_co#36519 ASC NULLS FIRST], false, 0\n         +- Exchange hashpartitioning(id#36498, srch_ci#36518, srch_co#36519, 200), ENSURE_REQUIREMENTS, [id=#18583]\n            +- SortAggregate(key=[id#36498, srch_ci#36518, srch_co#36519], functions=[partial_avg(avg_tmpr_c#36493) AS (sum#36589, count#36590L), partial_max(wthr_date#36502) AS max#36592, partial_min(wthr_date#36502) AS min#36594, partial_last(avg_tmpr_c#36493, false) AS (last#36597, valueSet#36598), partial_first(avg_tmpr_c#36493, false) AS (first#36601, valueSet#36602)], output=[id#36498, srch_ci#36518, srch_co#36519, sum#36589, count#36590L, max#36592, min#36594, last#36597, valueSet#36598, first#36601, valueSet#36602])\n               +- Sort [id#36498 ASC NULLS FIRST, srch_ci#36518 ASC NULLS FIRST, srch_co#36519 ASC NULLS FIRST], false, 0\n                  +- Sort [id#36498 ASC NULLS FIRST, wthr_date#36502 ASC NULLS FIRST], true, 0\n                     +- Exchange rangepartitioning(id#36498 ASC NULLS FIRST, wthr_date#36502 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#18577]\n                        +- Project [id#36498, avg_tmpr_c#36493, wthr_date#36502, srch_ci#36518, srch_co#36519]\n                           +- BroadcastHashJoin [cast(id#36498 as bigint)], [hotel_id#36525L], Inner, BuildLeft, ((wthr_date#36502 &gt;= srch_ci#36518) AND (wthr_date#36502 &lt;= srch_co#36519)), false\n                              :- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[1, string, false] as bigint)),false), [id=#18573]\n                              :  +- Filter (isnotnull(wthr_date#36502) AND isnotnull(id#36498))\n                              :     +- FileScan parquet spark_sql.hotel_weather[avg_tmpr_c#36493,id#36498,wthr_date#36502] Batched: true, DataFilters: [isnotnull(wthr_date#36502), isnotnull(id#36498)], Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/hotel_weather], PartitionFilters: [], PushedFilters: [IsNotNull(wthr_date), IsNotNull(id)], ReadSchema: struct&lt;avg_tmpr_c:double,id:string,wthr_date:string&gt;\n                              +- Filter (((isnotnull(srch_co#36519) AND isnotnull(srch_ci#36518)) AND (datediff(cast(srch_co#36519 as date), cast(srch_ci#36518 as date)) &gt; 7)) AND isnotnull(hotel_id#36525L))\n                                 +- FileScan parquet spark_sql.expedia[srch_ci#36518,srch_co#36519,hotel_id#36525L] Batched: true, DataFilters: [isnotnull(srch_co#36519), isnotnull(srch_ci#36518), (datediff(cast(srch_co#36519 as date), cast(..., Format: Parquet, Location: PreparedDeltaFileIndex[dbfs:/user/hive/warehouse/spark_sql.db/expedia], PartitionFilters: [], PushedFilters: [IsNotNull(srch_co), IsNotNull(srch_ci), IsNotNull(hotel_id)], ReadSchema: struct&lt;srch_ci:string,srch_co:string,hotel_id:bigint&gt;\n\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"spark_sql","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1211130925213075}},"nbformat":4,"nbformat_minor":0}
>>>>>>> developed spark sql hw
